<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    
    <head><meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
        <!-- AppResources meta begin -->
        <script type="text/javascript">var ncbi_startTime = new Date();</script>
        <!-- AppResources meta end -->
        
        <!-- TemplateResources meta begin -->
        <meta name="paf_template" content="" />

        <!-- TemplateResources meta end -->
        
        <!-- Logger begin -->
        <meta name="ncbi_db" content="pmc" /><meta name="ncbi_pdid" content="article" /><meta name="ncbi_acc" content="" /><meta name="ncbi_domain" content="nihpa" /><meta name="ncbi_report" content="record" /><meta name="ncbi_type" content="fulltext" /><meta name="ncbi_objectid" content="" /><meta name="ncbi_pcid" content="/articles/PMC5876027/" /><meta name="ncbi_app" content="pmc" />
        <!-- Logger end -->
        
        <title>FERA 2017 - Addressing Head Pose in the Third Facial Expression Recognition and Analysis Challenge</title>
        
        <!-- AppResources external_resources begin -->
        <link rel="stylesheet" href="/core/jig/1.14.8/css/jig.min.css" /><script type="text/javascript" src="/core/jig/1.14.8/js/jig.min.js"></script>

        <!-- AppResources external_resources end -->
        
        <!-- Page meta begin -->
        <meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE" /><link rel="canonical" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5876027/" /><link rel="schema.DC" href="http://purl.org/DC/elements/1.0/" /><meta name="citation_journal_title" content="Proceedings of the ... International Conference on Automatic Face and Gesture Recognition. IEEE International Conference on Automatic Face &amp; Gesture Recognition" /><meta name="citation_title" content="FERA 2017 - Addressing Head Pose in the Third Facial Expression Recognition and Analysis Challenge" /><meta name="citation_authors" content="Michel F. Valstar, Enrique Sánchez-Lozano, Jeffrey F. Cohn, László A. Jeni, Jeffrey M. Girard, Zheng Zhang, Lijun Yin, Maja Pantic" /><meta name="citation_date" content="May-Jun 2017" /><meta name="citation_volume" content="2017" /><meta name="citation_firstpage" content="839" /><meta name="citation_doi" content="10.1109/FG.2017.107" /><meta name="citation_abstract_html_url" content="/pmc/articles/PMC5876027/?report=abstract" /><meta name="citation_fulltext_html_url" content="/pmc/articles/PMC5876027/" /><meta name="citation_pmid" content="29606917" /><meta name="DC.Title" content="FERA 2017 - Addressing Head Pose in the Third Facial Expression Recognition and Analysis Challenge" /><meta name="DC.Type" content="Text" /><meta name="DC.Publisher" content="NIH Public Access" /><meta name="DC.Contributor" content="Michel F. Valstar" /><meta name="DC.Contributor" content="Enrique Sánchez-Lozano" /><meta name="DC.Contributor" content="Jeffrey F. Cohn" /><meta name="DC.Contributor" content="László A. Jeni" /><meta name="DC.Contributor" content="Jeffrey M. Girard" /><meta name="DC.Contributor" content="Zheng Zhang" /><meta name="DC.Contributor" content="Lijun Yin" /><meta name="DC.Contributor" content="Maja Pantic" /><meta name="DC.Date" content="May-Jun 2017" /><meta name="DC.Identifier" content="10.1109/FG.2017.107" /><meta name="DC.Language" content="en" /><meta property="og:title" content="FERA 2017 - Addressing Head Pose in the Third Facial Expression Recognition and Analysis Challenge" /><meta property="og:type" content="article" /><meta property="og:description" content="The field of Automatic Facial Expression Analysis has grown rapidly in recent years. However, despite progress in new approaches as well as benchmarking efforts, most evaluations still focus on either posed expressions, near-frontal recordings, or both. ..." /><meta property="og:url" content="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5876027/" /><meta property="og:site_name" content="PubMed Central (PMC)" /><meta property="og:image" content="https://www.ncbi.nlm.nih.gov/corehtml/pmc/pmcgifs/pmc-logo-share.png" /><meta name="twitter:card" content="summary" /><meta name="twitter:site" content="@ncbi" /><link rel="stylesheet" href="/corehtml/pmc/css/3.15.9/ncbi.min.css" type="text/css" data-apply="standalone" /><link rel="stylesheet" href="/corehtml/pmc/css/3.15.9/pmc.min.css" type="text/css" /><link rel="stylesheet" href="/corehtml/pmc/css/3.15.9/pmcrefs1.min.css" type="text/css" /><link rel="stylesheet" href="/corehtml/pmc/css/3.15.9/pmc_extras_prnt.min.css" type="text/css" media="print" /><style type="text/css">.pmc-wm {background:transparent repeat-y top left;background-image:url(/corehtml/pmc/pmcgifs/wm-hhspa.gif);background-size: auto, contain}</style><style type="text/css">.print-view{display:block}</style><script>
				var isjq= typeof jQuery === "function"
			</script><script type="text/javascript">if (!isjq){document.write('\x3Cscript type="text/javascript" src="/core/jig/1.15.2/js/jig.min.js"\x3E\x3C/script\x3E')}{document.write('\x3Cscript type="text/javascript" src="/core/jig/1.15.2/js/jig.nojquery.min.js"\x3E\x3C/script\x3E')}</script><script type="text/javascript" src="/corehtml/pmc/js/common.js">//</script><script type="text/javascript" src="/corehtml/pmc/js/NcbiTagServer.min.js">//</script><script type="text/javascript" src="/corehtml/pmc/js/jactions.js">//</script><meta name="citationexporter" content="backend:'https://api.ncbi.nlm.nih.gov/lit/ctxp/v1/pmc/'" /><script type="text/javascript" src="https://www.ncbi.nlm.nih.gov/corehtml/pmc/ctxp/jquery.citationexporter.min.js">//</script><link rel="stylesheet" href="https://www.ncbi.nlm.nih.gov/corehtml/pmc/ctxp/citationexporter.css" type="text/css" /><script type="text/javascript" src="/core/mathjax/2.6.1/MathJax.js?config=/corehtml/pmc/js/mathjax-config-classic.3.4.js"></script><script type="text/javascript">window.name="mainwindow";</script><style type="text/css">
        div.pmc_para_cit li.highlight,
        div.pmc_para_cit li.highlight .one_line_source
        { background: #E0E0E0; }
        a.bibr.highlight { background: #E0E0E0; } 
      </style><meta name="cited_in_systematic_reviews" content="" /><link rel="alternate" type="application/epub+zip" href="/pmc/articles/PMC5876027/epub/" /><link rel="alternate" type="application/pdf" href="/pmc/articles/PMC5876027/pdf/nihms950421.pdf" />

        <!-- Page meta end -->
    <link rel="shortcut icon" href="//www.ncbi.nlm.nih.gov/favicon.ico" /><meta name="ncbi_phid" content="8A1B8D72034FBA010000000008470846.m_8" />
<meta name='referrer' content='origin-when-cross-origin'/><link type="text/css" rel="stylesheet" href="//static.pubmed.gov/portal/portal3rc.fcgi/4160049/css/3852956/3985586/3808861/4121862/3974050/3917732/251717/4048120/3846471/14534/45193/4113719/3849091/3984811/3751656/4033350/3840896/3577051/3852958/3881636/3579733/4062871/12930/3964959/3855473/4047625/3854974/3854955/4076335/4128070/9685/3549676/3609192/3609193/3609213/3395586/4143404.css" /><link type="text/css" rel="stylesheet" href="//static.pubmed.gov/portal/portal3rc.fcgi/4160049/css/3411343/3882866/4157116.css" media="print" /></head>
    <body class="article">
        <div class="grid">
            <div class="col twelve_col nomargin shadow">
                <!-- System messages like service outage or JS required; this is handled by the TemplateResources portlet -->
                <div class="sysmessages">
                    <noscript>
	<p class="nojs">
	<strong>Warning:</strong>
	The NCBI web site requires JavaScript to function. 
	<a href="/guide/browsers/#enablejs" title="Learn how to enable JavaScript" target="_blank">more...</a>
	</p>
	</noscript>
                </div>
                <!--/.sysmessage-->
                <div class="wrap">
                    <div class="page">
                        <div class="top">
                            <div class="universal_header" id="universal_header"><ul class="inline_list jig-ncbimenu ui-ncbimenu resources_list" id="navcontent"><li class="ui-ncbimenu-item-leaf ui-ncbimenu-item-first ui-helper-reset ui-ncbimenu-item-no-hlt"><a class="ui-ncbimenu-link-first" href="/" role="banner" title="NCBI Home" id="ncbihome" accesskey="1"><span class="offscreen_noflow">NCBI</span><img src="//static.pubmed.gov/portal/portal3rc.fcgi/4160049/img/28977" class="ncbi_logo" title="NCBI" alt="NCBI Logo" /></a></li><li class="offscreen_noflow ui-ncbimenu-item-skip access"><a href="#maincontent" title="Skip to the content" tabindex="0" accesskey="3">Skip to main
                        content</a></li><li class="offscreen_noflow ui-ncbimenu-item-skip access"><a href="#navcontent" title="Skip to the navigation" tabindex="0" accesskey="4">Skip to
                        navigation</a></li><li id="resource-menu" class="topmenu ui-helper-reset ui-ncbimenu-item-first ui-helper-reset"><a class="ui-ncbimenu-first-link-has-submenu ui-ncbimenu-link-first topanchor expandDown" href="/static/header_footer_ajax/submenu/#resources">Resources</a></li><li id="all-howtos-menu" class="topmenu ui-helper-reset ui-ncbimenu-item-first"><a class="ui-ncbimenu-first-link-has-submenu ui-ncbimenu-link-first topanchor expandDown" href="/static/header_footer_ajax/submenu/#howto">How To</a></li><li class="offscreen_noflow ui-ncbimenu-item-skip access"><a href="/guide/browsers/#accesskeys" title="About My NCBI Accesskeys" tabindex="0" accesskey="0">About NCBI Accesskeys</a></li></ul><div class="myncbi"><span id="myncbiusername" style="display:none"><a href="/account/settings/" id="mnu" title="Edit account settings"></a></span><a accesskey="2" href="/myncbi/" id="myncbi" style="display:none">My NCBI</a><a href="/account/" id="sign_in">Sign in to NCBI</a><a href="/account/signout/" id="sign_out" style="display:none">Sign Out</a></div></div>
                            <div class="header">
    <div class="res_logo">
  <h1 class="img_logo"><a href="/pmc/" class="pmc_logo offscreen">PMC</a></h1>
  <div class="NLMLogo">
    <a href="https://www.nlm.nih.gov/" title="US National Library of Medicine">US National Library of Medicine</a>
    <br />
    <a href="https://www.nih.gov/" title="National Institutes of Health">National Institutes of Health</a>
  </div>
</div>
    <div class="search"><form method="get" action="/pmc/"><div class="search_form"><label for="database" class="offscreen_noflow">Search database</label><select id="database"><optgroup label="Recent"><option value="pmc" selected="selected" class="last" data-ac_dict="pmc-search-autocomplete">PMC</option></optgroup><optgroup label="All"><option value="gquery">All Databases</option><option value="assembly">Assembly</option><option value="biocollections">Biocollections</option><option value="bioproject">BioProject</option><option value="biosample">BioSample</option><option value="biosystems">BioSystems</option><option value="books">Books</option><option value="clinvar">ClinVar</option><option value="cdd">Conserved Domains</option><option value="gap">dbGaP</option><option value="dbvar">dbVar</option><option value="gene">Gene</option><option value="genome">Genome</option><option value="gds">GEO DataSets</option><option value="geoprofiles">GEO Profiles</option><option value="gtr">GTR</option><option value="homologene">HomoloGene</option><option value="ipg">Identical Protein Groups</option><option value="medgen">MedGen</option><option value="mesh">MeSH</option><option value="ncbisearch">NCBI Web Site</option><option value="nlmcatalog">NLM Catalog</option><option value="nuccore">Nucleotide</option><option value="omim">OMIM</option><option value="pmc" data-ac_dict="pmc-search-autocomplete">PMC</option><option value="popset">PopSet</option><option value="protein">Protein</option><option value="proteinclusters">Protein Clusters</option><option value="protfam">Protein Family Models</option><option value="pcassay">PubChem BioAssay</option><option value="pccompound">PubChem Compound</option><option value="pcsubstance">PubChem Substance</option><option value="pubmed">PubMed</option><option value="snp">SNP</option><option value="sra">SRA</option><option value="structure">Structure</option><option value="taxonomy">Taxonomy</option><option value="toolkit">ToolKit</option><option value="toolkitall">ToolKitAll</option><option value="toolkitbookgh">ToolKitBookgh</option></optgroup></select><div class="nowrap"><label for="term" class="offscreen_noflow" accesskey="/">Search term</label><div class="nowrap"><input type="text" name="term" id="term" title="Search PMC. Use up and down arrows to choose an item from the autocomplete." value="" class="jig-ncbiclearbutton jig-ncbiautocomplete" data-jigconfig="dictionary:'pmc-search-autocomplete',disableUrl:'NcbiSearchBarAutoComplCtrl'" autocomplete="off" data-sbconfig="ds:'no',pjs:'no',afs:'yes'" /></div><button id="search" type="submit" class="button_search nowrap" cmd="go">Search</button></div></div></form><ul class="searchlinks inline_list"><li>
                        <a href="/pmc/advanced/">Advanced</a>
                    </li><li>
                        <a href="/pmc/journals/">Journal list</a>
                    </li><li class="help">
                        <a target="_blank" href="/books/NBK3825/">Help</a>
                    </li></ul></div>
</div>

                            
                            
                        <!--<component id="Page" label="headcontent"/>-->
                            
                        </div>
                        <div class="content">
                            <!-- site messages -->
                            <div class="container">
    <div id="maincontent" class="content eight_col col">
        <div class="navlink-box">
            <ul class="page-breadcrumbs inline_list small"><li class="journal-list"><a href="/pmc/journals/" class="navlink">Journal List</a></li><li class="article-entrez-filter"><a href="/pmc/?term=hhs%20author%20manuscript[filter]" class="navlink">HHS Author Manuscripts</a></li><li class="accid">PMC5876027</li></ul>
        </div>

        <!-- Journal banner -->
        <div class="pmc-page-banner whole_rhythm"><div><img src="/corehtml/pmc/pmcgifs/logo-hhspa.png" alt="Logo of nihpa" usemap="#logo-imagemap" /><map id="logo-imagemap" name="logo-imagemap"><area shape="rect" coords="0,57,255,75" alt="About Author manuscripts" title="About Author manuscripts" href="https://www.ncbi.nlm.nih.gov/pmc/about/authorms.html" ref="https://www.ncbi.nlm.nih.gov/pmc/about/authorms.html" /><area shape="rect" coords="256,57,500,75" alt="Submit a manuscript" title="Submit a manuscript" href="https://www.nihms.nih.gov/" ref="reftype=publisher&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CBanner&amp;TO=Publisher%7COther%7CN/A" target="pmc_ext" /><area shape="rect" coords="0,0,499,74" alt="HHS Public Access; Author Manuscript; Accepted for publication in peer reviewed journal;" title="HHS Public Access; Author Manuscript; Accepted for publication in peer reviewed journal;" href="https://www.ncbi.nlm.nih.gov/pmc/about/public-access/" ref="reftype=publisher&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CBanner&amp;TO=Publisher%7COther%7CN/A" target="pmc_ext" /></map></div> </div>
        
        <!--component id='MainPortlet' label='search-reference'/-->
        
        <!-- Book content -->
        <div class="">
            
        
            
            <div id="mc" class=" article lit-style content pmc-wm slang-all page-box"><!--main-content--><div class="jig-ncbiinpagenav" data-jigconfig="smoothScroll: false, allHeadingLevels: ['h2'], headingExclude: ':hidden,.nomenu'"><div class="fm-sec half_rhythm no_top_margin"><div class="fm-flexbox"><div class="fm-citation"><div><span id="pmcmata">Proc Int Conf Autom Face Gesture Recognit.</span> Author manuscript; available in PMC 2018 Mar 29.</div><div></div><div class="final-form"><em>Published in final edited form as:</em></div><div class="final-citation"><div class="fm-vol-iss-date">Proc Int Conf Autom Face Gesture Recognit. 2017 May-Jun; 2017: 839–847. </div><span class="fm-vol-iss-date">Published online 2017 Jun 29. </span> <span class="doi"><span>doi: </span><a href="//dx.doi.org/10.1109%2FFG.2017.107" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CFront%20Matter&amp;TO=Content%20Provider%7CCrosslink%7CDOI">10.1109/FG.2017.107</a></span></div></div><div class="fm-ids"><div class="fm-citation-pmcid"><span class="fm-citation-ids-label">PMCID: </span><span>PMC5876027</span></div><div class="fm-citation-manuscriptid"><span class="fm-citation-ids-label">NIHMSID: </span><span>NIHMS950421</span></div><div class="fm-citation-pmid">PMID: <a href="/pubmed/29606917">29606917</a></div></div></div><h1 class="content-title">FERA 2017 - Addressing Head Pose in the Third Facial Expression Recognition and Analysis Challenge</h1><div class="half_rhythm"><div class="contrib-group fm-author"><a href="/pubmed/?term=Valstar%20MF%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=29606917" class="affpopup" co-rid="_co_idm139903788674624" co-class="co-affbox">Michel F. Valstar</a>,<sup>1</sup> <a href="/pubmed/?term=S%26%23x000e1%3Bnchez-Lozano%20E%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=29606917" class="affpopup" co-rid="_co_idm139903786068304" co-class="co-affbox">Enrique S&#x000e1;nchez-Lozano</a>,<sup>1</sup> <a href="/pubmed/?term=Cohn%20JF%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=29606917" class="affpopup" co-rid="_co_idm139903791570864" co-class="co-affbox">Jeffrey F. Cohn</a>,<sup>2,</sup><sup>6</sup> <a href="/pubmed/?term=Jeni%20LA%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=29606917" class="affpopup" co-rid="_co_idm139903783926256" co-class="co-affbox">L&#x000e1;szl&#x000f3; A. Jeni</a>,<sup>6</sup> <a href="/pubmed/?term=Girard%20JM%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=29606917" class="affpopup" co-rid="_co_idm139903787508928" co-class="co-affbox">Jeffrey M. Girard</a>,<sup>2</sup> <a href="/pubmed/?term=Zhang%20Z%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=29606917" class="affpopup" co-rid="_co_idm139903787506944" co-class="co-affbox">Zheng Zhang</a>,<sup>3</sup> <a href="/pubmed/?term=Yin%20L%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=29606917" class="affpopup" co-rid="_co_idm139903785277424" co-class="co-affbox">Lijun Yin</a>,<sup>3</sup> and  <a href="/pubmed/?term=Pantic%20M%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=29606917" class="affpopup" co-rid="_co_idm139903785802096" co-class="co-affbox">Maja Pantic</a><sup>4,</sup><sup>5</sup></div><div style="display:none" class="contrib-group aff-tip"><div id="_co_idm139903788674624"><h3 class="no_margin">Michel F. Valstar</h3><p>
<sup>1</sup>School of Computer Science, University of Nottingham, UK</p><div>Find articles by <a href="/pubmed/?term=Valstar%20MF%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=29606917">Michel F. Valstar</a></div></div><div id="_co_idm139903786068304"><h3 class="no_margin">Enrique S&#x000e1;nchez-Lozano</h3><p>
<sup>1</sup>School of Computer Science, University of Nottingham, UK</p><div>Find articles by <a href="/pubmed/?term=S%26%23x000e1%3Bnchez-Lozano%20E%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=29606917">Enrique S&#x000e1;nchez-Lozano</a></div></div><div id="_co_idm139903791570864"><h3 class="no_margin">Jeffrey F. Cohn</h3><p>
<sup>2</sup>Department of Psychology, University of Pittsburgh, Pittsburgh, USA</p><p>
<sup>6</sup>Robotics Institute, Carnegie Mellon University, Pittsburgh, USA</p><div>Find articles by <a href="/pubmed/?term=Cohn%20JF%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=29606917">Jeffrey F. Cohn</a></div></div><div id="_co_idm139903783926256"><h3 class="no_margin">L&#x000e1;szl&#x000f3; A. Jeni</h3><p>
<sup>6</sup>Robotics Institute, Carnegie Mellon University, Pittsburgh, USA</p><div>Find articles by <a href="/pubmed/?term=Jeni%20LA%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=29606917">L&#x000e1;szl&#x000f3; A. Jeni</a></div></div><div id="_co_idm139903787508928"><h3 class="no_margin">Jeffrey M. Girard</h3><p>
<sup>2</sup>Department of Psychology, University of Pittsburgh, Pittsburgh, USA</p><div>Find articles by <a href="/pubmed/?term=Girard%20JM%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=29606917">Jeffrey M. Girard</a></div></div><div id="_co_idm139903787506944"><h3 class="no_margin">Zheng Zhang</h3><p>
<sup>3</sup>Department of Computer Science, Binghamton University, Binghamton, USA</p><div>Find articles by <a href="/pubmed/?term=Zhang%20Z%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=29606917">Zheng Zhang</a></div></div><div id="_co_idm139903785277424"><h3 class="no_margin">Lijun Yin</h3><p>
<sup>3</sup>Department of Computer Science, Binghamton University, Binghamton, USA</p><div>Find articles by <a href="/pubmed/?term=Yin%20L%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=29606917">Lijun Yin</a></div></div><div id="_co_idm139903785802096"><h3 class="no_margin">Maja Pantic</h3><p>
<sup>4</sup>Department of Computing, Imperial College London, London, UK</p><p>
<sup>5</sup>Electrical Engineering, Mathematics and Computer Science, University of Twente, The Netherlands</p><div>Find articles by <a href="/pubmed/?term=Pantic%20M%5BAuthor%5D&amp;cauthor=true&amp;cauthor_uid=29606917">Maja Pantic</a></div></div></div></div><div class="fm-panel half_rhythm"><div class="togglers fm-copyright-license"><a href="#" class="pmctoggle" rid="idm139903785806688_ai">Author information</a> <a href="#" class="pmctoggle" rid="idm139903785806688_cpl">Copyright and License information</a> <a href="/pmc/about/disclaimer/" style="margin-left: 1em">Disclaimer</a></div><div class="fm-authors-info fm-panel hide half_rhythm" id="idm139903785806688_ai" style="display:none"><div class="fm-affl" lang="en" id="A1">
<sup>1</sup>School of Computer Science, University of Nottingham, UK</div><div class="fm-affl" lang="en" id="A2">
<sup>2</sup>Department of Psychology, University of Pittsburgh, Pittsburgh, USA</div><div class="fm-affl" lang="en" id="A3">
<sup>3</sup>Department of Computer Science, Binghamton University, Binghamton, USA</div><div class="fm-affl" lang="en" id="A4">
<sup>4</sup>Department of Computing, Imperial College London, London, UK</div><div class="fm-affl" lang="en" id="A5">
<sup>5</sup>Electrical Engineering, Mathematics and Computer Science, University of Twente, The Netherlands</div><div class="fm-affl" lang="en" id="A6">
<sup>6</sup>Robotics Institute, Carnegie Mellon University, Pittsburgh, USA</div></div><div class="fm-article-notes fm-panel half_rhythm"></div><div class="permissions fm-panel half_rhythm hide" id="idm139903785806688_cpl" style="display:none"><div class="fm-copyright half_rhythm"><a href="/pmc/about/copyright/">Copyright notice</a> </div></div></div><div id="pmclinksbox" class="links-box whole_rhythm"><div class="fm-panel"><div>See other articles in PMC that <a href="/pmc/articles/PMC5876027/citedby/">cite</a> the published article.</div></div></div></div><div class="sec"></div><div id="idm139903772014592" lang="en" class="tsec sec"><h2 class="head no_bottom_margin" id="idm139903772014592title">Abstract</h2><!--article-meta--><div><p id="P1" class="p p-first-last">The field of Automatic Facial Expression Analysis has grown rapidly in recent years. However, despite progress in new approaches as well as benchmarking efforts, most evaluations still focus on either posed expressions, near-frontal recordings, or both. This makes it hard to tell how existing expression recognition approaches perform under conditions where faces appear in a wide range of poses (or camera views), displaying ecologically valid expressions. The main obstacle for assessing this is the availability of suitable data, and the challenge proposed here addresses this limitation. The FG 2017 Facial Expression Recognition and Analysis challenge (FERA 2017) extends FERA 2015 to the estimation of Action Units occurrence and intensity under different camera views. In this paper we present the third challenge in automatic recognition of facial expressions, to be held in conjunction with the 12th IEEE conference on Face and Gesture Recognition, May 2017, in Washington, United States. Two sub-challenges are defined: the detection of AU occurrence, and the estimation of AU intensity. In this work we outline the evaluation protocol, the data used, and the results of a baseline method for both sub-challenges.</p></div></div><div id="S1" class="tsec sec"><h2 class="head no_bottom_margin" id="S1title">I. INTRODUCTION</h2><p id="P2" class="p p-first">Facial expression analysis is a rapidly growing field of research, due to the constantly increasing interest in, and feasibility of applying automatic human behaviour analysis to all kinds of multimedia recordings involving people. Applications include classical psychology studies, market research, interactions with virtual humans, multimedia retrieval, and the study of medical conditions that alter expressive behaviour [<a href="#R25" rid="R25" class=" bibr popnode">25</a>]. Given the increasing prominence and utility of expression recognition systems, it is is increasingly important that such systems can be evaluated fairly and compared systematically. The FG 2017 Facial Expression Recognition and Analysis challenge (FERA 2017) shall support this effort by addressing three aspects frequently ignored in existing benchmarks: head-pose, expression intensity, and video duration.</p><p id="P3">Most Facial Expression Recognition and Analysis systems proposed in the literature focus on analysis of expressions from frontal faces. While it can be argued that in many scenarios people&#x02019;s faces will indeed be largely frontal most of the time, there are also many conditions in which either the camera angle is such that obtaining frontal views is unrealistic, or where the head pose with respect to the camera varies widely over time.</p><p id="P4">There are a few databases that include a number of non-frontal head-poses of a limited set of posed expressions. Multi-PIE recorded a very small number of expressions simultaneously with 15 cameras placed around the subject in a well-lit office setting [<a href="#R8" rid="R8" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_687718698">8</a>]. The MMI-Face database obtained frontal and profile views of all Facial Action Coding System Action Units (FACS AUs, [<a href="#R5" rid="R5" class=" bibr popnode">5</a>]) and six basic emotions using a mirror [<a href="#R28" rid="R28" class=" bibr popnode">28</a>]. But only databases recorded with depth-sensing cameras can generate an almost arbitrary set of face views of the same facial expression. One example database is the Bosphorus corpus [<a href="#R20" rid="R20" class=" bibr popnode">20</a>].</p><p id="P5">A second limitation of many existing benchmark databases is that they assume expression intensity is fixed, and as such they do not support the evaluation of intensity estimation. Most databases focus on detecting the occurrence of expressions, regardless of the significant differences in appearance, shape, and temporal dynamics caused by different expression intensities. In reality, expressions can vary greatly in intensity, and intensity is often a crucial cue for the interpretation of the meaning of expressions.</p><p id="P6">Indeed McKeown et al. [<a href="#R16" rid="R16" class=" bibr popnode">16</a>] have argued that the level of intensity is the key dimension in facial expressions that distinguishes whether they are delivered for sociocommunicative functions at low levels of intensity or that they become hard-to-fake signals indicating that the expression is associated with a genuine felt emotion at high levels of intensity. If this is the case then intensity may be one of the most important features in assessing a user&#x02019;s psychological state from facial expressions. However, very little annotated data is available for the evaluation of AU intensity estimation approaches. FERA 2015 made a significant step towards benchmarking AU intensity estimation, however, the data used in that challenge was predominantly of (near) frontal views [<a href="#R26" rid="R26" class=" bibr popnode">26</a>].</p><p id="P7">Finally, despite efforts towards evaluation standards of face video lasting longer than a few seconds (e.g. FERA 2011 [<a href="#R27" rid="R27" class=" bibr popnode">27</a>]), video duration remains an issue that must be addressed by benchmarking challenges. In particular, the community needs to move away from evaluation procedures where each video recording consists of only a single expression, often with the onset and offset of an expression expressly defined. Instead, we need unsegmented videos that show multiple expression, with ideally expressions naturally transitioning one into another, without explicit neutral divisions in between.</p><p id="P8" class="p p-last">In these respects, FERA 2017 shall help raise the bar for expression recognition by challenging participants to estimate AU intensity in face video of variable duration with unknown head-pose, thereby continuing to bridge the gap between excellent research on facial expression recognition and comparability and replication of results. In FERA 2017, we will use the BP4D+ dataset [<a href="#R33" rid="R33" class=" bibr popnode">33</a>] to generate from every video 9 different 2D views, based the underlying 3D source data. The challenge is to detect the occurrence and intensity of AUs, without knowing a priori what the facial view will be. We do this by means of two selected tasks: the detection of FACS Action Unit occurrence (Occurrence Detection Sub-Challenge), and fully automatic AU intensity estimation where the occurrence of AUS is not known beforehand (Intensity Estimation Sub-Challenge).</p></div><div id="S2" class="tsec sec"><h2 class="head no_bottom_margin" id="S2title">II. RELATED WORK</h2><p id="P9" class="p p-first">Facial expression recognition in general and action unit detection in particular have been studied extensively over the past decade. As a result, it is impossible to provide a comprehensive review of the field here. Instead we provide an overview of the relevant works only, focussing on methods that target AU occurrence detection and intensity estimation. For a general overview of the field of expression recognition we refer the reader to excellent recent surveys [<a href="#R4" rid="R4" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_687718699">4</a>], [<a href="#R31" rid="R31" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_687718703">31</a>].</p><div id="S3" class="sec"><h3 id="S3title">A. AU occurrence detection</h3><p id="P10" class="p p-first-last">Common binary classifiers applied to this problem include Artificial Neural Networks (ANN), Boosting techniques, and Support Vector Machines (SVM). ANNs were the most popular method in earlier works (e.g. [<a href="#R24" rid="R24" class=" bibr popnode">24</a>], [<a href="#R2" rid="R2" class=" bibr popnode">2</a>]). Boosting algorithms, such as AdaBoost and GentleBoost, have been a common choice for AU recognition (e.g. [<a href="#R9" rid="R9" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_685421026">9</a>], [<a href="#R30" rid="R30" class=" bibr popnode">30</a>]). Boosting algorithms are simple and quick to train. They have fewer parameters than SVM or ANN, and can be less prone to overfitting. They implicitly perform feature selection, which is desirable for handling high-dimensional data and speeding up inference, and can handle multiclass classification. SVMs are currently the most popular choice (e.g. [<a href="#R3" rid="R3" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_687718697">3</a>], [<a href="#R29" rid="R29" class=" bibr popnode">29</a>], [<a href="#R15" rid="R15" class=" bibr popnode">15</a>]). SVMs provide good performance, can be non-linear, parameter optimisation is relatively easy, as efficient implementations are readily available, and a choice of kernel functions provides extreme flexibility of design.</p></div><div id="S4" class="sec sec-last"><h3 id="S4title">B. AU intensity estimation</h3><p id="P11" class="p p-first">The goal in AU intensity estimation is to assign a per-frame label with possible integer value from 0 to 5 for each AU. This problem can be approached using either a classification or a regression learning method.</p><div id="S5" class="sec"><p></p><h4 id="S5title" class="inline">Classification-based methods </h4><p id="P12" class="p p-first">Some approaches use the confidence of a (binary) frame-based AU activation classifier to estimate AU intensity. The rationale is that the lower the intensity is, the harder the classification will be. For example, Bartlett et al. used the distance of the test sample to the SVM separating hyperplane [<a href="#R1" rid="R1" class=" bibr popnode">1</a>], while Hamm et al. used the confidence of the decision given by AdaBoost [<a href="#R9" rid="R9" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_685421027">9</a>].</p><p id="P13" class="p p-last">It is however more natural to treat the problem as 6-class classification. For example, Mahoor et al. employed six one-vs.-all binary SVM classifiers [<a href="#R15" rid="R15" class=" bibr popnode">15</a>]. Alternatively, a single multi-class classifier (e.g. ANN or a Boosting variant) could be used. The extremely large class overlap means however that such approaches are unlikely to be optimal. Girard [<a href="#R6" rid="R6" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_687718700">6</a>] found that multi-class and regression-based approaches more accurately detected intensity in comparison with distance-from-hyperplane based measures.</p></div><div id="S6" class="sec sec-last"><p></p><h4 id="S6title" class="inline">Regression-based methods </h4><p id="P14" class="p p-first-last">AU intensity estimation is nowadays often posed as a regression problem. Regression methods penalise incorrect labelling proportionally to the difference between ground truth and prediction. Such ordinal consideration of the labels is absent in classification methods. The large overlap between classes also implies an underlying continuous nature of intensity that regression techniques are better equipped to model. Examples include Support Vector Regression ([<a href="#R11" rid="R11" class=" bibr popnode">11</a>], [<a href="#R6" rid="R6" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_687718702">6</a>] and [<a href="#R21" rid="R21" class=" bibr popnode">21</a>]). Kaltwang et al. instead used Relevance Vector Regression to obtain a probabilistic prediction [<a href="#R12" rid="R12" class=" bibr popnode">12</a>].</p></div></div></div><div id="S7" class="tsec sec"><h2 class="head no_bottom_margin" id="S7title">III. DATA</h2><p id="P15" class="p p-first">The training data for the FERA 2017 challenge is derived from the BP4D-Spontaneous database [<a href="#R32" rid="R32" class=" bibr popnode">32</a>], and the validation and test data of FERA 2017 is derived from a subset of BP4D+ database [<a href="#R33" rid="R33" class=" bibr popnode">33</a>]. Data is split into train, validation, and test partitions. The train and development partitions are publicly available for researchers to train and develop their AU analysis systems, and to allow participants to uniformly report performance (i.e. using cross-validation). The test partition is held back by the organisers. Participants submit their trained systems and the FERA 2017 organisers apply their systems on this held-back data to create a fair comparison.</p><p id="P16" class="p">The challenge will focus on 10 AUs that occurred frequently in the BP4D dataset. The Occurrence Detection sub-challenge requires participants to detect 10 AUs from the BP4D database (see <a href="/pmc/articles/PMC5876027/table/T1/" target="table" class="fig-table-link figpopup" rid-figpopup="T1" rid-ob="ob-T1" co-legend-rid=""><span>Table I</span></a>). AUs were selected based on their frequency of occurrence and sufficiently high inter-rater reliability scores. AU intensity estimation will be done on a subset of 7 AUs only (see <a href="/pmc/articles/PMC5876027/table/T1/" target="table" class="fig-table-link figpopup" rid-figpopup="T1" rid-ob="ob-T1" co-legend-rid=""><span>Table I</span></a>).</p><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap anchored whole_rhythm" id="T1"><h3>TABLE I</h3><!--caption a7--><div class="caption"><p id="P53">Overview of AUs included in the two sub-challenges</p></div><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139903777358816" class="xtable"><table frame="box" rules="all" class="rendered small default_table"><thead><tr><th align="center" rowspan="1" colspan="1"></th><th align="center" rowspan="1" colspan="1">Occurrence detection</th><th align="center" rowspan="1" colspan="1">Intensity Estimation</th></tr></thead><tbody><tr><td align="center" rowspan="1" colspan="1">BP4D</td><td align="center" rowspan="1" colspan="1">AU1, AU4, AU6, AU7, AU10 AU12, AU14, AU15, AU17, AU23</td><td align="center" rowspan="1" colspan="1">AU1, AU4, AU6, AU10 AU12, AU14, AU17</td></tr></tbody></table></div><div id="largeobj_idm139903777358816" class="largeobj-link align_right" style="display: none"><a target="object" href="/pmc/articles/PMC5876027/table/T1/?report=objectonly">Open in a separate window</a></div></div><div id="S8" class="sec"><h3 id="S8title">A. Multiview Face Synthesis</h3><p id="P17" class="p p-first-last">Contrary to the FERA 2015 challenge, for FERA 2017, nine videos were created for each corresponding recording, ranging different face orientations, using the 3D models captured for each of the subjects. To create nine different face orientations, 3D sequences in BP4D and BP4D+ were rotated by -40, -20, and 0 degrees pitch and -40, 0, and 40 degrees yaw from frontal pose using ZFace [<a href="#R10" rid="R10" class=" bibr popnode">10</a>] and the known correspondence between 2D and 3D vertices. ZFace is real-time face alignment software that accomplishes dense 3D registration from 2D videos and images without requiring person-specific training. We calculated the true 3D locations of the facial landmarks by mapping them to the ground truth 3D meshes. Faces were centred and scale was normalised to the average interocular distance of all subjects. An example of the resulting pose orientations addressed in this challenge is shown in <a href="/pmc/articles/PMC5876027/figure/F1/" target="figure" class="fig-table-link figpopup" rid-figpopup="F1" rid-ob="ob-F1" co-legend-rid="lgnd_F1"><span>Figure 1</span></a>.</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm" id="F1" co-legend-rid="lgnd_F1"><a href="/pmc/articles/PMC5876027/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139903768520272" class="figure"><a class="inline_block ts_canvas" href="/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=5876027_nihms950421f1.jpg" target="tileshopwindow"><div class="ts_bar small" title="Click on image to zoom"></div><img loading="lazy" alt="An external file that holds a picture, illustration, etc.&#10;Object name is nihms950421f1.jpg" title="Click on image to zoom" class="tileshop" src="/pmc/articles/PMC5876027/bin/nihms950421f1.jpg" /></a></div><div id="largeobj_idm139903768520272" class="largeobj-link align_right" style="display: none"><a target="object" href="/pmc/articles/PMC5876027/figure/F1/?report=objectonly">Open in a separate window</a></div></a><div class="icnblk_cntnt" id="lgnd_F1"><div><a class="figpopup" href="/pmc/articles/PMC5876027/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1">Fig. 1</a></div><!--caption a7--><div class="caption"><p id="P51">Each of the different views considered for the FERA 2017 Challenge.</p></div></div></div></div><div id="S9" class="sec"><h3 id="S9title">B. BP4D Database</h3><p id="P18" class="p p-first">Both the train and test partitions of the BP4D and BP4D+ databases consist of video data of young adults responding to emotion-elicitation tasks. The datasets are described in detail below. Here we note differences between them that are most relevant to the challenge. The training data was collected first and is publicly available [<a href="#R32" rid="R32" class=" bibr popnode">32</a>]. The testing data is newer, part of the new collection [<a href="#R33" rid="R33" class=" bibr popnode">33</a>] that includes 2D, 3D, thermal imaging and peripheral physiology, and will be released later. The number of participants in the two partitions is 41 and 20, respectively. Some differences exist in the threshold for coding AU occurrence and intensity, and changes occurred in the mix of AU coders of the two partitions. Coders were highly trained for both, and reliability was tested throughout coding to ensure consistency.</p><p id="P19" class="p">The train partition of BP4D is selected from BP4D-Original [<a href="#R32" rid="R32" class=" bibr popnode">32</a>], and the test partition from BP4D-Expanded (a.k.a. BP4D+ [<a href="#R33" rid="R33" class=" bibr popnode">33</a>]). Below we will refer to these as BP4D-Train and BP4D-Test.</p><div id="S10" class="sec"><p></p><h4 id="S10title" class="inline">BP4D-Train </h4><p id="P20" class="p p-first">The BP4D-Train dataset includes digital video of 41 participants (56.1% female, 49.1% white, ages 18&#x02013;29). These individuals were recruited from the departments of psychology and computer science and from the school of engineering at Binghamton University. All participants gave informed consent to the procedures and permissible uses of their data. Participants sat approximately 51 inches in front of a Di3D dynamic face capturing system during a series of eight emotion elicitation tasks.</p><p id="P21" class="p p-last">To elicit target emotional expressions and conversational behaviour, we used approaches adapted from other investigators plus techniques that proved promising in pilot testing. Each task was administered by an experimenter who was a professional actor/director of performing arts. The procedures were designed to elicit a range of emotions and facial expressions that include happiness/amusement, sadness, surprise/startle, embarrassment, fear/nervous, physical pain, anger/upset, and disgust.</p></div><div id="S11" class="sec"><p></p><h4 id="S11title" class="inline">BP4D-Validation </h4><p id="P22" class="p p-first-last">The BP4D-Validation dataset includes digital videos of 20 participants, which is a subset of BP4D+ [<a href="#R33" rid="R33" class=" bibr popnode">33</a>], with similar demographics as BP4D-original. It corresponds to the subjects belonging to the test set of FERA 2015. These individuals underwent similar recruitment, emotion-elicitation, and video recording procedures as those in the BP4D-Train dataset. The main difference between these datasets is that the extended dataset also collected physiological data and captured thermal images of participants. However, thermal and physiological data are not included in the FERA Challenge.</p></div><div id="S12" class="sec sec-last"><p></p><h4 id="S12title" class="inline">BP4D-Test </h4><p id="P23" class="p p-first">The BP4D-Test includes digital videos of 30 participants, which was selected from a subset of BP4D+ [<a href="#R33" rid="R33" class=" bibr popnode">33</a>].</p><p id="P24" class="p p-last">In summary, there are 328 sessions from 41 subjects in the training, 159 sessions from 20 subjects in the development (a.k.a. validation), and 120 sessions from 30 subjects in the test partition. In total with 9 different views of each subject, there are 2952 videos in the training partition, 1431 videos in the development, and 1080 videos in test partition.</p></div></div><div id="S13" class="sec sec-last"><h3 id="S13title">C. Action Unit Annotation</h3><p id="P25" class="p p-first">Action Units were annotated by a team of experts. Both databases were annotated frame-by-frame for the occurrence (i.e. activation) and intensity of AUs, using the Facial Action Coding System (FACS, [<a href="#R5" rid="R5" class=" bibr popnode">5</a>]). FACS is a system for human observer coding of facial expressions, decomposing expressions into anatomically-based action units that correspond to specific facial muscles or muscle groups. Action units (AU) individually or in combinations can describe nearly all possible facial expressions.</p><div id="S14" class="sec"><p></p><h4 id="S14title" class="inline">Occurrence Annotation </h4><p id="P26" class="p p-first">For BP4D-Train, coders annotated onsets when AUs reached the A-level of intensity and offsets when they dropped below it. Segments of the most facially-expressive 20 seconds of each task were selected for coding. Across all participants, AU base occurrence rates, defined as the fraction of coded frames in which an AU occurred, averaged 35.4%, and ranged from 17% for to 59%. To assess inter-coder reliability, approximately 11% of the data was independently coded by two highly trained and certified coders. Inter-coder reliability, as quantified by the Matthews Correlation Coefficient (MCC; [<a href="#R17" rid="R17" class=" bibr popnode">17</a>]), averaged 0.91. MCC for individual AU ranged from 0.81 for AU 23 to 0.96 for AU 2. These results suggest very strong inter-coder reliability for occurrence.</p><p id="P27" class="p p-last">For BP4D-Validation and BP4D-Test, coders annotated onsets when AUs reached the B-level of intensity and offsets when they dropped below it. Segments of the most facially-expressive 20 seconds of each task were selected for coding. Across all participants, AU base rates averaged 26.2%, ranging from 5% to 60%. To assess inter-coder reliability for occurrence, approximately 15% of the data were independently comparison coded as above. Inter-coder reliability, as quantified by MCC, averaged 0.79, ranging from 0.69 to 0.91. These results indicate strong to very strong inter-rater reliability. Across all AUs except for AU 15, inter-coder reliability for occurrence was lower in the expanded dataset than in the original dataset. These differences may be due in part to differences in threshold for determining occurrence (B-level versus A-level) and the addition of two coders in BP4D-Expanded (a.k.a BP4D+).</p></div><div id="S15" class="sec sec-last"><p></p><h4 id="S15title" class="inline">Intensity Annotation </h4><p id="P28" class="p p-first-last">For BP4D-Original, seven AUs were intensity coded in the BP4D-Original dataset: AU1, AU4, AU6, AU10, AU12, AU14, and AU17. The B- and C-levels of intensity were most common for all except AU1, AU4, and AU 17, which showed more A- than C-level intensity. To assess inter-coder reliability for intensity, approximately 6% of the data was independently coded by two highly trained and certified coders. Inter-coder reliability, as quantified by the intra-class correlation coefficient (ICC; [<a href="#R23" rid="R23" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_685421024">23</a>]), averaged 0.85. ICC for individual AU ranged from 0.79 to 0.92. These results indicate strong to very strong inter-coder reliability for intensity.</p></div></div></div><div id="S16" class="tsec sec"><h2 class="head no_bottom_margin" id="S16title">IV. EVALUATION PROCEDURE</h2><p id="P29" class="p p-first">To perform a fair evaluation of participants&#x02019; performance, participants are asked to submit their working programs to the challenge organisers, who will run these programs on the held-back test set.</p><p id="P30">The evaluation will be view-independent. Participants&#x02019; working programs will be evaluated indistinctly in all the videos in the test set, and no prior information of the specific view will be given. As such, participants should consider each of the views as independent videos, although for each user and task, the annotations corresponding to the 9 views will all be the same.</p><p id="P31">The performance measure for AU occurrence is the F1-measure, which is the harmonic mean of recall and precision. For an AU with precision <em>P</em> and recall <em>R</em>, it is calculated as:
</p><div class="disp-formula" id="FD1"><div class="f"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M1" display="block" overflow="scroll"><msub><mi>F</mi><mn>1</mn></msub><mo>=</mo><mfrac><mrow><mn>2</mn><mtext mathvariant="italic">PR</mtext></mrow><mrow><mi>P</mi><mo>+</mo><mi>R</mi></mrow></mfrac></math></div><div class="l">(1)</div></div><p></p><p id="P32">The performance measure for AU intensity is the Intraclass Correlation Coefficient (ICC, [<a href="#R23" rid="R23" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_685421025">23</a>]). Given ground truth labels <strong>y</strong>, <em>y<sub>t</sub></em> &#x02208; {0, 1, &#x02026;5} and predictions <strong>&#x00177;</strong>, <em>&#x00177;<sub>t</sub></em> &#x02208; &#x1d4a9;, the ICC <em>I</em> is calculated as follows:
</p><div class="disp-formula" id="FD2"><div class="f"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M2" display="block" overflow="scroll"><mi>I</mi><mo>=</mo><mfrac><mrow><mi>W</mi><mo>&#x02212;</mo><mi>S</mi></mrow><mrow><mi>W</mi><mo>+</mo><mo stretchy="false">(</mo><mi>k</mi><mo>&#x02212;</mo><mn>1</mn><mo stretchy="false">)</mo><mi>W</mi></mrow></mfrac></math></div><div class="l">(2)</div></div><p>where <em>k</em> is the number of coding sources compared; in our case <em>k</em> = 2. <em>W</em> and <em>S</em> are the Within-target Mean Squares and Residual Sum of Squares, respectively, and are computed as follows:
</p><div class="disp-formula" id="FD3"><div class="f"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M3" display="block" overflow="scroll"><mi>W</mi><mo>=</mo><munderover><mo>&#x02211;</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><munderover><mo>&#x02211;</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mfrac><msup><mrow><mo stretchy="false">(</mo><msub><mi>y</mi><mtext mathvariant="italic">ij</mtext></msub><mo>&#x02212;</mo><msub><mover><mi>y</mi><mo>&#x000af;</mo></mover><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mn>2</mn></msup><mrow><mi>n</mi><mo stretchy="false">(</mo><mi>k</mi><mo>&#x02212;</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mfrac><mo>=</mo><munderover><mo>&#x02211;</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><munderover><mo>&#x02211;</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mfrac><msup><mrow><mo stretchy="false">(</mo><msub><mi>y</mi><mtext mathvariant="italic">ij</mtext></msub><mo>&#x02212;</mo><msub><mover><mi>y</mi><mo>&#x000af;</mo></mover><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mn>2</mn></msup><mi>n</mi></mfrac></math></div><div class="l">(3)</div></div><p>where 
<math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M4" overflow="scroll"><msub><mover><mi>y</mi><mo>&#x000af;</mo></mover><mi>i</mi></msub><mo>=</mo><msubsup><mo>&#x02211;</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></msubsup><msub><mi>y</mi><mtext mathvariant="italic">ij</mtext></msub><mo>/</mo><mi>k</mi></math> and the third term of <a href="#FD3" rid="FD3" class=" disp-formula">Eq. (3)</a> follows from <em>k</em> = 2. <em>S</em> is defined as:
</p><div class="disp-formula" id="FD4"><div class="f"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M5" display="block" overflow="scroll"><mi>S</mi><mo>=</mo><munderover><mo>&#x02211;</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msup><mrow><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>&#x02212;</mo><msub><mover><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mn>2</mn></msup></math></div><div class="l">(4)</div></div><p></p><p id="P33">To come to a single score <em>s</em> for the Occurrence Detection and Intensity Estimation Sub-Challenges, labels of all test sequences will be concatenated into a sequence to calculate F1/ICC measures per AU. The average value will be used as the performance of a participant&#x02019;s submission:
</p><div class="disp-formula" id="FD5"><div class="f"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M6" display="block" overflow="scroll"><mi>s</mi><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>&#x02211;</mo><mrow><mi>a</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>f</mi><mi>a</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">y</mi><mo>,</mo><mover><mi mathvariant="bold">y</mi><mo>^</mo></mover><mo stretchy="false">)</mo></math></div><div class="l">(5)</div></div><p>where <em>f<sub>a</sub></em> is either the F1 or ICC measure for a given AU <em>a</em>, depending on the sub-challenge, and <em>N</em> is either the 10 AUs for Occurrence Detection, or the 7 AUs for intensity estimation.</p><p id="P34">For the baseline system, a number of different performance measures are shown, given that each has its own merits, and combined they provide a deeper analysis of the results. For the Occurrence detection, the measures are the F1, the Accuracy, and the 2AFC score. Whereas F1 and Accuracy are well-known performance measurement, 2AFC is less well-known. The 2AFC score is a good approximation of the area under the receiver operator characteristic curve (AUC). In contrast to F1, 2AFC does take True Negative preditions into account. In this study the 2AFC has been calculated based on the CRF/CORF (see Section V-B for more details) likelihood values as follows:
</p><div class="disp-formula" id="FD6"><div class="f"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M7" display="block" overflow="scroll"><mn>2</mn><mtext mathvariant="italic">AFC</mtext><mo stretchy="false">(</mo><mover><mi>Y</mi><mo>^</mo></mover><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>&#x02211;</mo><mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow><mi>n</mi></munderover><munderover><mo>&#x02211;</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mi>p</mi></munderover><mi>&#x003c3;</mi><mo stretchy="false">(</mo><msub><mi>P</mi><mi>j</mi></msub><mo>,</mo><msub><mi>N</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mfrac><mn>1</mn><mrow><mi>n</mi><mo>&#x000d7;</mo><mi>p</mi></mrow></mfrac><mo>,</mo></math></div><div class="l">(6)</div></div><p>
</p><div class="disp-formula" id="FD7"><div class="f"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M8" display="block" overflow="scroll"><mi>&#x003c3;</mi><mo stretchy="false">(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="true">{</mo><mtable><mtr><mtd columnalign="left"><mn>1</mn><mo>,</mo></mtd><mtd columnalign="left"><mtext>if&#x000a0;</mtext><mi>X</mi><mo>&#x0003e;</mo><mi>Y</mi></mtd></mtr><mtr><mtd columnalign="left"><mn>0.5</mn><mo>,</mo></mtd><mtd columnalign="left"><mtext>if&#x000a0;</mtext><mi>X</mi><mo>=</mo><mo>=</mo><mi>Y</mi></mtd></mtr><mtr><mtd columnalign="left"><mn>0</mn><mo>,</mo></mtd><mtd columnalign="left"><mtext>if&#x000a0;</mtext><mi>X</mi><mo>&#x0003c;</mo><mi>Y</mi></mtd></mtr></mtable></math></div></div><p>where <em>&#x00176;</em> is a vector of decision function output values, <em>n</em> is the total number of true negative and <em>p</em> the total number of true positive instances in <em>&#x00176;</em>, and <em>P</em> and <em>N</em> are subsets of <em>&#x00176;</em> corresponding to all positive and negative instances, respectively.</p><p id="P35" class="p p-last">For the Intensity sub-challenge, the used measures are the Root Mean Squared Error (RMSE), the Intra-Class Correlation (ICC), and the Pearson Correlation Coefficient (PCC).</p></div><div id="S17" class="tsec sec"><h2 class="head no_bottom_margin" id="S17title">V. BASELINE SYSTEM</h2><p id="P36" class="p p-first">In this work we provide baseline recognition results on both the development and test sets, for easy comparison of participants&#x02019; systems. Contrary to previous challenges, in FERA 2017 the baseline points and features are not made publicly available, as participants are asked to submit their methods to run as standalone applications, in which all challenging tasks associated to the different views must be addressed by participants.</p><div id="S18" class="sec"><h3 id="S18title">A. Baseline Features</h3><p id="P37" class="p p-first">For the challenge baseline we used geometric features derived from tracked facial point locations. The geometric features are based on the 66 landmarks detected and subsequently tracked with the Cascaded Continuous Regression facial point detector/tracker proposed by S&#x000e1;nchez-Lozano et al. [<a href="#R18" rid="R18" class=" bibr popnode">18</a>], [<a href="#R19" rid="R19" class=" bibr popnode tag_hotlink tag_tooltip" id="__tag_687718701">19</a>]. In some cases the facial point detection failed, and therefore the points are simply set to 0. In order to compute the features the points are registered with respect to the tracker&#x02019;s Shape Model. The Shape Model consists of 24 parameters, the first four of which correspond to rigid information, whereas the last 20 correspond to pose and expression, and was built using the training partition of the 300VW database [<a href="#R22" rid="R22" class=" bibr popnode">22</a>], using both the original annotations, and the mirrored points. This way, the first non-rigid shape parameter is responsible of encoding only the pose angle [<a href="#R7" rid="R7" class=" bibr popnode">7</a>]. In order to unify the feature extraction and make it view-independent, the pose-related parameter is set to zero, and then the 19 non-rigid parameters corresponding to expression are taken as the low-dimensional representation of the shape. <a href="/pmc/articles/PMC5876027/figure/F2/" target="figure" class="fig-table-link figpopup" rid-figpopup="F2" rid-ob="ob-F2" co-legend-rid="lgnd_F2"><span>Figure 2</span></a> shows an example of a posed-face and the reconstructed shape using the 19 non-rigid parameters. Reconstructing the face using only the last 19 non-rigid parameters, and encoding the rigid parameters to zero, implies that faces are automatically registered and normalised, and pose is removed. These 19 features represent the PCA parameters that would result after applying a dimensionality reduction to the registered and normalised points. Then, a set of geometric features is extracted from the reconstructed shapes. The first 19 features are the non-rigid parameters described above. The next 19 features are composed by subtracting the parameters of the previous frame from that of the current one<sup><sup><a href="#FN1" rid="FN1" class=" fn">1</a></sup></sup>. This applies to all frames except the very first one of every session, for which these features are the same as the first 19. For the next set of features the 49 inner facial landmarks have been split into three groups representing the left eye (points 20 &#x02013; 25) and left eyebrow (points 1 &#x02013; 5), the right eye (points 26 &#x02013; 31) and right eyebrow (points 6 &#x02013; 10), and the mouth region (points 32 &#x02013; 49). For each of these groups a set of features representing Euclidean distances as well as angles in radians between points within the groups is extracted.</p><!--fig ft0--><!--fig mode=article f1--><div class="fig iconblock whole_rhythm" id="F2" co-legend-rid="lgnd_F2"><a href="/pmc/articles/PMC5876027/figure/F2/" target="figure" rid-figpopup="F2" rid-ob="ob-F2"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139903785607392" class="figure"><a class="inline_block ts_canvas" href="/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=5876027_nihms950421f2.jpg" target="tileshopwindow"><div class="ts_bar small" title="Click on image to zoom"></div><img loading="lazy" alt="An external file that holds a picture, illustration, etc.&#10;Object name is nihms950421f2.jpg" title="Click on image to zoom" class="tileshop" src="/pmc/articles/PMC5876027/bin/nihms950421f2.jpg" /></a></div><div id="largeobj_idm139903785607392" class="largeobj-link align_right" style="display: none"><a target="object" href="/pmc/articles/PMC5876027/figure/F2/?report=objectonly">Open in a separate window</a></div></a><div class="icnblk_cntnt" id="lgnd_F2"><div><a class="figpopup" href="/pmc/articles/PMC5876027/figure/F2/" target="figure" rid-figpopup="F2" rid-ob="ob-F2">Fig. 2</a></div><!--caption a7--><div class="caption"><p id="P52">Left image corresponds to a shape captured during tracking, and the right image corresponds to the normalised and frontalised shape. It can be seen that the main expression remains whilst pose has been removed</p></div></div></div><p id="P38">Distances between points within a group are computed by taking the squared L2-norm between consecutive points:
</p><div class="disp-formula" id="FD8"><div class="f"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M9" display="block" overflow="scroll"><mi>F</mi><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo><mo>=</mo><msubsup><mrow><mo stretchy="false">&#x02016;</mo><msub><mover><mi>p</mi><mo>&#x0223c;</mo></mover><mi>i</mi></msub><mo>&#x02212;</mo><msub><mover><mi>p</mi><mo>&#x0223c;</mo></mover><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">&#x02016;</mo></mrow><mn>2</mn><mn>2</mn></msubsup><mo>,</mo></math></div></div><p>
</p><div class="disp-formula" id="FD9"><div class="f"><em>i</em> = {1‥<em>N</em><sub><em>p</em></sub> − 1}</div></div><p>where <em>N<sub>p</sub></em> is the total number of points within the region, <em><math><mover accent="true"><mi>&#x070;</mi><mo>&#x0303;</mo></mover></math><sub>i</sub></em> is the point coordinates vector and <em>F</em> is the feature array of the region. Hence, for each group the number of features constructed in this manner <em>N<sub>f</sub></em> is equal to:
</p><div class="disp-formula" id="FD10"><div class="f"><em>N</em><sub><em>f</em></sub> = <em>N</em><sub><em>p</em></sub> − 1</div></div><p></p><p id="P39">The same approach is used to calculate the angles between two lines defined by two pairs of points at a time within a group, where the two pairs share one common point. For each consecutive triplet of points Euclidean distances between them are computed first, which are then used to calculate angle between the points:
</p><div class="disp-formula" id="FD11"><div class="f"><math xmlns:mml="http://www.w3.org/1998/Math/MathML" id="M12" display="block" overflow="scroll"><mi>F</mi><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>arccos&#x000a0;</mtext><mo stretchy="true">(</mo><mfrac><mrow><msubsup><mover><mi>p</mi><mo>&#x0223c;</mo></mover><mn>12</mn><mn>2</mn></msubsup><mo>+</mo><msubsup><mover><mi>p</mi><mo>&#x0223c;</mo></mover><mn>13</mn><mn>2</mn></msubsup><mo>&#x02212;</mo><msubsup><mover><mi>p</mi><mo>&#x0223c;</mo></mover><mn>23</mn><mn>2</mn></msubsup></mrow><mrow><mn>2</mn><mo>&#x02217;</mo><msub><mover><mi>p</mi><mo>&#x0223c;</mo></mover><mn>12</mn></msub><mo>&#x02217;</mo><msub><mover><mi>p</mi><mo>&#x0223c;</mo></mover><mn>13</mn></msub></mrow></mfrac><mo stretchy="true">)</mo></math></div></div><p>where <em><math><mover accent="true"><mi>&#x070;</mi><mo>&#x0303;</mo></mover></math><sub>ij</sub></em> is an Euclidean distance between points <em>i</em> and <em>j</em>. The number of features extracted this way is equal to the total number of consecutive angles within the groups of points, which is equal to:
</p><div class="disp-formula" id="FD12"><div class="f"><em>N</em><sub><em>f</em></sub> = <em>N</em><sub><em>p</em></sub> − 2</div></div><p>There are thus 71 features in total extracted from the above face regions.</p><p id="P40" class="p p-last">Finally, for the last 49 features we first compute median of a set of stable points of the aligned shape, meant to be robust to change in pose and expression. We then go through all of the aligned shape points and compute Euclidean distance between them and the median. In total there are 158 geometric features extracted from every video frame in the database.</p></div><div id="S19" class="sec sec-last"><h3 id="S19title">B. Baseline Results</h3><p id="P41" class="p p-first">The baseline system is kept simple on purpose since it should be easy to interpret and simple to replicate. Contrary to previous challenge editions, we decided to model the temporal dynamics, with the aim of covering misaligned frames. The learning method for the temporal dynamics modelling is Conditional Random Field (CRF, [<a href="#R14" rid="R14" class=" bibr popnode">14</a>]), for the AU occurrence sub-challenge and Conditional Ordinal Random Field (CORF, [<a href="#R13" rid="R13" class=" bibr popnode">13</a>]), for the intensity sub-challenge using the geometric features extracted using the method described above.</p><p id="P42">We have divided the training videos into segments of 90 frames with a stride window of 30 frames. This way, given that expressions are spontaneous, we can encode short sequences. Moreover, short segments of missing frames can be compensated by the dynamics predicted by a graphical model, something that can not be done using a simple frame-by-frame estimator, which would be highly affected by the tracking system. Also, to avoid the influence of inaccurate tracked points for model training, and in order to prove the generalisation of our method to different views, we used for training only the geometric features extracted in the videos corresponding to views 5 and 6 (i.e., containing frontal faces). For each of the AUs, the training set is balanced so that the amount of samples per class is approximately the same (when possible). The dimensionality of the feature vector is 158, although it is reduced using a Correlation Feature Selection (CFS) method.</p><p id="P43">At test time, videos are evaluated following the same process: 90-frames windows are evaluated by the CRF/CORF model, with a stride of 30 frames. For each of the windows, inference returns the likelihood of the chosen class. Then, we have three predictions per-frame, with their corresponding likelihoods. The final per-frame assignment is given by the prediction attached to the maximum likelihood.</p><p id="P44">Baseline results for occurrence/activation detection, and intensity estimation, are shown in <a href="/pmc/articles/PMC5876027/table/T2/" target="table" class="fig-table-link figpopup" rid-figpopup="T2" rid-ob="ob-T2" co-legend-rid=""><span>Table II</span></a> and <a href="/pmc/articles/PMC5876027/table/T5/" target="table" class="fig-table-link figpopup" rid-figpopup="T5" rid-ob="ob-T5" co-legend-rid=""><span>Table V</span></a> respectively, for the development and test partitions. Detection performance is measured by F1 as well as Accuracy and 2AFC scores, for the occurrence challenge, and by ICC, RMSE and PCC scores for the intensity estimation challenge. A number of different performance measures are shown since each has their own merits, and combined they provide a deeper analysis of the results. However the challenge participants will only be judged based on F1/ICC scores.</p><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap anchored whole_rhythm" id="T2"><h3>TABLE II</h3><!--caption a7--><div class="caption"><p id="P54">Baseline results for the occurrence sub-challenge on the development and test partition measured in F1 score, 2AFC and Accuracy.</p></div><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139903787667072" class="xtable"><table frame="hsides" rules="cols" class="rendered small default_table"><thead><tr><th align="center" rowspan="3" valign="middle" colspan="1">Action Unit</th><th align="center" colspan="3" valign="middle" rowspan="1">Development</th><th align="center" colspan="3" valign="middle" rowspan="1">Test</th></tr><tr><th align="center" colspan="6" valign="bottom" rowspan="1">
<hr /></th></tr><tr><th align="center" valign="middle" rowspan="1" colspan="1">F1</th><th align="center" valign="middle" rowspan="1" colspan="1">2AFC</th><th align="center" valign="middle" rowspan="1" colspan="1">Accuracy</th><th align="center" valign="middle" rowspan="1" colspan="1">F1</th><th align="center" valign="middle" rowspan="1" colspan="1">2AFC</th><th align="center" valign="middle" rowspan="1" colspan="1">Accuracy</th></tr><tr><th align="center" colspan="7" valign="bottom" rowspan="1">
<hr /></th></tr></thead><tbody><tr><td align="center" rowspan="1" colspan="1">AU1</td><td align="center" rowspan="1" colspan="1">0.154</td><td align="center" rowspan="1" colspan="1">0.560</td><td align="center" rowspan="1" colspan="1">0.570</td><td align="center" rowspan="1" colspan="1">0.147</td><td align="center" rowspan="1" colspan="1">0.543</td><td align="center" rowspan="1" colspan="1">0.530</td></tr><tr><td align="center" rowspan="1" colspan="1">AU4</td><td align="center" rowspan="1" colspan="1">0.172</td><td align="center" rowspan="1" colspan="1">0.510</td><td align="center" rowspan="1" colspan="1">0.520</td><td align="center" rowspan="1" colspan="1">0.044</td><td align="center" rowspan="1" colspan="1">0.488</td><td align="center" rowspan="1" colspan="1">0.557</td></tr><tr><td align="center" rowspan="1" colspan="1">AU6</td><td align="center" rowspan="1" colspan="1">0.564</td><td align="center" rowspan="1" colspan="1">0.473</td><td align="center" rowspan="1" colspan="1">0.676</td><td align="center" rowspan="1" colspan="1">0.630</td><td align="center" rowspan="1" colspan="1">0.488</td><td align="center" rowspan="1" colspan="1">0.662</td></tr><tr><td align="center" rowspan="1" colspan="1">AU7</td><td align="center" rowspan="1" colspan="1">0.727</td><td align="center" rowspan="1" colspan="1">0.550</td><td align="center" rowspan="1" colspan="1">0.642</td><td align="center" rowspan="1" colspan="1">0.755</td><td align="center" rowspan="1" colspan="1">0.579</td><td align="center" rowspan="1" colspan="1">0.664</td></tr><tr><td align="center" rowspan="1" colspan="1">AU10</td><td align="center" rowspan="1" colspan="1">0.692</td><td align="center" rowspan="1" colspan="1">0.649</td><td align="center" rowspan="1" colspan="1">0.638</td><td align="center" rowspan="1" colspan="1">0.758</td><td align="center" rowspan="1" colspan="1">0.684</td><td align="center" rowspan="1" colspan="1">0.671</td></tr><tr><td align="center" rowspan="1" colspan="1">AU12</td><td align="center" rowspan="1" colspan="1">0.647</td><td align="center" rowspan="1" colspan="1">0.547</td><td align="center" rowspan="1" colspan="1">0.660</td><td align="center" rowspan="1" colspan="1">0.687</td><td align="center" rowspan="1" colspan="1">0.566</td><td align="center" rowspan="1" colspan="1">0.651</td></tr><tr><td align="center" rowspan="1" colspan="1">AU14</td><td align="center" rowspan="1" colspan="1">0.622</td><td align="center" rowspan="1" colspan="1">0.507</td><td align="center" rowspan="1" colspan="1">0.622</td><td align="center" rowspan="1" colspan="1">0.668</td><td align="center" rowspan="1" colspan="1">0.523</td><td align="center" rowspan="1" colspan="1">0.615</td></tr><tr><td align="center" rowspan="1" colspan="1">AU15</td><td align="center" rowspan="1" colspan="1">0.146</td><td align="center" rowspan="1" colspan="1">0.492</td><td align="center" rowspan="1" colspan="1">0.307</td><td align="center" rowspan="1" colspan="1">0.220</td><td align="center" rowspan="1" colspan="1">0.494</td><td align="center" rowspan="1" colspan="1">0.310</td></tr><tr><td align="center" rowspan="1" colspan="1">AU17</td><td align="center" rowspan="1" colspan="1">0.224</td><td align="center" rowspan="1" colspan="1">0.506</td><td align="center" rowspan="1" colspan="1">0.485</td><td align="center" rowspan="1" colspan="1">0.274</td><td align="center" rowspan="1" colspan="1">0.503</td><td align="center" rowspan="1" colspan="1">0.522</td></tr><tr><td align="center" rowspan="1" colspan="1">AU23</td><td align="center" rowspan="1" colspan="1">0.207</td><td align="center" rowspan="1" colspan="1">0.496</td><td align="center" rowspan="1" colspan="1">0.373</td><td align="center" rowspan="1" colspan="1">0.342</td><td align="center" rowspan="1" colspan="1">0.498</td><td align="center" rowspan="1" colspan="1">0.432</td></tr><tr><td align="center" colspan="7" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">Mean</td><td align="center" rowspan="1" colspan="1">0.416</td><td align="center" rowspan="1" colspan="1">0.529</td><td align="center" rowspan="1" colspan="1">0.549</td><td align="center" rowspan="1" colspan="1">0.452</td><td align="center" rowspan="1" colspan="1">0.537</td><td align="center" rowspan="1" colspan="1">0.561</td></tr></tbody></table></div><div id="largeobj_idm139903787667072" class="largeobj-link align_right" style="display: none"><a target="object" href="/pmc/articles/PMC5876027/table/T2/?report=objectonly">Open in a separate window</a></div></div><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap anchored whole_rhythm" id="T5"><h3>TABLE V</h3><!--caption a7--><div class="caption"><p id="P57">Baseline results for the intensity sub-challenge on the development and test partition measured in RMSE, PCC and ICC.</p></div><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139903825737104" class="xtable"><table frame="hsides" rules="cols" class="rendered small default_table"><thead><tr><th align="center" rowspan="3" valign="middle" colspan="1">Action Unit</th><th align="center" colspan="3" valign="middle" rowspan="1">Development</th><th align="center" colspan="3" valign="middle" rowspan="1">Test</th></tr><tr><th align="center" colspan="6" valign="bottom" rowspan="1">
<hr /></th></tr><tr><th align="center" valign="middle" rowspan="1" colspan="1">RMSE</th><th align="center" valign="middle" rowspan="1" colspan="1">PCC</th><th align="center" valign="middle" rowspan="1" colspan="1">ICC</th><th align="center" valign="middle" rowspan="1" colspan="1">RMSE</th><th align="center" valign="middle" rowspan="1" colspan="1">PCC</th><th align="center" valign="middle" rowspan="1" colspan="1">ICC</th></tr><tr><th align="center" colspan="7" valign="bottom" rowspan="1">
<hr /></th></tr></thead><tbody><tr><td align="center" rowspan="1" colspan="1">AU1</td><td align="center" rowspan="1" colspan="1">1.006</td><td align="center" rowspan="1" colspan="1">0.097</td><td align="center" rowspan="1" colspan="1">0.082</td><td align="center" rowspan="1" colspan="1">1.082</td><td align="center" rowspan="1" colspan="1">0.040</td><td align="center" rowspan="1" colspan="1">0.035</td></tr><tr><td align="center" rowspan="1" colspan="1">AU4</td><td align="center" rowspan="1" colspan="1">1.296</td><td align="center" rowspan="1" colspan="1">0.084</td><td align="center" rowspan="1" colspan="1">0.069</td><td align="center" rowspan="1" colspan="1">1.200</td><td align="center" rowspan="1" colspan="1">&#x02212;0.007</td><td align="center" rowspan="1" colspan="1">&#x02212;0.004</td></tr><tr><td align="center" rowspan="1" colspan="1">AU6</td><td align="center" rowspan="1" colspan="1">1.648</td><td align="center" rowspan="1" colspan="1">0.429</td><td align="center" rowspan="1" colspan="1">0.429</td><td align="center" rowspan="1" colspan="1">1.604</td><td align="center" rowspan="1" colspan="1">0.463</td><td align="center" rowspan="1" colspan="1">0.461</td></tr><tr><td align="center" rowspan="1" colspan="1">AU10</td><td align="center" rowspan="1" colspan="1">1.628</td><td align="center" rowspan="1" colspan="1">0.435</td><td align="center" rowspan="1" colspan="1">0.434</td><td align="center" rowspan="1" colspan="1">1.548</td><td align="center" rowspan="1" colspan="1">0.462</td><td align="center" rowspan="1" colspan="1">0.451</td></tr><tr><td align="center" rowspan="1" colspan="1">AU12</td><td align="center" rowspan="1" colspan="1">1.345</td><td align="center" rowspan="1" colspan="1">0.543</td><td align="center" rowspan="1" colspan="1">0.540</td><td align="center" rowspan="1" colspan="1">1.339</td><td align="center" rowspan="1" colspan="1">0.518</td><td align="center" rowspan="1" colspan="1">0.518</td></tr><tr><td align="center" rowspan="1" colspan="1">AU14</td><td align="center" rowspan="1" colspan="1">1.637</td><td align="center" rowspan="1" colspan="1">0.264</td><td align="center" rowspan="1" colspan="1">0.259</td><td align="center" rowspan="1" colspan="1">1.422</td><td align="center" rowspan="1" colspan="1">0.046</td><td align="center" rowspan="1" colspan="1">0.037</td></tr><tr><td align="center" rowspan="1" colspan="1">AU17</td><td align="center" rowspan="1" colspan="1">1.256</td><td align="center" rowspan="1" colspan="1">0.052</td><td align="center" rowspan="1" colspan="1">0.005</td><td align="center" rowspan="1" colspan="1">1.626</td><td align="center" rowspan="1" colspan="1">0.024</td><td align="center" rowspan="1" colspan="1">0.020</td></tr><tr><td align="center" colspan="7" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">Mean</td><td align="center" rowspan="1" colspan="1">1.402</td><td align="center" rowspan="1" colspan="1">0.265</td><td align="center" rowspan="1" colspan="1">0.260</td><td align="center" rowspan="1" colspan="1">1.403</td><td align="center" rowspan="1" colspan="1">0.221</td><td align="center" rowspan="1" colspan="1">0.217</td></tr></tbody></table></div><div id="largeobj_idm139903825737104" class="largeobj-link align_right" style="display: none"><a target="object" href="/pmc/articles/PMC5876027/table/T5/?report=objectonly">Open in a separate window</a></div></div><p id="P45">In order to demonstrate and evaluate the generalisation capabilities of the baseline system to different views, we have also included F1 scores and Accuracy per view, which are shown in <a href="/pmc/articles/PMC5876027/table/T3/" target="table" class="fig-table-link figpopup" rid-figpopup="T3" rid-ob="ob-T3" co-legend-rid=""><span>Table III</span></a> and <a href="/pmc/articles/PMC5876027/table/T4/" target="table" class="fig-table-link figpopup" rid-figpopup="T4" rid-ob="ob-T4" co-legend-rid=""><span>Table IV</span></a>. The first row shows the percentage of frames per view that were properly detected/ tracked. However, a high percentage does not necessarily mean that the accuracy of detected points is good enough to encode facial expressions. From the results shown in <a href="/pmc/articles/PMC5876027/table/T3/" target="table" class="fig-table-link figpopup" rid-figpopup="T3" rid-ob="ob-T3" co-legend-rid=""><span>Table III</span></a>, and after visual inspection, it can be seen that videos corresponding to view 4 have results close to those of views 5 and 6, despite view 4 being non-frontal. Given that the face tracker performs well in these sequences, the frontalisation approach serves to achieve a good performance, especially given that none of the videos corresponding to view 4 were used to train the models. However, other extreme views were harder to track, and inaccurate point localisations were given, thus affecting the system&#x02019;s performance. In addition, it can be seen that the frontalisation also yields good results for the Intensity subchallenge. Results per view (RMSE and ICC) are shown in <a href="/pmc/articles/PMC5876027/table/T6/" target="table" class="fig-table-link figpopup" rid-figpopup="T6" rid-ob="ob-T6" co-legend-rid=""><span>Table VI</span></a> and <a href="/pmc/articles/PMC5876027/table/T7/" target="table" class="fig-table-link figpopup" rid-figpopup="T7" rid-ob="ob-T7" co-legend-rid=""><span>Table VII</span></a>, in which also the chance level is shown, understood as the error that is given by a naive classifier returning always the class that has the highest frequency in the training set (0 in all of them). Results show to outperform chance level, giving reasonable results. However, for AU1, AU4, and AU17, the amount of frames labelled with intensity zero is around the 90% for the development set. This makes it hard for a graphical model to be accurate<sup><sup><a href="#FN2" rid="FN2" class=" fn">2</a></sup></sup>. This explains the low MSE measured, as well as the low ICC level.</p><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap anchored whole_rhythm" id="T3"><h3>TABLE III</h3><!--caption a7--><div class="caption"><p id="P55">Baseline results for the occurrence sub-challenge on the development partition, per view</p></div><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139903783624752" class="xtable"><table frame="hsides" rules="cols" class="rendered small default_table"><tbody><tr><td align="center" rowspan="1" colspan="1"></td><td align="center" colspan="9" rowspan="1">F1 score</td></tr><tr><td align="center" colspan="10" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">View</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">2</td><td align="center" rowspan="1" colspan="1">3</td><td align="center" rowspan="1" colspan="1">4</td><td align="center" rowspan="1" colspan="1">5</td><td align="center" rowspan="1" colspan="1">6</td><td align="center" rowspan="1" colspan="1">7</td><td align="center" rowspan="1" colspan="1">8</td><td align="center" rowspan="1" colspan="1">9</td></tr><tr><td align="center" colspan="10" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">% Detected frames</td><td align="center" rowspan="1" colspan="1">66.87</td><td align="center" rowspan="1" colspan="1">98.18</td><td align="center" rowspan="1" colspan="1">99.99</td><td align="center" rowspan="1" colspan="1">99.96</td><td align="center" rowspan="1" colspan="1">100</td><td align="center" rowspan="1" colspan="1">100</td><td align="center" rowspan="1" colspan="1">88.67</td><td align="center" rowspan="1" colspan="1">98.14</td><td align="center" rowspan="1" colspan="1">99.46</td></tr><tr><td align="center" colspan="10" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">AU1</td><td align="center" rowspan="1" colspan="1">0.103</td><td align="center" rowspan="1" colspan="1">0.150</td><td align="center" rowspan="1" colspan="1">0.136</td><td align="center" rowspan="1" colspan="1">0.193</td><td align="center" rowspan="1" colspan="1">0.196</td><td align="center" rowspan="1" colspan="1">0.171</td><td align="center" rowspan="1" colspan="1">0.180</td><td align="center" rowspan="1" colspan="1">0.145</td><td align="center" rowspan="1" colspan="1">0.123</td></tr><tr><td align="center" rowspan="1" colspan="1">AU4</td><td align="center" rowspan="1" colspan="1">0.150</td><td align="center" rowspan="1" colspan="1">0.159</td><td align="center" rowspan="1" colspan="1">0.148</td><td align="center" rowspan="1" colspan="1">0.191</td><td align="center" rowspan="1" colspan="1">0.190</td><td align="center" rowspan="1" colspan="1">0.183</td><td align="center" rowspan="1" colspan="1">0.202</td><td align="center" rowspan="1" colspan="1">0.202</td><td align="center" rowspan="1" colspan="1">0.175</td></tr><tr><td align="center" rowspan="1" colspan="1">AU6</td><td align="center" rowspan="1" colspan="1">0.505</td><td align="center" rowspan="1" colspan="1">0.557</td><td align="center" rowspan="1" colspan="1">0.134</td><td align="center" rowspan="1" colspan="1">0.689</td><td align="center" rowspan="1" colspan="1">0.747</td><td align="center" rowspan="1" colspan="1">0.724</td><td align="center" rowspan="1" colspan="1">0.560</td><td align="center" rowspan="1" colspan="1">0.532</td><td align="center" rowspan="1" colspan="1">0.493</td></tr><tr><td align="center" rowspan="1" colspan="1">AU7</td><td align="center" rowspan="1" colspan="1">0.721</td><td align="center" rowspan="1" colspan="1">0.729</td><td align="center" rowspan="1" colspan="1">0.413</td><td align="center" rowspan="1" colspan="1">0.746</td><td align="center" rowspan="1" colspan="1">0.797</td><td align="center" rowspan="1" colspan="1">0.787</td><td align="center" rowspan="1" colspan="1">0.716</td><td align="center" rowspan="1" colspan="1">0.747</td><td align="center" rowspan="1" colspan="1">0.758</td></tr><tr><td align="center" rowspan="1" colspan="1">AU10</td><td align="center" rowspan="1" colspan="1">0.554</td><td align="center" rowspan="1" colspan="1">0.710</td><td align="center" rowspan="1" colspan="1">0.642</td><td align="center" rowspan="1" colspan="1">0.777</td><td align="center" rowspan="1" colspan="1">0.776</td><td align="center" rowspan="1" colspan="1">0.750</td><td align="center" rowspan="1" colspan="1">0.639</td><td align="center" rowspan="1" colspan="1">0.679</td><td align="center" rowspan="1" colspan="1">0.659</td></tr><tr><td align="center" rowspan="1" colspan="1">AU12</td><td align="center" rowspan="1" colspan="1">0.522</td><td align="center" rowspan="1" colspan="1">0.678</td><td align="center" rowspan="1" colspan="1">0.184</td><td align="center" rowspan="1" colspan="1">0.786</td><td align="center" rowspan="1" colspan="1">0.809</td><td align="center" rowspan="1" colspan="1">0.771</td><td align="center" rowspan="1" colspan="1">0.596</td><td align="center" rowspan="1" colspan="1">0.638</td><td align="center" rowspan="1" colspan="1">0.601</td></tr><tr><td align="center" rowspan="1" colspan="1">AU14</td><td align="center" rowspan="1" colspan="1">0.515</td><td align="center" rowspan="1" colspan="1">0.563</td><td align="center" rowspan="1" colspan="1">0.090</td><td align="center" rowspan="1" colspan="1">0.675</td><td align="center" rowspan="1" colspan="1">0.724</td><td align="center" rowspan="1" colspan="1">0.744</td><td align="center" rowspan="1" colspan="1">0.619</td><td align="center" rowspan="1" colspan="1">0.670</td><td align="center" rowspan="1" colspan="1">0.678</td></tr><tr><td align="center" rowspan="1" colspan="1">AU15</td><td align="center" rowspan="1" colspan="1">0.131</td><td align="center" rowspan="1" colspan="1">0.150</td><td align="center" rowspan="1" colspan="1">0.142</td><td align="center" rowspan="1" colspan="1">0.146</td><td align="center" rowspan="1" colspan="1">0.146</td><td align="center" rowspan="1" colspan="1">0.146</td><td align="center" rowspan="1" colspan="1">0.143</td><td align="center" rowspan="1" colspan="1">0.159</td><td align="center" rowspan="1" colspan="1">0.152</td></tr><tr><td align="center" rowspan="1" colspan="1">AU17</td><td align="center" rowspan="1" colspan="1">0.173</td><td align="center" rowspan="1" colspan="1">0.251</td><td align="center" rowspan="1" colspan="1">0.235</td><td align="center" rowspan="1" colspan="1">0.242</td><td align="center" rowspan="1" colspan="1">0.246</td><td align="center" rowspan="1" colspan="1">0.241</td><td align="center" rowspan="1" colspan="1">0.220</td><td align="center" rowspan="1" colspan="1">0.211</td><td align="center" rowspan="1" colspan="1">0.195</td></tr><tr><td align="center" rowspan="1" colspan="1">AU23</td><td align="center" rowspan="1" colspan="1">0.227</td><td align="center" rowspan="1" colspan="1">0.229</td><td align="center" rowspan="1" colspan="1">0.199</td><td align="center" rowspan="1" colspan="1">0.208</td><td align="center" rowspan="1" colspan="1">0.196</td><td align="center" rowspan="1" colspan="1">0.166</td><td align="center" rowspan="1" colspan="1">0.201</td><td align="center" rowspan="1" colspan="1">0.201</td><td align="center" rowspan="1" colspan="1">0.208</td></tr><tr><td align="center" colspan="10" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">Mean</td><td align="center" rowspan="1" colspan="1">0.360</td><td align="center" rowspan="1" colspan="1">0.418</td><td align="center" rowspan="1" colspan="1">0.232</td><td align="center" rowspan="1" colspan="1">0.465</td><td align="center" rowspan="1" colspan="1">0.482</td><td align="center" rowspan="1" colspan="1">0.468</td><td align="center" rowspan="1" colspan="1">0.408</td><td align="center" rowspan="1" colspan="1">0.418</td><td align="center" rowspan="1" colspan="1">0.404</td></tr><tr><td align="center" colspan="10" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1"></td><td align="center" colspan="9" rowspan="1">Accuracy</td></tr><tr><td align="center" colspan="10" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">View</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">2</td><td align="center" rowspan="1" colspan="1">3</td><td align="center" rowspan="1" colspan="1">4</td><td align="center" rowspan="1" colspan="1">5</td><td align="center" rowspan="1" colspan="1">6</td><td align="center" rowspan="1" colspan="1">7</td><td align="center" rowspan="1" colspan="1">8</td><td align="center" rowspan="1" colspan="1">9</td></tr><tr><td align="center" colspan="10" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">AU1</td><td align="center" rowspan="1" colspan="1">0.252</td><td align="center" rowspan="1" colspan="1">0.359</td><td align="center" rowspan="1" colspan="1">0.329</td><td align="center" rowspan="1" colspan="1">0.563</td><td align="center" rowspan="1" colspan="1">0.580</td><td align="center" rowspan="1" colspan="1">0.500</td><td align="center" rowspan="1" colspan="1">0.729</td><td align="center" rowspan="1" colspan="1">0.902</td><td align="center" rowspan="1" colspan="1">0.915</td></tr><tr><td align="center" rowspan="1" colspan="1">AU4</td><td align="center" rowspan="1" colspan="1">0.300</td><td align="center" rowspan="1" colspan="1">0.372</td><td align="center" rowspan="1" colspan="1">0.143</td><td align="center" rowspan="1" colspan="1">0.456</td><td align="center" rowspan="1" colspan="1">0.554</td><td align="center" rowspan="1" colspan="1">0.627</td><td align="center" rowspan="1" colspan="1">0.501</td><td align="center" rowspan="1" colspan="1">0.810</td><td align="center" rowspan="1" colspan="1">0.920</td></tr><tr><td align="center" rowspan="1" colspan="1">AU6</td><td align="center" rowspan="1" colspan="1">0.732</td><td align="center" rowspan="1" colspan="1">0.727</td><td align="center" rowspan="1" colspan="1">0.696</td><td align="center" rowspan="1" colspan="1">0.813</td><td align="center" rowspan="1" colspan="1">0.829</td><td align="center" rowspan="1" colspan="1">0.791</td><td align="center" rowspan="1" colspan="1">0.667</td><td align="center" rowspan="1" colspan="1">0.473</td><td align="center" rowspan="1" colspan="1">0.357</td></tr><tr><td align="center" rowspan="1" colspan="1">AU7</td><td align="center" rowspan="1" colspan="1">0.606</td><td align="center" rowspan="1" colspan="1">0.642</td><td align="center" rowspan="1" colspan="1">0.539</td><td align="center" rowspan="1" colspan="1">0.695</td><td align="center" rowspan="1" colspan="1">0.738</td><td align="center" rowspan="1" colspan="1">0.728</td><td align="center" rowspan="1" colspan="1">0.610</td><td align="center" rowspan="1" colspan="1">0.604</td><td align="center" rowspan="1" colspan="1">0.617</td></tr><tr><td align="center" rowspan="1" colspan="1">AU10</td><td align="center" rowspan="1" colspan="1">0.563</td><td align="center" rowspan="1" colspan="1">0.650</td><td align="center" rowspan="1" colspan="1">0.711</td><td align="center" rowspan="1" colspan="1">0.749</td><td align="center" rowspan="1" colspan="1">0.722</td><td align="center" rowspan="1" colspan="1">0.675</td><td align="center" rowspan="1" colspan="1">0.612</td><td align="center" rowspan="1" colspan="1">0.560</td><td align="center" rowspan="1" colspan="1">0.503</td></tr><tr><td align="center" rowspan="1" colspan="1">AU12</td><td align="center" rowspan="1" colspan="1">0.627</td><td align="center" rowspan="1" colspan="1">0.707</td><td align="center" rowspan="1" colspan="1">0.609</td><td align="center" rowspan="1" colspan="1">0.810</td><td align="center" rowspan="1" colspan="1">0.811</td><td align="center" rowspan="1" colspan="1">0.764</td><td align="center" rowspan="1" colspan="1">0.636</td><td align="center" rowspan="1" colspan="1">0.539</td><td align="center" rowspan="1" colspan="1">0.436</td></tr><tr><td align="center" rowspan="1" colspan="1">AU14</td><td align="center" rowspan="1" colspan="1">0.618</td><td align="center" rowspan="1" colspan="1">0.626</td><td align="center" rowspan="1" colspan="1">0.516</td><td align="center" rowspan="1" colspan="1">0.712</td><td align="center" rowspan="1" colspan="1">0.730</td><td align="center" rowspan="1" colspan="1">0.730</td><td align="center" rowspan="1" colspan="1">0.608</td><td align="center" rowspan="1" colspan="1">0.533</td><td align="center" rowspan="1" colspan="1">0.524</td></tr><tr><td align="center" rowspan="1" colspan="1">AU15</td><td align="center" rowspan="1" colspan="1">0.398</td><td align="center" rowspan="1" colspan="1">0.218</td><td align="center" rowspan="1" colspan="1">0.102</td><td align="center" rowspan="1" colspan="1">0.678</td><td align="center" rowspan="1" colspan="1">0.215</td><td align="center" rowspan="1" colspan="1">0.121</td><td align="center" rowspan="1" colspan="1">0.368</td><td align="center" rowspan="1" colspan="1">0.285</td><td align="center" rowspan="1" colspan="1">0.378</td></tr><tr><td align="center" rowspan="1" colspan="1">AU17</td><td align="center" rowspan="1" colspan="1">0.699</td><td align="center" rowspan="1" colspan="1">0.468</td><td align="center" rowspan="1" colspan="1">0.246</td><td align="center" rowspan="1" colspan="1">0.741</td><td align="center" rowspan="1" colspan="1">0.598</td><td align="center" rowspan="1" colspan="1">0.522</td><td align="center" rowspan="1" colspan="1">0.464</td><td align="center" rowspan="1" colspan="1">0.306</td><td align="center" rowspan="1" colspan="1">0.323</td></tr><tr><td align="center" rowspan="1" colspan="1">AU23</td><td align="center" rowspan="1" colspan="1">0.271</td><td align="center" rowspan="1" colspan="1">0.275</td><td align="center" rowspan="1" colspan="1">0.554</td><td align="center" rowspan="1" colspan="1">0.508</td><td align="center" rowspan="1" colspan="1">0.466</td><td align="center" rowspan="1" colspan="1">0.594</td><td align="center" rowspan="1" colspan="1">0.349</td><td align="center" rowspan="1" colspan="1">0.189</td><td align="center" rowspan="1" colspan="1">0.154</td></tr><tr><td align="center" colspan="10" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">Mean</td><td align="center" rowspan="1" colspan="1">0.507</td><td align="center" rowspan="1" colspan="1">0.505</td><td align="center" rowspan="1" colspan="1">0.444</td><td align="center" rowspan="1" colspan="1">0.673</td><td align="center" rowspan="1" colspan="1">0.624</td><td align="center" rowspan="1" colspan="1">0.605</td><td align="center" rowspan="1" colspan="1">0.554</td><td align="center" rowspan="1" colspan="1">0.520</td><td align="center" rowspan="1" colspan="1">0.513</td></tr></tbody></table></div><div id="largeobj_idm139903783624752" class="largeobj-link align_right" style="display: none"><a target="object" href="/pmc/articles/PMC5876027/table/T3/?report=objectonly">Open in a separate window</a></div></div><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap anchored whole_rhythm" id="T4"><h3>TABLE IV</h3><!--caption a7--><div class="caption"><p id="P56">Baseline results for the occurrence sub-challenge on the test partition, per view</p></div><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139903789100224" class="xtable"><table frame="hsides" rules="cols" class="rendered small default_table"><tbody><tr><td align="center" rowspan="1" colspan="1"></td><td align="center" colspan="9" rowspan="1">F1 score</td></tr><tr><td align="center" colspan="10" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">View</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">2</td><td align="center" rowspan="1" colspan="1">3</td><td align="center" rowspan="1" colspan="1">4</td><td align="center" rowspan="1" colspan="1">5</td><td align="center" rowspan="1" colspan="1">6</td><td align="center" rowspan="1" colspan="1">7</td><td align="center" rowspan="1" colspan="1">8</td><td align="center" rowspan="1" colspan="1">9</td></tr><tr><td align="center" colspan="10" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">% Detected frames</td><td align="center" rowspan="1" colspan="1">73.27</td><td align="center" rowspan="1" colspan="1">98.97</td><td align="center" rowspan="1" colspan="1">100</td><td align="center" rowspan="1" colspan="1">99.92</td><td align="center" rowspan="1" colspan="1">100</td><td align="center" rowspan="1" colspan="1">100</td><td align="center" rowspan="1" colspan="1">85.31</td><td align="center" rowspan="1" colspan="1">99.19</td><td align="center" rowspan="1" colspan="1">99.86</td></tr><tr><td align="center" colspan="10" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">AU1</td><td align="center" rowspan="1" colspan="1">0.114</td><td align="center" rowspan="1" colspan="1">0.147</td><td align="center" rowspan="1" colspan="1">0.154</td><td align="center" rowspan="1" colspan="1">0.160</td><td align="center" rowspan="1" colspan="1">0.189</td><td align="center" rowspan="1" colspan="1">0.173</td><td align="center" rowspan="1" colspan="1">0.118</td><td align="center" rowspan="1" colspan="1">0.035</td><td align="center" rowspan="1" colspan="1">0.005</td></tr><tr><td align="center" rowspan="1" colspan="1">AU4</td><td align="center" rowspan="1" colspan="1">0.044</td><td align="center" rowspan="1" colspan="1">0.043</td><td align="center" rowspan="1" colspan="1">0.055</td><td align="center" rowspan="1" colspan="1">0.041</td><td align="center" rowspan="1" colspan="1">0.032</td><td align="center" rowspan="1" colspan="1">0.037</td><td align="center" rowspan="1" colspan="1">0.047</td><td align="center" rowspan="1" colspan="1">0.041</td><td align="center" rowspan="1" colspan="1">0.015</td></tr><tr><td align="center" rowspan="1" colspan="1">AU6</td><td align="center" rowspan="1" colspan="1">0.550</td><td align="center" rowspan="1" colspan="1">0.602</td><td align="center" rowspan="1" colspan="1">0.204</td><td align="center" rowspan="1" colspan="1">0.704</td><td align="center" rowspan="1" colspan="1">0.808</td><td align="center" rowspan="1" colspan="1">0.787</td><td align="center" rowspan="1" colspan="1">0.565</td><td align="center" rowspan="1" colspan="1">0.643</td><td align="center" rowspan="1" colspan="1">0.615</td></tr><tr><td align="center" rowspan="1" colspan="1">AU7</td><td align="center" rowspan="1" colspan="1">0.742</td><td align="center" rowspan="1" colspan="1">0.770</td><td align="center" rowspan="1" colspan="1">0.329</td><td align="center" rowspan="1" colspan="1">0.788</td><td align="center" rowspan="1" colspan="1">0.837</td><td align="center" rowspan="1" colspan="1">0.840</td><td align="center" rowspan="1" colspan="1">0.758</td><td align="center" rowspan="1" colspan="1">0.777</td><td align="center" rowspan="1" colspan="1">0.779</td></tr><tr><td align="center" rowspan="1" colspan="1">AU10</td><td align="center" rowspan="1" colspan="1">0.660</td><td align="center" rowspan="1" colspan="1">0.772</td><td align="center" rowspan="1" colspan="1">0.670</td><td align="center" rowspan="1" colspan="1">0.839</td><td align="center" rowspan="1" colspan="1">0.831</td><td align="center" rowspan="1" colspan="1">0.812</td><td align="center" rowspan="1" colspan="1">0.663</td><td align="center" rowspan="1" colspan="1">0.767</td><td align="center" rowspan="1" colspan="1">0.758</td></tr><tr><td align="center" rowspan="1" colspan="1">AU12</td><td align="center" rowspan="1" colspan="1">0.609</td><td align="center" rowspan="1" colspan="1">0.702</td><td align="center" rowspan="1" colspan="1">0.261</td><td align="center" rowspan="1" colspan="1">0.811</td><td align="center" rowspan="1" colspan="1">0.800</td><td align="center" rowspan="1" colspan="1">0.798</td><td align="center" rowspan="1" colspan="1">0.609</td><td align="center" rowspan="1" colspan="1">0.698</td><td align="center" rowspan="1" colspan="1">0.678</td></tr><tr><td align="center" rowspan="1" colspan="1">AU14</td><td align="center" rowspan="1" colspan="1">0.593</td><td align="center" rowspan="1" colspan="1">0.611</td><td align="center" rowspan="1" colspan="1">0.109</td><td align="center" rowspan="1" colspan="1">0.663</td><td align="center" rowspan="1" colspan="1">0.776</td><td align="center" rowspan="1" colspan="1">0.803</td><td align="center" rowspan="1" colspan="1">0.631</td><td align="center" rowspan="1" colspan="1">0.745</td><td align="center" rowspan="1" colspan="1">0.749</td></tr><tr><td align="center" rowspan="1" colspan="1">AU15</td><td align="center" rowspan="1" colspan="1">0.162</td><td align="center" rowspan="1" colspan="1">0.232</td><td align="center" rowspan="1" colspan="1">0.227</td><td align="center" rowspan="1" colspan="1">0.147</td><td align="center" rowspan="1" colspan="1">0.225</td><td align="center" rowspan="1" colspan="1">0.229</td><td align="center" rowspan="1" colspan="1">0.230</td><td align="center" rowspan="1" colspan="1">0.236</td><td align="center" rowspan="1" colspan="1">0.237</td></tr><tr><td align="center" rowspan="1" colspan="1">AU17</td><td align="center" rowspan="1" colspan="1">0.164</td><td align="center" rowspan="1" colspan="1">0.346</td><td align="center" rowspan="1" colspan="1">0.306</td><td align="center" rowspan="1" colspan="1">0.177</td><td align="center" rowspan="1" colspan="1">0.306</td><td align="center" rowspan="1" colspan="1">0.311</td><td align="center" rowspan="1" colspan="1">0.229</td><td align="center" rowspan="1" colspan="1">0.260</td><td align="center" rowspan="1" colspan="1">0.266</td></tr><tr><td align="center" rowspan="1" colspan="1">AU23</td><td align="center" rowspan="1" colspan="1">0.373</td><td align="center" rowspan="1" colspan="1">0.371</td><td align="center" rowspan="1" colspan="1">0.313</td><td align="center" rowspan="1" colspan="1">0.278</td><td align="center" rowspan="1" colspan="1">0.317</td><td align="center" rowspan="1" colspan="1">0.268</td><td align="center" rowspan="1" colspan="1">0.316</td><td align="center" rowspan="1" colspan="1">0.366</td><td align="center" rowspan="1" colspan="1">0.368</td></tr><tr><td align="center" colspan="10" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">Mean</td><td align="center" rowspan="1" colspan="1">0.401</td><td align="center" rowspan="1" colspan="1">0.460</td><td align="center" rowspan="1" colspan="1">0.263</td><td align="center" rowspan="1" colspan="1">0.461</td><td align="center" rowspan="1" colspan="1">0.512</td><td align="center" rowspan="1" colspan="1">0.506</td><td align="center" rowspan="1" colspan="1">0.416</td><td align="center" rowspan="1" colspan="1">0.457</td><td align="center" rowspan="1" colspan="1">0.447</td></tr><tr><td align="center" colspan="10" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1"></td><td align="center" colspan="9" rowspan="1">Accuracy</td></tr><tr><td align="center" colspan="10" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">View</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">2</td><td align="center" rowspan="1" colspan="1">3</td><td align="center" rowspan="1" colspan="1">4</td><td align="center" rowspan="1" colspan="1">5</td><td align="center" rowspan="1" colspan="1">6</td><td align="center" rowspan="1" colspan="1">7</td><td align="center" rowspan="1" colspan="1">8</td><td align="center" rowspan="1" colspan="1">9</td></tr><tr><td align="center" colspan="10" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">AU1</td><td align="center" rowspan="1" colspan="1">0.251</td><td align="center" rowspan="1" colspan="1">0.331</td><td align="center" rowspan="1" colspan="1">0.403</td><td align="center" rowspan="1" colspan="1">0.361</td><td align="center" rowspan="1" colspan="1">0.505</td><td align="center" rowspan="1" colspan="1">0.438</td><td align="center" rowspan="1" colspan="1">0.641</td><td align="center" rowspan="1" colspan="1">0.912</td><td align="center" rowspan="1" colspan="1">0.932</td></tr><tr><td align="center" rowspan="1" colspan="1">AU4</td><td align="center" rowspan="1" colspan="1">0.399</td><td align="center" rowspan="1" colspan="1">0.314</td><td align="center" rowspan="1" colspan="1">0.185</td><td align="center" rowspan="1" colspan="1">0.499</td><td align="center" rowspan="1" colspan="1">0.662</td><td align="center" rowspan="1" colspan="1">0.698</td><td align="center" rowspan="1" colspan="1">0.460</td><td align="center" rowspan="1" colspan="1">0.857</td><td align="center" rowspan="1" colspan="1">0.936</td></tr><tr><td align="center" rowspan="1" colspan="1">AU6</td><td align="center" rowspan="1" colspan="1">0.637</td><td align="center" rowspan="1" colspan="1">0.700</td><td align="center" rowspan="1" colspan="1">0.601</td><td align="center" rowspan="1" colspan="1">0.779</td><td align="center" rowspan="1" colspan="1">0.832</td><td align="center" rowspan="1" colspan="1">0.805</td><td align="center" rowspan="1" colspan="1">0.621</td><td align="center" rowspan="1" colspan="1">0.526</td><td align="center" rowspan="1" colspan="1">0.456</td></tr><tr><td align="center" rowspan="1" colspan="1">AU7</td><td align="center" rowspan="1" colspan="1">0.614</td><td align="center" rowspan="1" colspan="1">0.662</td><td align="center" rowspan="1" colspan="1">0.459</td><td align="center" rowspan="1" colspan="1">0.746</td><td align="center" rowspan="1" colspan="1">0.786</td><td align="center" rowspan="1" colspan="1">0.790</td><td align="center" rowspan="1" colspan="1">0.643</td><td align="center" rowspan="1" colspan="1">0.640</td><td align="center" rowspan="1" colspan="1">0.639</td></tr><tr><td align="center" rowspan="1" colspan="1">AU10</td><td align="center" rowspan="1" colspan="1">0.595</td><td align="center" rowspan="1" colspan="1">0.678</td><td align="center" rowspan="1" colspan="1">0.656</td><td align="center" rowspan="1" colspan="1">0.786</td><td align="center" rowspan="1" colspan="1">0.754</td><td align="center" rowspan="1" colspan="1">0.718</td><td align="center" rowspan="1" colspan="1">0.587</td><td align="center" rowspan="1" colspan="1">0.643</td><td align="center" rowspan="1" colspan="1">0.619</td></tr><tr><td align="center" rowspan="1" colspan="1">AU12</td><td align="center" rowspan="1" colspan="1">0.605</td><td align="center" rowspan="1" colspan="1">0.700</td><td align="center" rowspan="1" colspan="1">0.548</td><td align="center" rowspan="1" colspan="1">0.795</td><td align="center" rowspan="1" colspan="1">0.760</td><td align="center" rowspan="1" colspan="1">0.756</td><td align="center" rowspan="1" colspan="1">0.598</td><td align="center" rowspan="1" colspan="1">0.577</td><td align="center" rowspan="1" colspan="1">0.523</td></tr><tr><td align="center" rowspan="1" colspan="1">AU14</td><td align="center" rowspan="1" colspan="1">0.583</td><td align="center" rowspan="1" colspan="1">0.607</td><td align="center" rowspan="1" colspan="1">0.423</td><td align="center" rowspan="1" colspan="1">0.652</td><td align="center" rowspan="1" colspan="1">0.736</td><td align="center" rowspan="1" colspan="1">0.757</td><td align="center" rowspan="1" colspan="1">0.581</td><td align="center" rowspan="1" colspan="1">0.599</td><td align="center" rowspan="1" colspan="1">0.599</td></tr><tr><td align="center" rowspan="1" colspan="1">AU15</td><td align="center" rowspan="1" colspan="1">0.450</td><td align="center" rowspan="1" colspan="1">0.213</td><td align="center" rowspan="1" colspan="1">0.139</td><td align="center" rowspan="1" colspan="1">0.620</td><td align="center" rowspan="1" colspan="1">0.255</td><td align="center" rowspan="1" colspan="1">0.170</td><td align="center" rowspan="1" colspan="1">0.359</td><td align="center" rowspan="1" colspan="1">0.245</td><td align="center" rowspan="1" colspan="1">0.336</td></tr><tr><td align="center" rowspan="1" colspan="1">AU17</td><td align="center" rowspan="1" colspan="1">0.715</td><td align="center" rowspan="1" colspan="1">0.564</td><td align="center" rowspan="1" colspan="1">0.353</td><td align="center" rowspan="1" colspan="1">0.753</td><td align="center" rowspan="1" colspan="1">0.665</td><td align="center" rowspan="1" colspan="1">0.559</td><td align="center" rowspan="1" colspan="1">0.476</td><td align="center" rowspan="1" colspan="1">0.249</td><td align="center" rowspan="1" colspan="1">0.361</td></tr><tr><td align="center" rowspan="1" colspan="1">AU23</td><td align="center" rowspan="1" colspan="1">0.325</td><td align="center" rowspan="1" colspan="1">0.275</td><td align="center" rowspan="1" colspan="1">0.533</td><td align="center" rowspan="1" colspan="1">0.581</td><td align="center" rowspan="1" colspan="1">0.574</td><td align="center" rowspan="1" colspan="1">0.677</td><td align="center" rowspan="1" colspan="1">0.396</td><td align="center" rowspan="1" colspan="1">0.283</td><td align="center" rowspan="1" colspan="1">0.242</td></tr><tr><td align="center" colspan="10" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">Mean</td><td align="center" rowspan="1" colspan="1">0.517</td><td align="center" rowspan="1" colspan="1">0.504</td><td align="center" rowspan="1" colspan="1">0.430</td><td align="center" rowspan="1" colspan="1">0.657</td><td align="center" rowspan="1" colspan="1">0.653</td><td align="center" rowspan="1" colspan="1">0.637</td><td align="center" rowspan="1" colspan="1">0.536</td><td align="center" rowspan="1" colspan="1">0.553</td><td align="center" rowspan="1" colspan="1">0.564</td></tr></tbody></table></div><div id="largeobj_idm139903789100224" class="largeobj-link align_right" style="display: none"><a target="object" href="/pmc/articles/PMC5876027/table/T4/?report=objectonly">Open in a separate window</a></div></div><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap anchored whole_rhythm" id="T6"><h3>TABLE VI</h3><!--caption a7--><div class="caption"><p id="P58">Baseline results for the intensity sub-challenge on the development partition, per view</p></div><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139903779795024" class="xtable"><table frame="hsides" rules="cols" class="rendered small default_table"><thead><tr><th align="center" colspan="2" rowspan="1">% Detected frames</th><th align="center" rowspan="1" colspan="1">66.87</th><th align="center" rowspan="1" colspan="1">98.18</th><th align="center" rowspan="1" colspan="1">99.99</th><th align="center" rowspan="1" colspan="1">99.96</th><th align="center" rowspan="1" colspan="1">100</th><th align="center" rowspan="1" colspan="1">100</th><th align="center" rowspan="1" colspan="1">88.67</th><th align="center" rowspan="1" colspan="1">98.14</th><th align="center" rowspan="1" colspan="1">99.46</th></tr><tr><th align="center" colspan="11" valign="bottom" rowspan="1">
<hr /></th></tr></thead><tbody><tr><td align="center" rowspan="1" colspan="1"></td><td align="center" colspan="10" rowspan="1">RMSE</td></tr><tr><td align="center" colspan="11" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">View</td><td align="center" rowspan="1" colspan="1">Chance</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">2</td><td align="center" rowspan="1" colspan="1">3</td><td align="center" rowspan="1" colspan="1">4</td><td align="center" rowspan="1" colspan="1">5</td><td align="center" rowspan="1" colspan="1">6</td><td align="center" rowspan="1" colspan="1">7</td><td align="center" rowspan="1" colspan="1">8</td><td align="center" rowspan="1" colspan="1">9</td></tr><tr><td align="center" colspan="11" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">AU1</td><td align="center" rowspan="1" colspan="1">0.485</td><td align="center" rowspan="1" colspan="1">1.005</td><td align="center" rowspan="1" colspan="1">1.019</td><td align="center" rowspan="1" colspan="1">0.958</td><td align="center" rowspan="1" colspan="1">0.871</td><td align="center" rowspan="1" colspan="1">0.772</td><td align="center" rowspan="1" colspan="1">0.962</td><td align="center" rowspan="1" colspan="1">1.069</td><td align="center" rowspan="1" colspan="1">0.924</td><td align="center" rowspan="1" colspan="1">1.369</td></tr><tr><td align="center" rowspan="1" colspan="1">AU4</td><td align="center" rowspan="1" colspan="1">0.532</td><td align="center" rowspan="1" colspan="1">1.246</td><td align="center" rowspan="1" colspan="1">1.416</td><td align="center" rowspan="1" colspan="1">1.287</td><td align="center" rowspan="1" colspan="1">1.090</td><td align="center" rowspan="1" colspan="1">1.012</td><td align="center" rowspan="1" colspan="1">1.028</td><td align="center" rowspan="1" colspan="1">1.431</td><td align="center" rowspan="1" colspan="1">1.630</td><td align="center" rowspan="1" colspan="1">1.390</td></tr><tr><td align="center" rowspan="1" colspan="1">AU6</td><td align="center" rowspan="1" colspan="1">1.633</td><td align="center" rowspan="1" colspan="1">1.526</td><td align="center" rowspan="1" colspan="1">1.728</td><td align="center" rowspan="1" colspan="1">1.402</td><td align="center" rowspan="1" colspan="1">1.414</td><td align="center" rowspan="1" colspan="1">1.469</td><td align="center" rowspan="1" colspan="1">1.731</td><td align="center" rowspan="1" colspan="1">1.693</td><td align="center" rowspan="1" colspan="1">1.780</td><td align="center" rowspan="1" colspan="1">1.998</td></tr><tr><td align="center" rowspan="1" colspan="1">AU10</td><td align="center" rowspan="1" colspan="1">1.913</td><td align="center" rowspan="1" colspan="1">1.646</td><td align="center" rowspan="1" colspan="1">1.720</td><td align="center" rowspan="1" colspan="1">1.477</td><td align="center" rowspan="1" colspan="1">1.246</td><td align="center" rowspan="1" colspan="1">1.346</td><td align="center" rowspan="1" colspan="1">1.607</td><td align="center" rowspan="1" colspan="1">1.624</td><td align="center" rowspan="1" colspan="1">1.616</td><td align="center" rowspan="1" colspan="1">2.192</td></tr><tr><td align="center" rowspan="1" colspan="1">AU12</td><td align="center" rowspan="1" colspan="1">1.860</td><td align="center" rowspan="1" colspan="1">1.612</td><td align="center" rowspan="1" colspan="1">1.353</td><td align="center" rowspan="1" colspan="1">1.329</td><td align="center" rowspan="1" colspan="1">1.048</td><td align="center" rowspan="1" colspan="1">1.100</td><td align="center" rowspan="1" colspan="1">1.302</td><td align="center" rowspan="1" colspan="1">1.466</td><td align="center" rowspan="1" colspan="1">1.245</td><td align="center" rowspan="1" colspan="1">1.542</td></tr><tr><td align="center" rowspan="1" colspan="1">AU14</td><td align="center" rowspan="1" colspan="1">1.923</td><td align="center" rowspan="1" colspan="1">1.735</td><td align="center" rowspan="1" colspan="1">1.620</td><td align="center" rowspan="1" colspan="1">1.693</td><td align="center" rowspan="1" colspan="1">1.616</td><td align="center" rowspan="1" colspan="1">1.550</td><td align="center" rowspan="1" colspan="1">1.496</td><td align="center" rowspan="1" colspan="1">1.679</td><td align="center" rowspan="1" colspan="1">1.584</td><td align="center" rowspan="1" colspan="1">1.742</td></tr><tr><td align="center" rowspan="1" colspan="1">AU17</td><td align="center" rowspan="1" colspan="1">0.793</td><td align="center" rowspan="1" colspan="1">0.948</td><td align="center" rowspan="1" colspan="1">1.255</td><td align="center" rowspan="1" colspan="1">1.591</td><td align="center" rowspan="1" colspan="1">0.847</td><td align="center" rowspan="1" colspan="1">0.972</td><td align="center" rowspan="1" colspan="1">0.929</td><td align="center" rowspan="1" colspan="1">1.122</td><td align="center" rowspan="1" colspan="1">1.399</td><td align="center" rowspan="1" colspan="1">1.859</td></tr><tr><td align="center" colspan="11" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">Mean</td><td align="center" rowspan="1" colspan="1">1.306</td><td align="center" rowspan="1" colspan="1">1.388</td><td align="center" rowspan="1" colspan="1">1.444</td><td align="center" rowspan="1" colspan="1">1.391</td><td align="center" rowspan="1" colspan="1">1.162</td><td align="center" rowspan="1" colspan="1">1.174</td><td align="center" rowspan="1" colspan="1">1.294</td><td align="center" rowspan="1" colspan="1">1.441</td><td align="center" rowspan="1" colspan="1">1.454</td><td align="center" rowspan="1" colspan="1">1.727</td></tr><tr><td align="center" colspan="11" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1"></td><td align="center" colspan="10" rowspan="1">ICC</td></tr><tr><td align="center" colspan="11" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">View</td><td align="center" rowspan="1" colspan="1">Chance</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">2</td><td align="center" rowspan="1" colspan="1">3</td><td align="center" rowspan="1" colspan="1">4</td><td align="center" rowspan="1" colspan="1">5</td><td align="center" rowspan="1" colspan="1">6</td><td align="center" rowspan="1" colspan="1">7</td><td align="center" rowspan="1" colspan="1">8</td><td align="center" rowspan="1" colspan="1">9</td></tr><tr><td align="center" colspan="11" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">AU1</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">0.017</td><td align="center" rowspan="1" colspan="1">&#x02212;0.037</td><td align="center" rowspan="1" colspan="1">&#x02212;0.001</td><td align="center" rowspan="1" colspan="1">0.196</td><td align="center" rowspan="1" colspan="1">0.263</td><td align="center" rowspan="1" colspan="1">0.200</td><td align="center" rowspan="1" colspan="1">0.073</td><td align="center" rowspan="1" colspan="1">0.085</td><td align="center" rowspan="1" colspan="1">0.018</td></tr><tr><td align="center" rowspan="1" colspan="1">AU4</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">0.061</td><td align="center" rowspan="1" colspan="1">0.080</td><td align="center" rowspan="1" colspan="1">0.075</td><td align="center" rowspan="1" colspan="1">0.082</td><td align="center" rowspan="1" colspan="1">0.125</td><td align="center" rowspan="1" colspan="1">0.072</td><td align="center" rowspan="1" colspan="1">0.111</td><td align="center" rowspan="1" colspan="1">0.027</td><td align="center" rowspan="1" colspan="1">0.028</td></tr><tr><td align="center" rowspan="1" colspan="1">AU6</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">0.322</td><td align="center" rowspan="1" colspan="1">0.324</td><td align="center" rowspan="1" colspan="1">0.396</td><td align="center" rowspan="1" colspan="1">0.642</td><td align="center" rowspan="1" colspan="1">0.630</td><td align="center" rowspan="1" colspan="1">0.584</td><td align="center" rowspan="1" colspan="1">0.375</td><td align="center" rowspan="1" colspan="1">0.454</td><td align="center" rowspan="1" colspan="1">0.280</td></tr><tr><td align="center" rowspan="1" colspan="1">AU10</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">0.332</td><td align="center" rowspan="1" colspan="1">0.433</td><td align="center" rowspan="1" colspan="1">0.398</td><td align="center" rowspan="1" colspan="1">0.613</td><td align="center" rowspan="1" colspan="1">0.633</td><td align="center" rowspan="1" colspan="1">0.598</td><td align="center" rowspan="1" colspan="1">0.380</td><td align="center" rowspan="1" colspan="1">0.471</td><td align="center" rowspan="1" colspan="1">0.277</td></tr><tr><td align="center" rowspan="1" colspan="1">AU12</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">0.286</td><td align="center" rowspan="1" colspan="1">0.463</td><td align="center" rowspan="1" colspan="1">0.506</td><td align="center" rowspan="1" colspan="1">0.768</td><td align="center" rowspan="1" colspan="1">0.778</td><td align="center" rowspan="1" colspan="1">0.756</td><td align="center" rowspan="1" colspan="1">0.432</td><td align="center" rowspan="1" colspan="1">0.583</td><td align="center" rowspan="1" colspan="1">0.317</td></tr><tr><td align="center" rowspan="1" colspan="1">AU14</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">0.211</td><td align="center" rowspan="1" colspan="1">0.246</td><td align="center" rowspan="1" colspan="1">0.185</td><td align="center" rowspan="1" colspan="1">0.318</td><td align="center" rowspan="1" colspan="1">0.342</td><td align="center" rowspan="1" colspan="1">0.354</td><td align="center" rowspan="1" colspan="1">0.232</td><td align="center" rowspan="1" colspan="1">0.305</td><td align="center" rowspan="1" colspan="1">0.216</td></tr><tr><td align="center" rowspan="1" colspan="1">AU17</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">&#x02212;0.018</td><td align="center" rowspan="1" colspan="1">0.048</td><td align="center" rowspan="1" colspan="1">0.065</td><td align="center" rowspan="1" colspan="1">0.023</td><td align="center" rowspan="1" colspan="1">&#x02212;0.022</td><td align="center" rowspan="1" colspan="1">&#x02212;0.011</td><td align="center" rowspan="1" colspan="1">&#x02212;0.023</td><td align="center" rowspan="1" colspan="1">&#x02212;0.009</td><td align="center" rowspan="1" colspan="1">&#x02212;0.032</td></tr><tr><td align="center" colspan="11" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">Mean</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">0.173</td><td align="center" rowspan="1" colspan="1">0.222</td><td align="center" rowspan="1" colspan="1">0.232</td><td align="center" rowspan="1" colspan="1">0.377</td><td align="center" rowspan="1" colspan="1">0.392</td><td align="center" rowspan="1" colspan="1">0.365</td><td align="center" rowspan="1" colspan="1">0.226</td><td align="center" rowspan="1" colspan="1">0.274</td><td align="center" rowspan="1" colspan="1">0.158</td></tr></tbody></table></div><div id="largeobj_idm139903779795024" class="largeobj-link align_right" style="display: none"><a target="object" href="/pmc/articles/PMC5876027/table/T6/?report=objectonly">Open in a separate window</a></div></div><!--table ft1--><!--table-wrap mode="anchored" t5--><div class="table-wrap anchored whole_rhythm" id="T7"><h3>TABLE VII</h3><!--caption a7--><div class="caption"><p id="P59">Baseline results for the intensity sub-challenge on the test partition, per view</p></div><div data-largeobj="" data-largeobj-link-rid="largeobj_idm139903790401232" class="xtable"><table frame="hsides" rules="cols" class="rendered small default_table"><thead><tr><th align="center" colspan="2" rowspan="1">% Detected frames</th><th align="center" rowspan="1" colspan="1">66.87</th><th align="center" rowspan="1" colspan="1">98.18</th><th align="center" rowspan="1" colspan="1">99.99</th><th align="center" rowspan="1" colspan="1">99.96</th><th align="center" rowspan="1" colspan="1">100</th><th align="center" rowspan="1" colspan="1">100</th><th align="center" rowspan="1" colspan="1">88.67</th><th align="center" rowspan="1" colspan="1">98.14</th><th align="center" rowspan="1" colspan="1">99.46</th></tr><tr><th align="center" colspan="11" valign="bottom" rowspan="1">
<hr /></th></tr></thead><tbody><tr><td align="center" rowspan="1" colspan="1"></td><td align="center" colspan="10" rowspan="1">RMSE</td></tr><tr><td align="center" colspan="11" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">View</td><td align="center" rowspan="1" colspan="1">Chance</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">2</td><td align="center" rowspan="1" colspan="1">3</td><td align="center" rowspan="1" colspan="1">4</td><td align="center" rowspan="1" colspan="1">5</td><td align="center" rowspan="1" colspan="1">6</td><td align="center" rowspan="1" colspan="1">7</td><td align="center" rowspan="1" colspan="1">8</td><td align="center" rowspan="1" colspan="1">9</td></tr><tr><td align="center" colspan="11" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">AU1</td><td align="center" rowspan="1" colspan="1">0.523</td><td align="center" rowspan="1" colspan="1">1.036</td><td align="center" rowspan="1" colspan="1">0.875</td><td align="center" rowspan="1" colspan="1">0.955</td><td align="center" rowspan="1" colspan="1">1.233</td><td align="center" rowspan="1" colspan="1">1.044</td><td align="center" rowspan="1" colspan="1">1.245</td><td align="center" rowspan="1" colspan="1">1.046</td><td align="center" rowspan="1" colspan="1">0.946</td><td align="center" rowspan="1" colspan="1">1.278</td></tr><tr><td align="center" rowspan="1" colspan="1">AU4</td><td align="center" rowspan="1" colspan="1">0.308</td><td align="center" rowspan="1" colspan="1">1.073</td><td align="center" rowspan="1" colspan="1">1.364</td><td align="center" rowspan="1" colspan="1">1.124</td><td align="center" rowspan="1" colspan="1">0.886</td><td align="center" rowspan="1" colspan="1">0.847</td><td align="center" rowspan="1" colspan="1">0.845</td><td align="center" rowspan="1" colspan="1">1.377</td><td align="center" rowspan="1" colspan="1">1.493</td><td align="center" rowspan="1" colspan="1">1.528</td></tr><tr><td align="center" rowspan="1" colspan="1">AU6</td><td align="center" rowspan="1" colspan="1">1.641</td><td align="center" rowspan="1" colspan="1">1.642</td><td align="center" rowspan="1" colspan="1">1.553</td><td align="center" rowspan="1" colspan="1">1.315</td><td align="center" rowspan="1" colspan="1">1.518</td><td align="center" rowspan="1" colspan="1">1.502</td><td align="center" rowspan="1" colspan="1">1.609</td><td align="center" rowspan="1" colspan="1">1.715</td><td align="center" rowspan="1" colspan="1">1.706</td><td align="center" rowspan="1" colspan="1">1.824</td></tr><tr><td align="center" rowspan="1" colspan="1">AU10</td><td align="center" rowspan="1" colspan="1">1.759</td><td align="center" rowspan="1" colspan="1">1.668</td><td align="center" rowspan="1" colspan="1">1.642</td><td align="center" rowspan="1" colspan="1">1.343</td><td align="center" rowspan="1" colspan="1">1.126</td><td align="center" rowspan="1" colspan="1">1.330</td><td align="center" rowspan="1" colspan="1">1.483</td><td align="center" rowspan="1" colspan="1">1.660</td><td align="center" rowspan="1" colspan="1">1.504</td><td align="center" rowspan="1" colspan="1">2.009</td></tr><tr><td align="center" rowspan="1" colspan="1">AU12</td><td align="center" rowspan="1" colspan="1">1.765</td><td align="center" rowspan="1" colspan="1">1.606</td><td align="center" rowspan="1" colspan="1">1.217</td><td align="center" rowspan="1" colspan="1">1.334</td><td align="center" rowspan="1" colspan="1">1.203</td><td align="center" rowspan="1" colspan="1">1.255</td><td align="center" rowspan="1" colspan="1">1.344</td><td align="center" rowspan="1" colspan="1">1.519</td><td align="center" rowspan="1" colspan="1">1.215</td><td align="center" rowspan="1" colspan="1">1.296</td></tr><tr><td align="center" rowspan="1" colspan="1">AU14</td><td align="center" rowspan="1" colspan="1">0.634</td><td align="center" rowspan="1" colspan="1">1.170</td><td align="center" rowspan="1" colspan="1">1.669</td><td align="center" rowspan="1" colspan="1">1.098</td><td align="center" rowspan="1" colspan="1">1.117</td><td align="center" rowspan="1" colspan="1">1.319</td><td align="center" rowspan="1" colspan="1">1.440</td><td align="center" rowspan="1" colspan="1">1.264</td><td align="center" rowspan="1" colspan="1">1.659</td><td align="center" rowspan="1" colspan="1">1.851</td></tr><tr><td align="center" rowspan="1" colspan="1">AU17</td><td align="center" rowspan="1" colspan="1">0.665</td><td align="center" rowspan="1" colspan="1">1.199</td><td align="center" rowspan="1" colspan="1">1.358</td><td align="center" rowspan="1" colspan="1">2.216</td><td align="center" rowspan="1" colspan="1">1.107</td><td align="center" rowspan="1" colspan="1">1.186</td><td align="center" rowspan="1" colspan="1">1.324</td><td align="center" rowspan="1" colspan="1">1.756</td><td align="center" rowspan="1" colspan="1">2.135</td><td align="center" rowspan="1" colspan="1">1.889</td></tr><tr><td align="center" colspan="11" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">Mean</td><td align="center" rowspan="1" colspan="1">1.042</td><td align="center" rowspan="1" colspan="1">1.342</td><td align="center" rowspan="1" colspan="1">1.383</td><td align="center" rowspan="1" colspan="1">1.341</td><td align="center" rowspan="1" colspan="1">1.170</td><td align="center" rowspan="1" colspan="1">1.212</td><td align="center" rowspan="1" colspan="1">1.327</td><td align="center" rowspan="1" colspan="1">1.477</td><td align="center" rowspan="1" colspan="1">1.523</td><td align="center" rowspan="1" colspan="1">1.668</td></tr><tr><td align="center" colspan="11" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1"></td><td align="center" colspan="10" rowspan="1">ICC</td></tr><tr><td align="center" colspan="11" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">View</td><td align="center" rowspan="1" colspan="1">Chance</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">2</td><td align="center" rowspan="1" colspan="1">3</td><td align="center" rowspan="1" colspan="1">4</td><td align="center" rowspan="1" colspan="1">5</td><td align="center" rowspan="1" colspan="1">6</td><td align="center" rowspan="1" colspan="1">7</td><td align="center" rowspan="1" colspan="1">8</td><td align="center" rowspan="1" colspan="1">9</td></tr><tr><td align="center" colspan="11" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">AU1</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">0.006</td><td align="center" rowspan="1" colspan="1">0.104</td><td align="center" rowspan="1" colspan="1">0.087</td><td align="center" rowspan="1" colspan="1">&#x02212;0.014</td><td align="center" rowspan="1" colspan="1">0.055</td><td align="center" rowspan="1" colspan="1">0.025</td><td align="center" rowspan="1" colspan="1">&#x02212;0.020</td><td align="center" rowspan="1" colspan="1">0.035</td><td align="center" rowspan="1" colspan="1">0.060</td></tr><tr><td align="center" rowspan="1" colspan="1">AU4</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">&#x02212;0.017</td><td align="center" rowspan="1" colspan="1">&#x02212;0.002</td><td align="center" rowspan="1" colspan="1">0.004</td><td align="center" rowspan="1" colspan="1">0.003</td><td align="center" rowspan="1" colspan="1">&#x02212;0.012</td><td align="center" rowspan="1" colspan="1">0.003</td><td align="center" rowspan="1" colspan="1">&#x02212;0.028</td><td align="center" rowspan="1" colspan="1">&#x02212;0.010</td><td align="center" rowspan="1" colspan="1">0.018</td></tr><tr><td align="center" rowspan="1" colspan="1">AU6</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">0.293</td><td align="center" rowspan="1" colspan="1">0.464</td><td align="center" rowspan="1" colspan="1">0.437</td><td align="center" rowspan="1" colspan="1">0.613</td><td align="center" rowspan="1" colspan="1">0.628</td><td align="center" rowspan="1" colspan="1">0.616</td><td align="center" rowspan="1" colspan="1">0.309</td><td align="center" rowspan="1" colspan="1">0.529</td><td align="center" rowspan="1" colspan="1">0.409</td></tr><tr><td align="center" rowspan="1" colspan="1">AU10</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">0.232</td><td align="center" rowspan="1" colspan="1">0.488</td><td align="center" rowspan="1" colspan="1">0.419</td><td align="center" rowspan="1" colspan="1">0.646</td><td align="center" rowspan="1" colspan="1">0.663</td><td align="center" rowspan="1" colspan="1">0.662</td><td align="center" rowspan="1" colspan="1">0.233</td><td align="center" rowspan="1" colspan="1">0.574</td><td align="center" rowspan="1" colspan="1">0.378</td></tr><tr><td align="center" rowspan="1" colspan="1">AU12</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">0.244</td><td align="center" rowspan="1" colspan="1">0.540</td><td align="center" rowspan="1" colspan="1">0.496</td><td align="center" rowspan="1" colspan="1">0.675</td><td align="center" rowspan="1" colspan="1">0.706</td><td align="center" rowspan="1" colspan="1">0.709</td><td align="center" rowspan="1" colspan="1">0.275</td><td align="center" rowspan="1" colspan="1">0.601</td><td align="center" rowspan="1" colspan="1">0.512</td></tr><tr><td align="center" rowspan="1" colspan="1">AU14</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">0.046</td><td align="center" rowspan="1" colspan="1">0.039</td><td align="center" rowspan="1" colspan="1">0.046</td><td align="center" rowspan="1" colspan="1">&#x02212;0.019</td><td align="center" rowspan="1" colspan="1">0.050</td><td align="center" rowspan="1" colspan="1">0.066</td><td align="center" rowspan="1" colspan="1">&#x02212;0.031</td><td align="center" rowspan="1" colspan="1">0.063</td><td align="center" rowspan="1" colspan="1">0.066</td></tr><tr><td align="center" rowspan="1" colspan="1">AU17</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">&#x02212;0.027</td><td align="center" rowspan="1" colspan="1">0.035</td><td align="center" rowspan="1" colspan="1">0.092</td><td align="center" rowspan="1" colspan="1">0.055</td><td align="center" rowspan="1" colspan="1">0.019</td><td align="center" rowspan="1" colspan="1">0.015</td><td align="center" rowspan="1" colspan="1">&#x02212;0.023</td><td align="center" rowspan="1" colspan="1">0.034</td><td align="center" rowspan="1" colspan="1">0.014</td></tr><tr><td align="center" colspan="11" valign="bottom" rowspan="1">
<hr /></td></tr><tr><td align="center" rowspan="1" colspan="1">Mean</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">0.111</td><td align="center" rowspan="1" colspan="1">0.238</td><td align="center" rowspan="1" colspan="1">0.226</td><td align="center" rowspan="1" colspan="1">0.280</td><td align="center" rowspan="1" colspan="1">0.301</td><td align="center" rowspan="1" colspan="1">0.299</td><td align="center" rowspan="1" colspan="1">0.102</td><td align="center" rowspan="1" colspan="1">0.261</td><td align="center" rowspan="1" colspan="1">0.208</td></tr></tbody></table></div><div id="largeobj_idm139903790401232" class="largeobj-link align_right" style="display: none"><a target="object" href="/pmc/articles/PMC5876027/table/T7/?report=objectonly">Open in a separate window</a></div></div><p id="P46" class="p p-last">Despite the good results given for some of the views, there is still a huge gap to improve, especially for challenging views, such as view 1 and 9.</p></div></div><div id="S20" class="tsec sec"><h2 class="head no_bottom_margin" id="S20title">VI. CONCLUSION</h2><p id="P47" class="p p-first-last">In this paper we have presented the Third Facial Expression Recognition and Analysis Challenge (FERA 2017) dedicated to FACS Action Units detection and intensity estimation on the highly challenging set of data. The dataset for this challenge has been derived from the BP4D, and extended to generate an extensive set of videos comprising 9 different views. This is the first time that a FACS AU annotated dataset is focused on expression analysis under different camera views, ranging extreme poses. The challenge addresses such significant problems of the field as expression intensity estimation as well as robust detection under non-frontal head poses, or partial self-occlusions. Baseline results obtained using geometric features demonstrate a huge room for potential improvements to be brought by the challenge participants, especially corresponding to challenging views.</p></div><div id="S21" class="tsec sec"><h2 class="head no_bottom_margin" id="S21title">Acknowledgments</h2><div class="sec"><p id="P48">Support was provided in part by National Science Foundation awards CNS-1629898, CNS-1629716, CNS-1205664, CNS-1205195, IIS-1051103, and IIS-1051169, National Institutes of Health award MH 096951, and the European Union&#x02019;s Horizon 2020 research and innovation programme under grant agreement No. 645378.</p></div></div><div id="idm139903783996464" class="tsec sec"><h2 class="head no_bottom_margin" id="idm139903783996464title">Footnotes</h2><!--back/fn-group--><div class="fm-sec half_rhythm small"><p class="fn sec" id="FN1"><sup>1</sup>Note that subtracting the shape parameters is directly equivalent to subtracting the reconstructed shapes themselves</p><p class="fn sec" id="FN2"><sup>2</sup>In general, if a CRF/CORF is trained with a highly imbalanced number of training instances per class, then it is most likely to approach a naive classifier, whereas when balancing the training data, it is more likely to be less accurate</p></div></div><div id="idm139903790873440" class="tsec sec"><h2 class="head no_bottom_margin" id="idm139903790873440title">References</h2><div class="ref-list-sec sec" id="reference-list"><div class="ref-cit-blk half_rhythm" id="R1">1. <span class="element-citation">Bartlett M, Littlewort G, Frank M, Lainscsek C, Fasel I, Movellan J. Automatic recognition of facial actions in spontaneous expressions. <span><span class="ref-journal">Journal of Multimedia. </span>2006;<span class="ref-vol">1</span>(6):22–35.</span> <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Journal+of+Multimedia&amp;title=Automatic+recognition+of+facial+actions+in+spontaneous+expressions&amp;author=M+Bartlett&amp;author=G+Littlewort&amp;author=M+Frank&amp;author=C+Lainscsek&amp;author=I+Fasel&amp;volume=1&amp;issue=6&amp;publication_year=2006&amp;pages=22-35&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R2">2. <span class="element-citation">Bazzo J, Lamar M. Recognizing facial actions using Gabor wavelets with neutral face average difference; IEEE Int&#x02019;l Conf. on Automatic Face and Gesture Recognition; 2004. pp. 505–510. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Int&#x02019;l+Conf.+on+Automatic+Face+and+Gesture+Recognition&amp;title=Recognizing+facial+actions+using+Gabor+wavelets+with+neutral+face+average+difference&amp;author=J+Bazzo&amp;author=M+Lamar&amp;publication_year=2004&amp;pages=505-510&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R3">3. <span class="element-citation">Chew SW, Lucey P, Saragih S, Cohn JF, Sridharan S. In the pursuit of effective affective computing: The relationship between features and registration. <span><span class="ref-journal">IEEE Trans. Systems, Man and Cybernetics, Part B. </span>2012;<span class="ref-vol">42</span>(4):1006–1016.</span> [<a href="/pubmed/22581139" ref="reftype=pubmed&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Systems,+Man+and+Cybernetics,+Part+B&amp;title=In+the+pursuit+of+effective+affective+computing:+The+relationship+between+features+and+registration&amp;author=SW+Chew&amp;author=P+Lucey&amp;author=S+Saragih&amp;author=JF+Cohn&amp;author=S+Sridharan&amp;volume=42&amp;issue=4&amp;publication_year=2012&amp;pages=1006-1016&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R4">4. <span class="element-citation">Corneanu C, Oliu M, Cohn JF, Escalera S. Survey on rgb, thermal, and multimodal approaches for facial expression analysis: History, trends, and affect-related applications. <span><span class="ref-journal">IEEE Trans. on Pattern Analysis and Machine Intelligence. </span>2016;<span class="ref-vol">38</span>(8):1548–1568.</span> <span class="nowrap">[<a class="int-reflink" href="/pmc/articles/PMC7426891/">PMC free article</a>]</span> [<a href="/pubmed/26761193" ref="reftype=pubmed&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+on+Pattern+Analysis+and+Machine+Intelligence&amp;title=Survey+on+rgb,+thermal,+and+multimodal+approaches+for+facial+expression+analysis:+History,+trends,+and+affect-related+applications&amp;author=C+Corneanu&amp;author=M+Oliu&amp;author=JF+Cohn&amp;author=S+Escalera&amp;volume=38&amp;issue=8&amp;publication_year=2016&amp;pages=1548-1568&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R5">5. <span class="element-citation">Ekman P, Friesen W, Hager JC. Facial action coding system. <span><span class="ref-journal">A Human Face. </span>2002</span> <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=A+Human+Face&amp;title=Facial+action+coding+system&amp;author=P+Ekman&amp;author=W+Friesen&amp;author=JC+Hager&amp;publication_year=2002&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R6">6. <span class="element-citation">Girard JM, Cohn JF, De la Torre F. Estimating smile intensity: A better way. <span><span class="ref-journal">Pattern Recognition Letters. </span>2014;<span class="ref-vol">66</span>:13–21.</span> <span class="nowrap">[<a class="int-reflink" href="/pmc/articles/PMC4598946/">PMC free article</a>]</span> [<a href="/pubmed/26461205" ref="reftype=pubmed&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Pattern+Recognition+Letters&amp;title=Estimating+smile+intensity:+A+better+way&amp;author=JM+Girard&amp;author=JF+Cohn&amp;author=F+De+la+Torre&amp;volume=66&amp;publication_year=2014&amp;pages=13-21&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R7">7. <span class="element-citation">Gonz&#x000e1;lez-Jim&#x000e9;nez D, Alba-Castro J. Toward pose-invariant 2-d face recognition through point distribution models and facial symmetry. <span><span class="ref-journal">IEEE Trans. Information Forensics and Security. </span>2007;<span class="ref-vol">2</span>(3):413–429.</span> <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Information+Forensics+and+Security&amp;title=Toward+pose-invariant+2-d+face+recognition+through+point+distribution+models+and+facial+symmetry&amp;author=D+Gonz&#x000e1;lez-Jim&#x000e9;nez&amp;author=J+Alba-Castro&amp;volume=2&amp;issue=3&amp;publication_year=2007&amp;pages=413-429&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R8">8. <span class="element-citation">Gross R, Matthews I, Cohn J, Kanade T, Baker S. Multi-pie. <span><span class="ref-journal">Image and Vision Computing. </span>2010;<span class="ref-vol">28</span>(5):807–813.</span> <span class="nowrap">[<a class="int-reflink" href="/pmc/articles/PMC2873597/">PMC free article</a>]</span> [<a href="/pubmed/20490373" ref="reftype=pubmed&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Image+and+Vision+Computing&amp;title=Multi-pie&amp;author=R+Gross&amp;author=I+Matthews&amp;author=J+Cohn&amp;author=T+Kanade&amp;author=S+Baker&amp;volume=28&amp;issue=5&amp;publication_year=2010&amp;pages=807-813&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R9">9. <span class="element-citation">Hamm J, Kohler CG, Gur RC, Verma R. Automated facial action coding system for dynamic analysis of facial expressions in neuropsychiatric disorders. <span><span class="ref-journal">Journal of Neuroscience Methods. </span>2011;<span class="ref-vol">200</span>(2):237–56.</span> <span class="nowrap">[<a class="int-reflink" href="/pmc/articles/PMC3402717/">PMC free article</a>]</span> [<a href="/pubmed/21741407" ref="reftype=pubmed&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Journal+of+Neuroscience+Methods&amp;title=Automated+facial+action+coding+system+for+dynamic+analysis+of+facial+expressions+in+neuropsychiatric+disorders&amp;author=J+Hamm&amp;author=CG+Kohler&amp;author=RC+Gur&amp;author=R+Verma&amp;volume=200&amp;issue=2&amp;publication_year=2011&amp;pages=237-56&amp;pmid=21741407&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R10">10. <span class="element-citation">Jeni LA, Cohn JF, Kanade T. Dense 3d face alignment from 2d video for real-time use. <span><span class="ref-journal">Image and Vision Computing. </span>2016</span> <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Image+and+Vision+Computing&amp;title=Dense+3d+face+alignment+from+2d+video+for+real-time+use&amp;author=LA+Jeni&amp;author=JF+Cohn&amp;author=T+Kanade&amp;publication_year=2016&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R11">11. <span class="element-citation">Jeni LA, Girard JM, Cohn J, De la Torre F. Continuous au intensity estimation using localized, sparse facial feature space; IEEE Int&#x02019;l Conf. on Automatic Face and Gesture Recognition Workshop; 2013.  <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Int&#x02019;l+Conf.+on+Automatic+Face+and+Gesture+Recognition+Workshop&amp;title=Continuous+au+intensity+estimation+using+localized,+sparse+facial+feature+space&amp;author=LA+Jeni&amp;author=JM+Girard&amp;author=J+Cohn&amp;author=F+De+la+Torre&amp;publication_year=2013&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R12">12. <span class="element-citation">Kaltwang S, Rudovic O, Pantic M. Continuous pain intensity estimation from facial expressions; Proceedings of the International Symposium on Visual Computing; 2012. pp. 368–377. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+International+Symposium+on+Visual+Computing&amp;title=Continuous+pain+intensity+estimation+from+facial+expressions&amp;author=S+Kaltwang&amp;author=O+Rudovic&amp;author=M+Pantic&amp;publication_year=2012&amp;pages=368-377&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R13">13. <span class="element-citation">Kim M, Pavlovic V. Structured output ordinal regression for dynamic facial emotion intensity prediction; European Conference on Computer Vision; 2010. pp. 649–662. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=European+Conference+on+Computer+Vision&amp;title=Structured+output+ordinal+regression+for+dynamic+facial+emotion+intensity+prediction&amp;author=M+Kim&amp;author=V+Pavlovic&amp;publication_year=2010&amp;pages=649-662&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R14">14. <span class="element-citation">Lafferty J, McCallum A, Pereira F. Conditional random fields: Probabilistic models for segmenting and labeling sequence data; Proc. Intl&#x02019; Conf. on Machine Learning; 2001. pp. 282–289. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proc.+Intl&#x02019;+Conf.+on+Machine+Learning&amp;title=Conditional+random+fields:+Probabilistic+models+for+segmenting+and+labeling+sequence+data&amp;author=J+Lafferty&amp;author=A+McCallum&amp;author=F+Pereira&amp;publication_year=2001&amp;pages=282-289&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R15">15. <span class="element-citation">Mahoor MH, Cadavid S, Messinger DS, Cohn JF. A framework for automated measurement of the intensity of non-posed facial action units; IEEE Conference on Computer Vision and Pattern Recognition Workshop; 2009. pp. 74–80. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Conference+on+Computer+Vision+and+Pattern+Recognition+Workshop&amp;title=A+framework+for+automated+measurement+of+the+intensity+of+non-posed+facial+action+units&amp;author=MH+Mahoor&amp;author=S+Cadavid&amp;author=DS+Messinger&amp;author=JF+Cohn&amp;publication_year=2009&amp;pages=74-80&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R16">16. <span class="element-citation">McKeown G, Sneddon I, Curran W. Gender differences in the perceptions of genuine and simulated laughter and amused facial expressions. <span><span class="ref-journal">Emotion Review. </span>2015;<span class="ref-vol">7</span>(1):30–38.</span> <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Emotion+Review&amp;title=Gender+differences+in+the+perceptions+of+genuine+and+simulated+laughter+and+amused+facial+expressions&amp;author=G+McKeown&amp;author=I+Sneddon&amp;author=W+Curran&amp;volume=7&amp;issue=1&amp;publication_year=2015&amp;pages=30-38&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R17">17. <span class="element-citation">Powers DMW. Evaluation: From precision, recall and f-measure to roc, informedness, markedness, and correlation. <span><span class="ref-journal">Journal of Machine Learning Technologies. </span>2011;<span class="ref-vol">2</span>(1):37–63.</span> <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Journal+of+Machine+Learning+Technologies&amp;title=Evaluation:+From+precision,+recall+and+f-measure+to+roc,+informedness,+markedness,+and+correlation&amp;author=DMW+Powers&amp;volume=2&amp;issue=1&amp;publication_year=2011&amp;pages=37-63&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R18">18. <span class="element-citation">S&#x000e1;nchez-Lozano E, Martinez B, Tzimiropoulos G, Valstar M. Cascaded continuous regression for real-time incremental face tracking; European Conference on Computer Vision &#x02013; ECCV 2016, Part VIII; 2016. pp. 645–661. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=European+Conference+on+Computer+Vision+&#x02013;+ECCV+2016,+Part+VIII&amp;title=Cascaded+continuous+regression+for+real-time+incremental+face+tracking&amp;author=E+S&#x000e1;nchez-Lozano&amp;author=B+Martinez&amp;author=G+Tzimiropoulos&amp;author=M+Valstar&amp;publication_year=2016&amp;pages=645-661&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R19">19. <span class="element-citation">S&#x000e1;nchez-Lozano E, Tzimiropoulos G, Martinez B, De la Torre F, Valstar M. A functional regression approach to facial landmark tracking. <span><span class="ref-journal">CoRR. </span>2016</span> abs/1612.02203. [<a href="/pubmed/28858786" ref="reftype=pubmed&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=CoRR&amp;title=A+functional+regression+approach+to+facial+landmark+tracking&amp;author=E+S&#x000e1;nchez-Lozano&amp;author=G+Tzimiropoulos&amp;author=B+Martinez&amp;author=F+De+la+Torre&amp;author=M+Valstar&amp;publication_year=2016&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R20">20. <span class="element-citation">Savran A, Aly&#x000fc;z N, Dibeklio&#x0011f;lu H, &#x000c7;eliktutan O, G&#x000f6;kberk B, Sankur B, Akarun L.  <span class="ref-journal">European Workshop on Biometrics and Identity Management.</span> Springer; 2008. Bosphorus database for 3d face analysis; pp. 47–56. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=European+Workshop+on+Biometrics+and+Identity+Management&amp;author=A+Savran&amp;author=N+Aly&#x000fc;z&amp;author=H+Dibeklio&#x0011f;lu&amp;author=O+&#x000c7;eliktutan&amp;author=B+G&#x000f6;kberk&amp;publication_year=2008&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R21">21. <span class="element-citation">Savran A, Sankur B, Bilge MT. Regression-based intensity estimation of facial action units. <span><span class="ref-journal">Image and Vision Computing. </span>2012;<span class="ref-vol">30</span>(10):774–784.</span> <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Image+and+Vision+Computing&amp;title=Regression-based+intensity+estimation+of+facial+action+units&amp;author=A+Savran&amp;author=B+Sankur&amp;author=MT+Bilge&amp;volume=30&amp;issue=10&amp;publication_year=2012&amp;pages=774-784&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R22">22. <span class="element-citation">Shen J, Zafeiriou S, Chrysos G, Kossaifi J, Tzimiropoulos G, Pantic M. The first facial landmark tracking in-the-wild challenge: Benchmark and results; Proc. IEEE Int. Conf. Computer Vision Workshop; 2015.  <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proc.+IEEE+Int.+Conf.+Computer+Vision+Workshop&amp;title=The+first+facial+landmark+tracking+in-the-wild+challenge:+Benchmark+and+results&amp;author=J+Shen&amp;author=S+Zafeiriou&amp;author=G+Chrysos&amp;author=J+Kossaifi&amp;author=G+Tzimiropoulos&amp;publication_year=2015&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R23">23. <span class="element-citation">Shrout P, Fleiss J. Intraclass correlations: Uses in assessing rater reliability. <span><span class="ref-journal">Psychological Bulletin. </span>1979;<span class="ref-vol">86</span>(2):420–428.</span> [<a href="/pubmed/18839484" ref="reftype=pubmed&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Psychological+Bulletin&amp;title=Intraclass+correlations:+Uses+in+assessing+rater+reliability&amp;author=P+Shrout&amp;author=J+Fleiss&amp;volume=86&amp;issue=2&amp;publication_year=1979&amp;pages=420-428&amp;pmid=18839484&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R24">24. <span class="element-citation">Tian Y, Kanade T, Cohn JF. Evaluation of Gabor-wavelet-based facial action unit recognition in image sequences of increasing complexity; IEEE Int&#x02019;l Conf. on Automatic Face and Gesture Recognition; 2002. pp. 229–234. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Int&#x02019;l+Conf.+on+Automatic+Face+and+Gesture+Recognition&amp;title=Evaluation+of+Gabor-wavelet-based+facial+action+unit+recognition+in+image+sequences+of+increasing+complexity&amp;author=Y+Tian&amp;author=T+Kanade&amp;author=JF+Cohn&amp;publication_year=2002&amp;pages=229-234&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R25">25. <span class="element-citation">Valstar M.  <span class="ref-journal">Proceedings of the 2014 Workshop on Roadmapping the Future of Multimodal Interaction Research including Business Opportunities and Challenges.</span> ACM; 2014. Automatic behaviour understanding in medicine; pp. 57–60. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=Proceedings+of+the+2014+Workshop+on+Roadmapping+the+Future+of+Multimodal+Interaction+Research+including+Business+Opportunities+and+Challenges&amp;author=M+Valstar&amp;publication_year=2014&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R26">26. <span class="element-citation">Valstar MF, Almaev T, Girard JM, McKeown G, Mehu M, Yin L, Pantic M, Cohn JF.  <span class="ref-journal">Automatic Face and Gesture Recognition (FG), 2015 11th IEEE International Conference and Workshops on.</span> Vol. 6. IEEE; 2015. Fera 2015-second facial expression recognition and analysis challenge; pp. 1–8. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?title=Automatic+Face+and+Gesture+Recognition+(FG),+2015+11th+IEEE+International+Conference+and+Workshops+on&amp;author=MF+Valstar&amp;author=T+Almaev&amp;author=JM+Girard&amp;author=G+McKeown&amp;author=M+Mehu&amp;publication_year=2015&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R27">27. <span class="element-citation">Valstar MF, Jiang B, Mehu M, Pantic M, Scherer K. The first facial expression recognition and analysis challenge; IEEE Int&#x02019;l Conf. on Automatic Face and Gesture Recognition Workshop; 2011.  <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Int&#x02019;l+Conf.+on+Automatic+Face+and+Gesture+Recognition+Workshop&amp;title=The+first+facial+expression+recognition+and+analysis+challenge&amp;author=MF+Valstar&amp;author=B+Jiang&amp;author=M+Mehu&amp;author=M+Pantic&amp;author=K+Scherer&amp;publication_year=2011&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R28">28. <span class="element-citation">Valstar MF, Pantic M. Induced disgust, happiness and surprise: an addition to the MMI facial expression database; Proc. Int&#x02019;l Conf. Language Resources and Evaluation, W&#x02019;shop on EMOTION; 2010. pp. 65–70. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proc.+Int&#x02019;l+Conf.+Language+Resources+and+Evaluation,+W&#x02019;shop+on+EMOTION&amp;title=Induced+disgust,+happiness+and+surprise:+an+addition+to+the+MMI+facial+expression+database&amp;author=MF+Valstar&amp;author=M+Pantic&amp;publication_year=2010&amp;pages=65-70&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R29">29. <span class="element-citation">Wu T, Butko NJ, Ruvolo P, Whitehill JS, Bartlett M, Movellan JR. Multi-layer architectures of facial action unit recognition. <span><span class="ref-journal">IEEE Trans. Systems, Man and Cybernetics, Part B. </span>2012</span> In print. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Systems,+Man+and+Cybernetics,+Part+B&amp;title=Multi-layer+architectures+of+facial+action+unit+recognition&amp;author=T+Wu&amp;author=NJ+Butko&amp;author=P+Ruvolo&amp;author=JS+Whitehill&amp;author=M+Bartlett&amp;publication_year=2012&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R30">30. <span class="element-citation">Yang P, Liua Q, Metaxasa DN. Boosting encoded dynamic features for facial expression recognition. <span><span class="ref-journal">Pattern Recognition Letters. </span>2009;<span class="ref-vol">30</span>(2):132–139.</span> <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Pattern+Recognition+Letters&amp;title=Boosting+encoded+dynamic+features+for+facial+expression+recognition&amp;author=P+Yang&amp;author=Q+Liua&amp;author=DN+Metaxasa&amp;volume=30&amp;issue=2&amp;publication_year=2009&amp;pages=132-139&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R31">31. <span class="element-citation">Zeng Z, Pantic M, Roisman GI, Huang TS. A survey of affect recognition methods: audio, visual, and spontaneous expressions. <span><span class="ref-journal">IEEE Trans. Pattern Analysis and Machine Intelligence. </span>2009;<span class="ref-vol">31</span>(1):39–58.</span> [<a href="/pubmed/19029545" ref="reftype=pubmed&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=IEEE+Trans.+Pattern+Analysis+and+Machine+Intelligence&amp;title=A+survey+of+affect+recognition+methods:+audio,+visual,+and+spontaneous+expressions&amp;author=Z+Zeng&amp;author=M+Pantic&amp;author=GI+Roisman&amp;author=TS+Huang&amp;volume=31&amp;issue=1&amp;publication_year=2009&amp;pages=39-58&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R32">32. <span class="element-citation">Zhang X, Yin L, Cohn JF, S C, Reale M, Horowitz A, Girard JM. Bp4d-spontaneous: a high-resolution spontaneous 3d dynamic facial expression database. <span><span class="ref-journal">Image and Vision Computing. </span>2014;<span class="ref-vol">32</span>(10):692–706.</span> <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Image+and+Vision+Computing&amp;title=Bp4d-spontaneous:+a+high-resolution+spontaneous+3d+dynamic+facial+expression+database&amp;author=X+Zhang&amp;author=L+Yin&amp;author=JF+Cohn&amp;author=C+S&amp;author=M+Reale&amp;volume=32&amp;issue=10&amp;publication_year=2014&amp;pages=692-706&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div><div class="ref-cit-blk half_rhythm" id="R33">33. <span class="element-citation">Zhang Z, Girard JM, Wu Y, Zhang X, Liu P, Ciftci U, Canavan S, Reale M, Horowitz A, Yang H, Cohn J, Ji Q, Yin L. Multimodal spontaneous emotion corpus for human behavior analysis; Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; 2016. pp. 3438–3446. <span class="nowrap">[<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings+of+the+IEEE+Conference+on+Computer+Vision+and+Pattern+Recognition&amp;title=Multimodal+spontaneous+emotion+corpus+for+human+behavior+analysis&amp;author=Z+Zhang&amp;author=JM+Girard&amp;author=Y+Wu&amp;author=X+Zhang&amp;author=P+Liu&amp;publication_year=2016&amp;pages=3438-3446&amp;" ref="reftype=other&amp;article-id=5876027&amp;issue-id=309380&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></div></div></div></div><!--post-content--></div>
            
            
        
            
        </div>
        <!-- Book content -->
    </div>
    
    <div id="rightcolumn" class="four_col col last">
        <!-- Custom content above discovery portlets -->
        <div class="col6">
            
        </div>
        
        <div xmlns:np="http://ncbi.gov/portal/XSLT/namespace" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><div class="format-menu"><h2>Formats:</h2><ul><li class="selected">Article</li> | <li><a href="/pmc/articles/PMC5876027/?report=reader">PubReader</a></li> | <li class="epub-link"><a href="/pmc/articles/PMC5876027/epub/">ePub (beta)</a></li> | <li><a href="/pmc/articles/PMC5876027/pdf/nihms950421.pdf">PDF (631K)</a></li> | <li><a href="#" data-citationid="PMC5876027" class="citationexporter ctxp">Cite</a></li></ul></div></div><div xmlns:np="http://ncbi.gov/portal/XSLT/namespace" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" class="share-buttons"><h2>Share</h2><ul><li class="facebook"><a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC5876027%2F"><img src="//static.pubmed.gov/portal/portal3rc.fcgi/4160049/img/4047626" alt="Share on Facebook" />
                             Facebook
                        </a></li><li class="twitter"><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC5876027%2F&amp;text=FERA%202017%20-%20Addressing%20Head%20Pose%20in%20the%20Third%20Facial%20Expression%20Recognition%20and%20Analysis%20Challenge"><img src="//static.pubmed.gov/portal/portal3rc.fcgi/4160049/img/4047627" alt="Share on Twitter" />
                             Twitter
                        </a></li><li class="gplus"><a href="https://plus.google.com/share?url=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC5876027%2F"><img src="//static.pubmed.gov/portal/portal3rc.fcgi/4160049/img/4047628" alt="Share on Google Plus" />
                             Google+
                        </a></li></ul></div>
        
        <div id="ajax-portlets" data-pmid="29606917" data-aiid="5876027" data-aid="5876027" data-iid="309380" data-domainid="319" data-domain="nihpa" data-accid="PMC5876027" data-md5="b532d6f6d97822b8087e20f3da6a00a8"></div>
                
        <!-- Custom content below discovery portlets -->
        <div class="col7">
            
        </div>
    </div>
</div>

<!-- Custom content after all -->
<div class="col8">
    
</div>
<div class="col9">
    
</div>

<script src="/corehtml/pmc/js/jquery.scrollTo-1.4.2.js"></script>
<script>
    (function($){
        $('.skiplink').each(function(i, item){
            var href = $($(item).attr('href'));
            href.attr('tabindex', '-1').addClass('skiptarget'); // ensure the target can receive focus
            $(item).on('click', function(event){
                event.preventDefault();
                $.scrollTo(href, 0, {
                    onAfter: function(){
                        href.focus();
                    }
                });
            });
        });
    })(jQuery);
</script>



<div id="body-link-poppers"></div>
                        </div>
                        <div class="bottom">
                            
                            <div id="NCBIFooter_dynamic">
    <a id="help-desk-link" class="help_desk" href="" target="_blank">Support Center</a>
    <a id="help-desk-link" class="help_desk" href="https://support.ncbi.nlm.nih.gov/ics/support/KBList.asp?Time=2021-02-23T09:21:27-05:00&amp;Snapshot=%2Fprojects%2FPMC%2FPMCViewer@4.46&amp;Host=ptpmc102&amp;ncbi_phid=8A1B8D72034FBA010000000008470846&amp;ncbi_session=8A1B8BA203508531_1346SID&amp;from=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC5876027%2F&amp;Db=pmc&amp;folderID=132&amp;Ncbi_App=pmc&amp;Page=literature&amp;style=classic&amp;deptID=28049" target="_blank">Support Center</a>
    
</div>

                            <div class="footer" id="footer">
    
    <div class="subfooter"> </div><script type="text/javascript" src="/portal/portal3rc.fcgi/static/js/preloaderWidget.js"> </script>
    <div id="external-disclaimer" class="offscreen_noflow">
        External link. Please review our <a href="https://www.nlm.nih.gov/privacy.html">privacy policy</a>.
    </div>    
    <div id="ncbifooter" class="contact_info">      
        <div id="footer-contents-right">
            <div id="nlm_thumb_logo">
                <a href="https://www.nlm.nih.gov" title="NLM">NLM</a>
            </div>
            <div id="nih_thumb_logo">
                <a href="https://www.nih.gov" title="NIH">NIH</a>
            </div>
            <div id="hhs_thumb_logo">
                <a href="https://www.hhs.gov" title="DHHS">DHHS</a>
            </div>
            <div id="usagov_thumb_logo">
                <a href="https://www.usa.gov" title="USA.gov">USA.gov</a>
            </div>         
        </div>
        
        <div id="footer-contents-left">
            <p class="address vcard">
                <span class="url">
                    <a class="fn url newdomain" href="https://www.ncbi.nlm.nih.gov">National Center for
                        Biotechnology Information</a>,
                </span> <span class="org url newdomain"><a href="https://www.nlm.nih.gov/">U.S. National Library of Medicine</a></span>
                <span class="adr">
                    <span class="street-address">8600 Rockville Pike</span>, <span class="locality">Bethesda</span>
                    <span class="region">MD</span>, <span class="postal-code">20894</span>
                    <span class="country-name">USA</span>
                </span>
            </p>
            
            <a href="/home/about/policies.shtml">Policies and Guidelines</a> | <a href="/home/about/contact.shtml">Contact</a>
        </div>
    </div>
    <script type="text/javascript" src="/portal/portal3rc.fcgi/rlib/js/InstrumentOmnitureBaseJS/InstrumentNCBIConfigJS/InstrumentNCBIBaseJS/InstrumentPageStarterJS.js?v=1"> </script>    
    <script type="text/javascript" src="/portal/portal3rc.fcgi/static/js/hfjs2.js"> </script>
</div>
                        </div>
                    </div>
                    <!--/.page-->
                </div>
                <!--/.wrap-->
            </div><!-- /.twelve_col -->
        </div>
        <!-- /.grid -->

        <span class="PAFAppResources"></span>
        
        <!-- BESelector tab -->
        
        
        
        <noscript><img alt="statistics" src="/stat?jsdisabled=true&amp;ncbi_db=pmc&amp;ncbi_pdid=article&amp;ncbi_acc=&amp;ncbi_domain=nihpa&amp;ncbi_report=record&amp;ncbi_type=fulltext&amp;ncbi_objectid=&amp;ncbi_pcid=/articles/PMC5876027/&amp;ncbi_app=pmc" /></noscript>
        
        
        <!-- usually for JS scripts at page bottom -->
        <!--<component id="PageFixtures" label="styles"></component>-->
    

<!-- 8A1B8BA203508531_1346SID /projects/PMC/PMCViewer@4.46 ptpmc102 v4.1.r621975 Fri, Dec 18 2020 02:56:50 -->

<script type="text/javascript" src="//static.pubmed.gov/portal/portal3rc.fcgi/4160049/js/3879255/4121861/3818874/4168176/3821238/4117325/4087685/4072593/4076480/3921943/4105668/4065628.js" snapshot="pmc"></script></body>
</html>