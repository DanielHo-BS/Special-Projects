{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#等距抽样\n",
    "def dataSample(data,sample_count):\n",
    "    record_count=data.shape[0]\n",
    "    width=int(record_count/sample_count)#计算抽样间距\n",
    "    data_sample=[]\n",
    "    n=0\n",
    "    for i in range(record_count-1):\n",
    "        if i%width==0:\n",
    "            data_sample.append(data.iloc[[i]])\n",
    "            n +=1\n",
    "        if  n==sample_count:\n",
    "            break\n",
    "        \n",
    "    data_sample = np.array(data_sample)\n",
    "    return data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#等距抽样\n",
    "def dataSample2(data,sample_count):\n",
    "    record_count=data.shape[0]\n",
    "    width=int(record_count/sample_count)#计算抽样间距\n",
    "    data_sample=[]\n",
    "    n=0\n",
    "    for i in range(record_count-1):\n",
    "        if i%width==0:\n",
    "            data_sample.append(data[i])\n",
    "            n +=1\n",
    "        if  n==sample_count:\n",
    "            break\n",
    "        \n",
    "    data_sample = np.array(data_sample)\n",
    "    return data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfcombine(dfh, dfp, df, label,sample_count):\n",
    "    df = df \n",
    "    label = label\n",
    "\n",
    "\n",
    "    image_df_health = np.load(dfh)\n",
    "    image_df_pain = np.load(dfp)\n",
    "    print('orginal data')\n",
    "    print(image_df_health.shape)\n",
    "    print(image_df_pain.shape)\n",
    "    print('\\n')\n",
    "\n",
    "    image_df_health = dataSample2(image_df_health,sample_count)\n",
    "    image_df_pain = dataSample2(image_df_pain,sample_count)\n",
    "    print('smaple data')\n",
    "    print(image_df_health.shape)\n",
    "    print(image_df_pain.shape)\n",
    "    print('\\n')\n",
    "\n",
    "    labelH=[]\n",
    "    labelP=[]\n",
    "    for i in range(image_df_health.shape[0]):\n",
    "        labelH=np.append(labelH,[0,1],axis=0)\n",
    "        labelP=np.append(labelP,[1,0],axis=0)\n",
    "    labelH=np.reshape(labelH,(-1,2))\n",
    "    labelP=np.reshape(labelP,(-1,2))\n",
    "    print('label')\n",
    "    print(labelH.shape)\n",
    "    print(labelP.shape)\n",
    "    print('\\n')\n",
    "\n",
    "    image_df_health=np.append(image_df_health,image_df_pain,axis=0)\n",
    "    labelH=np.append(labelH,labelP,axis=0)\n",
    "\n",
    "    if np.array_equal(df,[]) :\n",
    "        df = image_df_health\n",
    "        label=labelH\n",
    "    else:\n",
    "        df =np.append(df, image_df_health,axis=0)\n",
    "        label=np.append(label, labelH,axis=0)\n",
    "\n",
    "\n",
    "\n",
    "    return df,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orginal data\n",
      "(5503, 128, 128, 3)\n",
      "(4761, 128, 128, 3)\n",
      "\n",
      "\n",
      "smaple data\n",
      "(350, 128, 128, 3)\n",
      "(350, 128, 128, 3)\n",
      "\n",
      "\n",
      "label\n",
      "(350, 2)\n",
      "(350, 2)\n",
      "\n",
      "\n",
      "orginal data\n",
      "(1457, 128, 128, 3)\n",
      "(7240, 128, 128, 3)\n",
      "\n",
      "\n",
      "smaple data\n",
      "(350, 128, 128, 3)\n",
      "(350, 128, 128, 3)\n",
      "\n",
      "\n",
      "label\n",
      "(350, 2)\n",
      "(350, 2)\n",
      "\n",
      "\n",
      "orginal data\n",
      "(7338, 128, 128, 3)\n",
      "(8733, 128, 128, 3)\n",
      "\n",
      "\n",
      "smaple data\n",
      "(350, 128, 128, 3)\n",
      "(350, 128, 128, 3)\n",
      "\n",
      "\n",
      "label\n",
      "(350, 2)\n",
      "(350, 2)\n",
      "\n",
      "\n",
      "orginal data\n",
      "(7555, 128, 128, 3)\n",
      "(7872, 128, 128, 3)\n",
      "\n",
      "\n",
      "smaple data\n",
      "(350, 128, 128, 3)\n",
      "(350, 128, 128, 3)\n",
      "\n",
      "\n",
      "label\n",
      "(350, 2)\n",
      "(350, 2)\n",
      "\n",
      "\n",
      "orginal data\n",
      "(4117, 128, 128, 3)\n",
      "(7653, 128, 128, 3)\n",
      "\n",
      "\n",
      "smaple data\n",
      "(350, 128, 128, 3)\n",
      "(350, 128, 128, 3)\n",
      "\n",
      "\n",
      "label\n",
      "(350, 2)\n",
      "(350, 2)\n",
      "\n",
      "\n",
      "orginal data\n",
      "(5219, 128, 128, 3)\n",
      "(4963, 128, 128, 3)\n",
      "\n",
      "\n",
      "smaple data\n",
      "(350, 128, 128, 3)\n",
      "(350, 128, 128, 3)\n",
      "\n",
      "\n",
      "label\n",
      "(350, 2)\n",
      "(350, 2)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = []\n",
    "label = []\n",
    "\n",
    "df, label = dfcombine(r'B/health_image_dataset.npy',r'B/pain_image_dataset.npy',df, label,350)\n",
    "df, label = dfcombine(r'KT/health_image_dataset.npy',r'KT/pain_image_dataset.npy',df, label,350)\n",
    "df, label = dfcombine(r'MS/health_image_dataset.npy',r'MS/pain_image_dataset.npy',df, label,350)\n",
    "df, label = dfcombine(r'SW_line/health_image_dataset.npy',r'SW_line/pain_image_dataset.npy',df, label,350)\n",
    "df, label = dfcombine(r'SW_smooth/health_image_dataset.npy',r'SW_smooth/pain_image_dataset.npy',df, label,350)\n",
    "df, label = dfcombine(r'TW/health_image_dataset.npy',r'TW/pain_image_dataset.npy',df, label,350)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4200, 128, 128, 3)\n",
      "(4200, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfcombine2(sitaH,sitaP,df,sample_count):\n",
    "    df=df\n",
    "    dfh = pd.read_csv(sitaH)\n",
    "    dfp = pd.read_csv(sitaP)\n",
    "\n",
    "    print('orginal data')\n",
    "    print(dfh.shape)\n",
    "    print(dfp.shape)\n",
    "\n",
    "    dfh=dfh.drop(labels=['frame'],axis=1)\n",
    "    dfh=dataSample(dfh,sample_count)\n",
    "    dfp=dfp.drop(labels=['frame'],axis=1)\n",
    "    dfp=dataSample(dfp,sample_count)\n",
    "\n",
    "    print('smaple data')\n",
    "    print(dfh.shape)\n",
    "    print(dfp.shape)\n",
    "\n",
    "    df.append([dfh])\n",
    "    df.append([dfp])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orginal data\n",
      "(5503, 16)\n",
      "(4761, 16)\n",
      "smaple data\n",
      "(350, 1, 15)\n",
      "(350, 1, 15)\n",
      "orginal data\n",
      "(1457, 16)\n",
      "(7240, 16)\n",
      "smaple data\n",
      "(350, 1, 15)\n",
      "(350, 1, 15)\n",
      "orginal data\n",
      "(7338, 16)\n",
      "(8733, 16)\n",
      "smaple data\n",
      "(350, 1, 15)\n",
      "(350, 1, 15)\n",
      "orginal data\n",
      "(7555, 16)\n",
      "(7872, 16)\n",
      "smaple data\n",
      "(350, 1, 15)\n",
      "(350, 1, 15)\n",
      "orginal data\n",
      "(4117, 16)\n",
      "(7653, 16)\n",
      "smaple data\n",
      "(350, 1, 15)\n",
      "(350, 1, 15)\n",
      "orginal data\n",
      "(5219, 16)\n",
      "(4963, 16)\n",
      "smaple data\n",
      "(350, 1, 15)\n",
      "(350, 1, 15)\n",
      "df_sita\n",
      "(4200, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.498051</td>\n",
       "      <td>79.149447</td>\n",
       "      <td>64.352502</td>\n",
       "      <td>17.171511</td>\n",
       "      <td>128.753684</td>\n",
       "      <td>34.074804</td>\n",
       "      <td>69.184814</td>\n",
       "      <td>64.945033</td>\n",
       "      <td>45.870153</td>\n",
       "      <td>30.277698</td>\n",
       "      <td>34.407984</td>\n",
       "      <td>115.314319</td>\n",
       "      <td>49.604237</td>\n",
       "      <td>51.579495</td>\n",
       "      <td>78.816268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.117217</td>\n",
       "      <td>59.560022</td>\n",
       "      <td>94.322761</td>\n",
       "      <td>24.882440</td>\n",
       "      <td>102.439892</td>\n",
       "      <td>52.677668</td>\n",
       "      <td>53.068137</td>\n",
       "      <td>86.553258</td>\n",
       "      <td>40.378604</td>\n",
       "      <td>41.645093</td>\n",
       "      <td>56.626140</td>\n",
       "      <td>81.728767</td>\n",
       "      <td>42.879870</td>\n",
       "      <td>81.508580</td>\n",
       "      <td>55.611550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.212402</td>\n",
       "      <td>70.226085</td>\n",
       "      <td>76.561513</td>\n",
       "      <td>19.060416</td>\n",
       "      <td>121.302772</td>\n",
       "      <td>39.636812</td>\n",
       "      <td>68.633704</td>\n",
       "      <td>65.632096</td>\n",
       "      <td>45.734200</td>\n",
       "      <td>36.924701</td>\n",
       "      <td>39.704560</td>\n",
       "      <td>103.370739</td>\n",
       "      <td>51.076687</td>\n",
       "      <td>58.764976</td>\n",
       "      <td>70.158337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.461348</td>\n",
       "      <td>51.025098</td>\n",
       "      <td>101.513554</td>\n",
       "      <td>27.884503</td>\n",
       "      <td>101.848415</td>\n",
       "      <td>50.267082</td>\n",
       "      <td>57.669395</td>\n",
       "      <td>87.207349</td>\n",
       "      <td>35.123256</td>\n",
       "      <td>51.246472</td>\n",
       "      <td>51.725556</td>\n",
       "      <td>77.027972</td>\n",
       "      <td>50.823317</td>\n",
       "      <td>79.610059</td>\n",
       "      <td>49.566624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.022072</td>\n",
       "      <td>57.990936</td>\n",
       "      <td>92.986992</td>\n",
       "      <td>23.888187</td>\n",
       "      <td>104.236163</td>\n",
       "      <td>51.875651</td>\n",
       "      <td>85.480987</td>\n",
       "      <td>58.202519</td>\n",
       "      <td>36.316494</td>\n",
       "      <td>41.111341</td>\n",
       "      <td>46.866980</td>\n",
       "      <td>92.021679</td>\n",
       "      <td>46.245227</td>\n",
       "      <td>70.755166</td>\n",
       "      <td>62.999607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195</th>\n",
       "      <td>34.979733</td>\n",
       "      <td>42.026269</td>\n",
       "      <td>102.993998</td>\n",
       "      <td>44.287579</td>\n",
       "      <td>92.888773</td>\n",
       "      <td>42.823649</td>\n",
       "      <td>79.515023</td>\n",
       "      <td>79.772644</td>\n",
       "      <td>20.712333</td>\n",
       "      <td>60.170349</td>\n",
       "      <td>50.020700</td>\n",
       "      <td>69.808951</td>\n",
       "      <td>50.862504</td>\n",
       "      <td>94.308278</td>\n",
       "      <td>34.829218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4196</th>\n",
       "      <td>34.193825</td>\n",
       "      <td>42.408194</td>\n",
       "      <td>103.397981</td>\n",
       "      <td>44.090838</td>\n",
       "      <td>92.558115</td>\n",
       "      <td>43.351047</td>\n",
       "      <td>79.120631</td>\n",
       "      <td>79.992358</td>\n",
       "      <td>20.887010</td>\n",
       "      <td>60.046934</td>\n",
       "      <td>51.178963</td>\n",
       "      <td>68.774103</td>\n",
       "      <td>50.149921</td>\n",
       "      <td>95.269801</td>\n",
       "      <td>34.580278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4197</th>\n",
       "      <td>34.775106</td>\n",
       "      <td>41.505307</td>\n",
       "      <td>103.719587</td>\n",
       "      <td>44.055830</td>\n",
       "      <td>92.834719</td>\n",
       "      <td>43.109451</td>\n",
       "      <td>77.569328</td>\n",
       "      <td>82.389387</td>\n",
       "      <td>20.041285</td>\n",
       "      <td>60.610136</td>\n",
       "      <td>49.450257</td>\n",
       "      <td>69.939607</td>\n",
       "      <td>51.329412</td>\n",
       "      <td>93.506088</td>\n",
       "      <td>35.164501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>33.727211</td>\n",
       "      <td>42.427599</td>\n",
       "      <td>103.845189</td>\n",
       "      <td>43.928071</td>\n",
       "      <td>91.977749</td>\n",
       "      <td>44.094180</td>\n",
       "      <td>75.519666</td>\n",
       "      <td>83.735295</td>\n",
       "      <td>20.745039</td>\n",
       "      <td>59.751010</td>\n",
       "      <td>51.716309</td>\n",
       "      <td>68.532682</td>\n",
       "      <td>49.550149</td>\n",
       "      <td>95.644380</td>\n",
       "      <td>34.805470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4199</th>\n",
       "      <td>34.510153</td>\n",
       "      <td>42.422612</td>\n",
       "      <td>103.067235</td>\n",
       "      <td>43.683733</td>\n",
       "      <td>93.325728</td>\n",
       "      <td>42.990539</td>\n",
       "      <td>74.197094</td>\n",
       "      <td>83.947154</td>\n",
       "      <td>21.855752</td>\n",
       "      <td>60.076696</td>\n",
       "      <td>50.475064</td>\n",
       "      <td>69.448240</td>\n",
       "      <td>50.903116</td>\n",
       "      <td>94.158797</td>\n",
       "      <td>34.938087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4200 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1           2          3           4          5   \\\n",
       "0     36.498051  79.149447   64.352502  17.171511  128.753684  34.074804   \n",
       "1     26.117217  59.560022   94.322761  24.882440  102.439892  52.677668   \n",
       "2     33.212402  70.226085   76.561513  19.060416  121.302772  39.636812   \n",
       "3     27.461348  51.025098  101.513554  27.884503  101.848415  50.267082   \n",
       "4     29.022072  57.990936   92.986992  23.888187  104.236163  51.875651   \n",
       "...         ...        ...         ...        ...         ...        ...   \n",
       "4195  34.979733  42.026269  102.993998  44.287579   92.888773  42.823649   \n",
       "4196  34.193825  42.408194  103.397981  44.090838   92.558115  43.351047   \n",
       "4197  34.775106  41.505307  103.719587  44.055830   92.834719  43.109451   \n",
       "4198  33.727211  42.427599  103.845189  43.928071   91.977749  44.094180   \n",
       "4199  34.510153  42.422612  103.067235  43.683733   93.325728  42.990539   \n",
       "\n",
       "             6          7          8          9          10          11  \\\n",
       "0     69.184814  64.945033  45.870153  30.277698  34.407984  115.314319   \n",
       "1     53.068137  86.553258  40.378604  41.645093  56.626140   81.728767   \n",
       "2     68.633704  65.632096  45.734200  36.924701  39.704560  103.370739   \n",
       "3     57.669395  87.207349  35.123256  51.246472  51.725556   77.027972   \n",
       "4     85.480987  58.202519  36.316494  41.111341  46.866980   92.021679   \n",
       "...         ...        ...        ...        ...        ...         ...   \n",
       "4195  79.515023  79.772644  20.712333  60.170349  50.020700   69.808951   \n",
       "4196  79.120631  79.992358  20.887010  60.046934  51.178963   68.774103   \n",
       "4197  77.569328  82.389387  20.041285  60.610136  49.450257   69.939607   \n",
       "4198  75.519666  83.735295  20.745039  59.751010  51.716309   68.532682   \n",
       "4199  74.197094  83.947154  21.855752  60.076696  50.475064   69.448240   \n",
       "\n",
       "             12         13         14  \n",
       "0     49.604237  51.579495  78.816268  \n",
       "1     42.879870  81.508580  55.611550  \n",
       "2     51.076687  58.764976  70.158337  \n",
       "3     50.823317  79.610059  49.566624  \n",
       "4     46.245227  70.755166  62.999607  \n",
       "...         ...        ...        ...  \n",
       "4195  50.862504  94.308278  34.829218  \n",
       "4196  50.149921  95.269801  34.580278  \n",
       "4197  51.329412  93.506088  35.164501  \n",
       "4198  49.550149  95.644380  34.805470  \n",
       "4199  50.903116  94.158797  34.938087  \n",
       "\n",
       "[4200 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sita=[]\n",
    "df_sita=dfcombine2(r'B/sitaHealth.csv',r'B/sitaPain.csv',df_sita,350)\n",
    "df_sita=dfcombine2(r'KT/sitaHealth.csv',r'KT/sitaPain.csv',df_sita,350)\n",
    "df_sita=dfcombine2(r'MS/sitaHealth.csv',r'MS/sitaPain.csv',df_sita,350)\n",
    "df_sita=dfcombine2(r'SW_line/sitaHealth.csv',r'SW_line/sitaPain.csv',df_sita,350)\n",
    "df_sita=dfcombine2(r'SW_smooth/sitaHealth.csv',r'SW_smooth/sitaPain.csv',df_sita,350)\n",
    "df_sita=dfcombine2(r'TW/sitaHealth.csv',r'TW/sitaPain.csv',df_sita,350)\n",
    "df_sita=np.array(df_sita)\n",
    "df_sita=df_sita.reshape(-1,15)\n",
    "\n",
    "print('df_sita')\n",
    "print(df_sita.shape)\n",
    "df_sita=pd.DataFrame(df_sita)\n",
    "df_sita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "(2200, 128, 128, 3)\n",
      "(2200, 2)\n",
      "validation\n",
      "(1000, 128, 128, 3)\n",
      "(1000, 2)\n",
      "test\n",
      "(1000, 128, 128, 3)\n",
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "image_df_health=df[label[:,0]==0]\n",
    "image_df_pain=df[label[:,0]==1]\n",
    "labelH=label[label[:,0]==0]\n",
    "labelP=label[label[:,0]==1]\n",
    "\n",
    "random_state=42\n",
    "A_train, A_test, b_train, b_test = train_test_split(image_df_health, labelH, test_size=20/42, random_state=random_state)\n",
    "A_validation, A_test, b_validation, b_test = train_test_split(A_test, b_test, test_size=0.5, random_state=random_state)\n",
    "\n",
    "W_train, W_test, v_train, v_test = train_test_split(image_df_pain, labelP, test_size=20/42, random_state=random_state)\n",
    "W_validation, W_test, v_validation, v_test = train_test_split(W_test, v_test, test_size=0.5, random_state=random_state)\n",
    "\n",
    "X_train=np.append(A_train, W_train,axis=0)\n",
    "X_validation=np.append(A_validation, W_validation,axis=0)\n",
    "X_test=np.append(A_test, W_test,axis=0)\n",
    "\n",
    "y_train=np.append(b_train, v_train,axis=0)\n",
    "y_validation=np.append(b_validation, v_validation,axis=0)\n",
    "y_test=np.append(b_test, v_test,axis=0)\n",
    "\n",
    "print('train')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print('validation')\n",
    "print(X_validation.shape)\n",
    "print(y_validation.shape)\n",
    "print('test')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_validation = X_validation.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /=255\n",
    "X_validation  /=255\n",
    "X_test  /=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Concatenate,Dropout\n",
    "from keras import applications\n",
    "\n",
    "def model_InceptionV3(df):\n",
    "    base_model = applications.InceptionV3(weights='imagenet', \n",
    "                                    include_top=False, \n",
    "                                    input_shape=(df.shape[1],df.shape[2],3))\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    add_model = Sequential()\n",
    "    add_model.add(base_model)\n",
    "    add_model.add(GlobalAveragePooling2D())\n",
    "    add_model.add(Dropout(0.2))\n",
    "    add_model.add(Dense(1024, activation='relu'))\n",
    "    add_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model = add_model\n",
    "\n",
    "    #adam = optimizers.Adam(lr=1e-4)\n",
    "    #model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    opt = optimizers.SGD(lr=1e-4, momentum=0.0, decay=0.0, nesterov=False)\n",
    "    #opt = optimizers.RMSprop(lr=0.0001)\n",
    "    model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Functional)    (None, 2, 2, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 23,903,010\n",
      "Trainable params: 2,100,226\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.2407 - accuracy: 0.5033\n",
      "Epoch 00001: val_loss improved from inf to 0.97669, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 900ms/step - loss: 1.2407 - accuracy: 0.5033 - val_loss: 0.9767 - val_accuracy: 0.5360\n",
      "Epoch 2/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.1820 - accuracy: 0.4680\n",
      "Epoch 00002: val_loss improved from 0.97669 to 0.90010, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 946ms/step - loss: 1.1820 - accuracy: 0.4680 - val_loss: 0.9001 - val_accuracy: 0.5560\n",
      "Epoch 3/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.1020 - accuracy: 0.5160\n",
      "Epoch 00003: val_loss improved from 0.90010 to 0.83682, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 15s 969ms/step - loss: 1.1020 - accuracy: 0.5160 - val_loss: 0.8368 - val_accuracy: 0.5740\n",
      "Epoch 4/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.0714 - accuracy: 0.5180\n",
      "Epoch 00004: val_loss improved from 0.83682 to 0.79978, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 952ms/step - loss: 1.0714 - accuracy: 0.5180 - val_loss: 0.7998 - val_accuracy: 0.5760\n",
      "Epoch 5/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.0254 - accuracy: 0.5287\n",
      "Epoch 00005: val_loss improved from 0.79978 to 0.75190, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 941ms/step - loss: 1.0254 - accuracy: 0.5287 - val_loss: 0.7519 - val_accuracy: 0.6060\n",
      "Epoch 6/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.0163 - accuracy: 0.5247\n",
      "Epoch 00006: val_loss improved from 0.75190 to 0.72048, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 953ms/step - loss: 1.0163 - accuracy: 0.5247 - val_loss: 0.7205 - val_accuracy: 0.6180\n",
      "Epoch 7/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.9163 - accuracy: 0.5573\n",
      "Epoch 00007: val_loss improved from 0.72048 to 0.69240, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 959ms/step - loss: 0.9163 - accuracy: 0.5573 - val_loss: 0.6924 - val_accuracy: 0.6340\n",
      "Epoch 8/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.9273 - accuracy: 0.5687\n",
      "Epoch 00008: val_loss improved from 0.69240 to 0.68284, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 15s 969ms/step - loss: 0.9273 - accuracy: 0.5687 - val_loss: 0.6828 - val_accuracy: 0.6320\n",
      "Epoch 9/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.9251 - accuracy: 0.5647\n",
      "Epoch 00009: val_loss improved from 0.68284 to 0.64734, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 940ms/step - loss: 0.9251 - accuracy: 0.5647 - val_loss: 0.6473 - val_accuracy: 0.6720\n",
      "Epoch 10/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.9130 - accuracy: 0.5800\n",
      "Epoch 00010: val_loss improved from 0.64734 to 0.63173, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 958ms/step - loss: 0.9130 - accuracy: 0.5800 - val_loss: 0.6317 - val_accuracy: 0.6800\n",
      "Epoch 11/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.8794 - accuracy: 0.6027\n",
      "Epoch 00011: val_loss improved from 0.63173 to 0.61593, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 15s 968ms/step - loss: 0.8794 - accuracy: 0.6027 - val_loss: 0.6159 - val_accuracy: 0.6900\n",
      "Epoch 12/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.8245 - accuracy: 0.6240\n",
      "Epoch 00012: val_loss improved from 0.61593 to 0.59859, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 949ms/step - loss: 0.8245 - accuracy: 0.6240 - val_loss: 0.5986 - val_accuracy: 0.7080\n",
      "Epoch 13/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.8250 - accuracy: 0.6113\n",
      "Epoch 00013: val_loss improved from 0.59859 to 0.58365, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 951ms/step - loss: 0.8250 - accuracy: 0.6113 - val_loss: 0.5836 - val_accuracy: 0.7160\n",
      "Epoch 14/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.8108 - accuracy: 0.6133\n",
      "Epoch 00014: val_loss improved from 0.58365 to 0.57309, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 15s 971ms/step - loss: 0.8108 - accuracy: 0.6133 - val_loss: 0.5731 - val_accuracy: 0.7260\n",
      "Epoch 15/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.7907 - accuracy: 0.6407\n",
      "Epoch 00015: val_loss improved from 0.57309 to 0.56041, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 934ms/step - loss: 0.7907 - accuracy: 0.6407 - val_loss: 0.5604 - val_accuracy: 0.7280\n",
      "Epoch 16/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.7618 - accuracy: 0.6413\n",
      "Epoch 00016: val_loss improved from 0.56041 to 0.55001, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 15s 970ms/step - loss: 0.7618 - accuracy: 0.6413 - val_loss: 0.5500 - val_accuracy: 0.7320\n",
      "Epoch 17/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.7858 - accuracy: 0.6267\n",
      "Epoch 00017: val_loss improved from 0.55001 to 0.53165, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 13s 878ms/step - loss: 0.7858 - accuracy: 0.6267 - val_loss: 0.5316 - val_accuracy: 0.7480\n",
      "Epoch 18/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.7398 - accuracy: 0.6587\n",
      "Epoch 00018: val_loss improved from 0.53165 to 0.52193, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 952ms/step - loss: 0.7398 - accuracy: 0.6587 - val_loss: 0.5219 - val_accuracy: 0.7520\n",
      "Epoch 19/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.7119 - accuracy: 0.6780\n",
      "Epoch 00019: val_loss improved from 0.52193 to 0.52059, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 922ms/step - loss: 0.7119 - accuracy: 0.6780 - val_loss: 0.5206 - val_accuracy: 0.7540\n",
      "Epoch 20/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.7591 - accuracy: 0.6420\n",
      "Epoch 00020: val_loss improved from 0.52059 to 0.50684, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 946ms/step - loss: 0.7591 - accuracy: 0.6420 - val_loss: 0.5068 - val_accuracy: 0.7660\n",
      "Epoch 21/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6957 - accuracy: 0.6733\n",
      "Epoch 00021: val_loss improved from 0.50684 to 0.49417, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 959ms/step - loss: 0.6957 - accuracy: 0.6733 - val_loss: 0.4942 - val_accuracy: 0.7700\n",
      "Epoch 22/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6958 - accuracy: 0.6767\n",
      "Epoch 00022: val_loss did not improve from 0.49417\n",
      "15/15 [==============================] - 12s 809ms/step - loss: 0.6958 - accuracy: 0.6767 - val_loss: 0.4976 - val_accuracy: 0.7780\n",
      "Epoch 23/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.7081 - accuracy: 0.6727\n",
      "Epoch 00023: val_loss improved from 0.49417 to 0.48420, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 944ms/step - loss: 0.7081 - accuracy: 0.6727 - val_loss: 0.4842 - val_accuracy: 0.7840\n",
      "Epoch 24/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6590 - accuracy: 0.6840\n",
      "Epoch 00024: val_loss improved from 0.48420 to 0.47345, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 905ms/step - loss: 0.6590 - accuracy: 0.6840 - val_loss: 0.4735 - val_accuracy: 0.7860\n",
      "Epoch 25/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6617 - accuracy: 0.6940\n",
      "Epoch 00025: val_loss did not improve from 0.47345\n",
      "15/15 [==============================] - 11s 746ms/step - loss: 0.6617 - accuracy: 0.6940 - val_loss: 0.4738 - val_accuracy: 0.7940\n",
      "Epoch 26/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6919 - accuracy: 0.6873\n",
      "Epoch 00026: val_loss improved from 0.47345 to 0.46124, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 13s 855ms/step - loss: 0.6919 - accuracy: 0.6873 - val_loss: 0.4612 - val_accuracy: 0.7960\n",
      "Epoch 27/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6217 - accuracy: 0.7133\n",
      "Epoch 00027: val_loss improved from 0.46124 to 0.45337, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 938ms/step - loss: 0.6217 - accuracy: 0.7133 - val_loss: 0.4534 - val_accuracy: 0.8020\n",
      "Epoch 28/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6497 - accuracy: 0.7047\n",
      "Epoch 00028: val_loss improved from 0.45337 to 0.44752, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 915ms/step - loss: 0.6497 - accuracy: 0.7047 - val_loss: 0.4475 - val_accuracy: 0.8140\n",
      "Epoch 29/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6516 - accuracy: 0.6980\n",
      "Epoch 00029: val_loss improved from 0.44752 to 0.44147, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 921ms/step - loss: 0.6516 - accuracy: 0.6980 - val_loss: 0.4415 - val_accuracy: 0.8180\n",
      "Epoch 30/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6423 - accuracy: 0.7087\n",
      "Epoch 00030: val_loss improved from 0.44147 to 0.43565, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 951ms/step - loss: 0.6423 - accuracy: 0.7087 - val_loss: 0.4357 - val_accuracy: 0.8200\n",
      "Epoch 31/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6332 - accuracy: 0.7193\n",
      "Epoch 00031: val_loss improved from 0.43565 to 0.43562, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 945ms/step - loss: 0.6332 - accuracy: 0.7193 - val_loss: 0.4356 - val_accuracy: 0.8160\n",
      "Epoch 32/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6137 - accuracy: 0.7133\n",
      "Epoch 00032: val_loss improved from 0.43562 to 0.43373, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 912ms/step - loss: 0.6137 - accuracy: 0.7133 - val_loss: 0.4337 - val_accuracy: 0.8160\n",
      "Epoch 33/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5868 - accuracy: 0.7280\n",
      "Epoch 00033: val_loss improved from 0.43373 to 0.42047, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 932ms/step - loss: 0.5868 - accuracy: 0.7280 - val_loss: 0.4205 - val_accuracy: 0.8260\n",
      "Epoch 34/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.5839 - accuracy: 0.7253\n",
      "Epoch 00034: val_loss did not improve from 0.42047\n",
      "15/15 [==============================] - 12s 816ms/step - loss: 0.5839 - accuracy: 0.7253 - val_loss: 0.4226 - val_accuracy: 0.8260\n",
      "Epoch 35/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6254 - accuracy: 0.7053\n",
      "Epoch 00035: val_loss improved from 0.42047 to 0.41652, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 926ms/step - loss: 0.6254 - accuracy: 0.7053 - val_loss: 0.4165 - val_accuracy: 0.8260\n",
      "Epoch 36/40\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.6028 - accuracy: 0.7247\n",
      "Epoch 00036: val_loss improved from 0.41652 to 0.41014, saving model to save\\best_weights_ALL3.hdf5\n",
      "15/15 [==============================] - 14s 953ms/step - loss: 0.6028 - accuracy: 0.7247 - val_loss: 0.4101 - val_accuracy: 0.8260\n"
     ]
    }
   ],
   "source": [
    "model=model_InceptionV3(X_train)\n",
    "\n",
    "\n",
    "file_path=\"save/best_weights_ALL2.hdf5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',patience=3,min_delta=0.001) \n",
    "callbacks_list = [checkpoint, early_stopping]\n",
    "history = model.fit(X_train, y_train,\n",
    "          callbacks = callbacks_list,\n",
    "          batch_size=100,\n",
    "          epochs=40,\n",
    "          verbose=1,\n",
    "          validation_data=(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA5sUlEQVR4nO3dd3iUZdb48e9JJ72QQAi9Q0JooQhSFKSpIMjS1F1soK6r7qpr+b2uZVfX11dd1sWGiqKwKCIqKKioIChFEnqvQRJaKAESEtLu3x/PAAGSkIRMnpnM+VzXXDN52px5LpgzdxdjDEoppTyXl90BKKWUspcmAqWU8nCaCJRSysNpIlBKKQ+niUAppTycJgKllPJwmgiUKicR+UBE/lHOY1NFpP+VXkep6qCJQCmlPJwmAqWU8nCaCFSN4qiSeVRE1otItoi8JyJ1RGSBiJwSke9FJKLY8UNFZJOIZIrIYhFpU2xfRxFZ7TjvEyDgove6QUTWOs5dJiKJlYz5bhHZKSLHRGSuiNRzbBcR+ZeIHBaRE47PlODYN0RENjtiSxeRRyp1w5RCE4GqmW4GrgNaAjcCC4AngdpY/+YfABCRlsBM4CEgGpgPzBMRPxHxA74APgIigU8d18VxbidgKjARiALeBuaKiH9FAhWRa4F/AqOAWGAv8LFj9wCgt+NzhAOjgaOOfe8BE40xIUAC8GNF3lep4jQRqJroP8aYQ8aYdGApsNIYs8YYcwb4HOjoOG408LUxZqExJh94GagF9AC6A77AJGNMvjFmNrCq2HvcDbxtjFlpjCk0xkwDzjjOq4hbgKnGmNWO+J4ArhKRxkA+EAK0BsQYs8UYc8BxXj7QVkRCjTHHjTGrK/i+Sp2jiUDVRIeKvc4p4e9gx+t6WL/AATDGFAH7gDjHvnRz4ayMe4u9bgQ87KgWyhSRTKCB47yKuDiGLKxf/XHGmB+BycDrwCERmSIioY5DbwaGAHtF5CcRuaqC76vUOZoIlCfbj/WFDlh18lhf5unAASDOse2shsVe7wOeN8aEF3sEGmNmXmEMQVhVTekAxpjXjDGdgXisKqJHHdtXGWOGATFYVVizKvi+Sp2jiUB5slnA9SLST0R8gYexqneWAcuBAuABEfERkRFA12LnvgPcIyLdHI26QSJyvYiEVDCG/wK3i0gHR/vCC1hVWaki0sVxfV8gG8gFCh1tGLeISJijSuskUHgF90F5OE0EymMZY7YBtwL/AY5gNSzfaIzJM8bkASOA8cBxrPaEOcXOTcZqJ5js2L/TcWxFY/gBeAr4DKsU0gwY49gdipVwjmNVHx3FascAuA1IFZGTwD2Oz6FUpYguTKOUUp5NSwRKKeXhNBEopZSH00SglFIeThOBUkp5OB+7A6io2rVrm8aNG9sdhlJKuZWUlJQjxpjokva5XSJo3LgxycnJdoehlFJuRUT2lrZPq4aUUsrDaSJQSikPp4lAKaU8nNu1ESilapb8/HzS0tLIzc21O5QaISAggPr16+Pr61vuczQRKKVslZaWRkhICI0bN+bCyV5VRRljOHr0KGlpaTRp0qTc52nVkFLKVrm5uURFRWkSqAIiQlRUVIVLV5oIlFK20yRQdSpzLz0mEaRn5vDsvE3kFxbZHYpSSrkUj0kEm9JP8P4vqbz38x67Q1FKuZDMzEzeeOONCp83ZMgQMjMzqz4gG3hMIhgQX5fr2tZh0vfb2XfstN3hKKVcRGmJoLCw7EXf5s+fT3h4uJOiql4ekwgAnh0aj5cIf/tyI7ogj1IK4PHHH2fXrl106NCBLl26cM011zBu3DjatWsHwE033UTnzp2Jj49nypQp585r3LgxR44cITU1lTZt2nD33XcTHx/PgAEDyMnJsevjVIpHdR+tF16Lv1zXkn98vYUFGw8ypF2s3SEppYp5dt4mNu8/WaXXbFsvlKdvjC91/4svvsjGjRtZu3Ytixcv5vrrr2fjxo3nul9OnTqVyMhIcnJy6NKlCzfffDNRUVEXXGPHjh3MnDmTd955h1GjRvHZZ59x663us3qoR5UIAMb3aEzb2FCenbeJU7n5doejlHIxXbt2vaAP/muvvUb79u3p3r07+/btY8eOHZec06RJEzp06ABA586dSU1NraZoq4ZHlQgAfLy9+OeIdtz0xi+88t12nhla+i8FpVT1KuuXe3UJCgo693rx4sV8//33LF++nMDAQPr27VtiH31/f/9zr729vd2uasjjSgQA7RuE8/vujZi2PJV1+zLtDkcpZaOQkBBOnTpV4r4TJ04QERFBYGAgW7duZcWKFdUcXfVwWiIQkakiclhENpay/xYRWe94LBOR9s6KpSQPD2xFdLA/T36+gQIdW6CUx4qKiqJnz54kJCTw6KOPXrBv0KBBFBQUkJiYyFNPPUX37t1titK5xFm9Z0SkN5AFfGiMSShhfw9gizHmuIgMBp4xxnS73HWTkpJMVS1MM3/DAe6bsZqnbmjLnVeXf14OpVTV2bJlC23atLE7jBqlpHsqIinGmKSSjndaicAYswQ4Vsb+ZcaY444/VwD1nRVLaQYn1OWaVtG8+t029me6V52eUkpVFVdpI7gTWFDaThGZICLJIpKckZFRZW8qIjw3LIFCY3hm7qYqu65SSrkT2xOBiFyDlQgeK+0YY8wUY0ySMSYpOrrEtZcrrUFkIA/2a8l3mw+xcPOhKr22Ukq5A1sTgYgkAu8Cw4wxR+2K465eTWhVJ4Snv9xI9pkCu8JQSilb2JYIRKQhMAe4zRiz3a44AHy9vXhhRAL7T+Qy6XtbQ1FKqWrnzO6jM4HlQCsRSRORO0XkHhG5x3HI34Ao4A0RWSsiVdMVqJI6N4pkdFIDpi3by+GTumSeUspzOLPX0FhjTKwxxtcYU98Y854x5i1jzFuO/XcZYyKMMR0cjxK7NVWne/s2I7+oiA+WpdodilLKRQUHBwOwf/9+Ro4cWeIxffv25XLd3CdNmsTp0+dnQrZzWmvbG4tdSePaQQyKr8v0FXvJ0rYCpVQZ6tWrx+zZsyt9/sWJwM5prTURXGRC76aczC1g1qp9doeilKoGjz322AXrETzzzDM8++yz9OvXj06dOtGuXTu+/PLLS85LTU0lIcEaK5uTk8OYMWNITExk9OjRF8w1dO+995KUlER8fDxPP/00YE1kt3//fq655hquueYa4Py01gCvvvoqCQkJJCQkMGnSpHPv56zprj1u0rnL6dgwgq6NI3nv5z38/qpG+HhrrlSq2ix4HA5uqNpr1m0Hg18sdfeYMWN46KGHuO+++wCYNWsW33zzDX/+858JDQ3lyJEjdO/enaFDh5a6HvCbb75JYGAg69evZ/369XTq1Oncvueff57IyEgKCwvp168f69ev54EHHuDVV19l0aJF1K5d+4JrpaSk8P7777Ny5UqMMXTr1o0+ffoQERHhtOmu9VuuBBN6NyU9M4evNxywOxSllJN17NiRw4cPs3//ftatW0dERASxsbE8+eSTJCYm0r9/f9LT0zl0qPRxRkuWLDn3hZyYmEhiYuK5fbNmzaJTp0507NiRTZs2sXnz5jLj+fnnnxk+fDhBQUEEBwczYsQIli5dCjhvumstEZTg2tYxNIsOYsqS3QxtX6/UXwFKqSpWxi93Zxo5ciSzZ8/m4MGDjBkzhhkzZpCRkUFKSgq+vr40bty4xOmniyvpe2LPnj28/PLLrFq1ioiICMaPH3/Z65Q1/5uzprvWEkEJvLyEu3s1ZdP+kyzbZds4N6VUNRkzZgwff/wxs2fPZuTIkZw4cYKYmBh8fX1ZtGgRe/fuLfP83r17M2PGDAA2btzI+vXrATh58iRBQUGEhYVx6NAhFiw4P5NOadNf9+7dmy+++ILTp0+TnZ3N559/Tq9evarw015KE0EpbuoYR+1gf95estvuUJRSThYfH8+pU6eIi4sjNjaWW265heTkZJKSkpgxYwatW7cu8/x7772XrKwsEhMTeemll+jatSsA7du3p2PHjsTHx3PHHXfQs2fPc+dMmDCBwYMHn2ssPqtTp06MHz+erl270q1bN+666y46duxY9R+6GKdNQ+0sVTkN9eW8vmgn//ftNhY82Is2saHV8p5KeRqdhrrqucw01DXBLd0aEujnzTtLtVSglKq5NBGUITzQj1FJDZi7dj8HTuh6BUqpmkkTwWXceXUTDPD+L6l2h6JUjeVuVdSurDL3UhPBZTSIDGRIu1j+u/I3Tubm2x2OUjVOQEAAR48e1WRQBYwxHD16lICAgAqdp+MIymFi76bMW7efmSt/Y2KfZnaHo1SNUr9+fdLS0qjK1Qc9WUBAAPXrV2zlX00E5ZAQF0aPZlG8/0sqt/dsgp+PFqSUqiq+vr40adLE7jA8mn6jldOE3k05eDKXeev22x2KUkpVKU0E5dSnZTSt6oTwztLdWpeplKpRNBGUk4hwd++mbD14ih+3HrY7HKWUqjKaCCpgaPt6NIoK5IGZa/h+c+kzESqllDvRRFABfj5ezJp4Fc1igrn7o2Te+mmXVhMppdyeJoIKqhMawCcTrmJIu1heXLCVRz5dz5mCQrvDUkqpStPuo5VQy8+byWM70iImmEnf72Dv0Wzevq0zUcH+lz9ZKaVcjJYIKklEeKh/SyaP68iG9BMMe/0Xth28dG5xpZRydZoIrtANifWYNfEq8gqKGPHGL/ywRRuRlVLuRRNBFWjfIJy5919Nk+gg7vowmSlLtBFZKeU+NBFUkbphAXw6sQeDE+rywvytTNXZSpVSbkITQRWyGpE7MaBtHV6Yv4Xlut6xUsoNaCKoYl5ewiuj2tM4KpD7/7ua/Zm6oI1SyrVpInCCkABfpvw+iTMFRdwzPYXcfB1noJRyXZoInKRZdDCvjmrP+rQTPPXFRm08Vkq5LE0ETjQgvi4PXNucT1PSmL7yN7vDUUqpEmkicLKH+rfkmlbRPDdvEyl7j9kdjlJKXUITgZN5eQmTRnekXngt7pm+mkMnc+0OSSmlLqCJoBqEBfoy5bYkss8UcN+M1eQVFNkdklJKnaOJoJq0qhvCSyMTSdl7nOe+2mR3OEopdY7OPlqNbkisx4a0E7y9ZDctYkIY160hvt6ai5VS9tJEUM0eHdiKTftP8vTcTfzvN1tJahxJ96aRXNU0ioS4ME0MSqlqp4mgmvl4e/HuH5L4YcthVuw+yordR3npm20ABPl5OxJDFN2bRpJYPxxvL7E5YqVUTSfuNtApKSnJJCcn2x1Glco4dYZf9xw7lxh2HM4C4PdXNeK5YQk2R6eUqglEJMUYk1TSPqeVCERkKnADcNgYc8m3mYgI8G9gCHAaGG+MWe2seFxZdIg/1yfGcn1iLGAlhmfmbeLT5DQeG9SaIH8tuCmlnMeZFdIfAIPK2D8YaOF4TADedGIsbiU6xJ/bezQmJ7+QbzYetDscpVQN57REYIxZApQ1lHYY8KGxrADCRSTWWfG4m86NImgYGcicNWl2h6KUquHs7KISB+wr9neaY5vCWhN5eMc4lu06yoETOpW1Usp57EwEJXWHKbHlWkQmiEiyiCRnZGQ4OSzXMaJTHMbAF2v22x2KUqoGszMRpAENiv1dHyjxG88YM8UYk2SMSYqOjq6W4FxBo6ggkhpFMGd1mk5jrZRyGjsTwVzg92LpDpwwxhywMR6XNLxTHDsOZ7Fp/0m7Q1FK1VBOSwQiMhNYDrQSkTQRuVNE7hGRexyHzAd2AzuBd4D7nBWLO7uhXT38vL2Yszrd7lCUUjWU0zqoG2PGXma/Af7orPe/xL5fYfGLMOpD8A+utre9UmGBvvRrE8Pcdek8MaS1TkGhlKpyHvStIrDrB0j5wO5AKmxEp/ocycpj6Q7PaShXSlUfz0kEDbpAk96w7D9QcMbuaCqkT8toIgJ9tXpIKeUUnpMIAHo9DFkHYe1/7Y6kQvx8vBjavh7fbT7Eydx8u8NRStUwnpUImvSBuM7wyyQoLLA7mgoZ0ak+eQVFLNigHauUUlXLsxKBiFUqOJ4Km+bYHU2FJNYPo2l0EJ9p9ZBSqop5ViIAaDkYotvA0lehyH3WDhYRbu5Un1/3HGPfsdN2h6OUqkE8LxF4eUGvv0DGFti+wO5oKmRYh3oAfLFGSwVKqarjeYkAIH4ERDSGpa+AG03dUD8ikO5NI5mzJl2nnFBKVRnPTATePtDzIUhPgT0/2R1NhYzoWJ89R7JZuy/T7lCUUjWEZyYCgA7jILiuVSpwI4Pb1cXfR6ecUEpVHc9NBD7+0ONPsGcJ7FtldzTlFhLgy8D4usxbv5+8Avdp7FZKuS7PXgy383hY+rJVKhj3sd3RlNvwTnHMXbefRdsOMzC+7iX70zNz+GHLIb7fcpitB04S7O9DSC1fQgN8CK3lS2iAL6G1fBzPvrSICaZL40i8vUpaIkIpVdN5diLwD4Zu98LiF+DgRqibYHdE5dKreW1qB/szZ3UaA+PrUlRkWJeWyQ9bDvP9lkNsPXgKgMZRgfRqEc2ZgkJO5hZwMief9MwcTuZYr/MKz5coagf7MyihDkMSYunaJBIfndxOKY8h7tb7JCkpySQnJ1fdBU8fg0ntoOUgGPle1V3Xyf7+1WY+XJ7K8I5x/Lg1gyNZZ/ASSGocSf82MfRrU4dm0WXPspqbX8iJnHxWpR5jwYaD/Lj1MDn5hUQF+TEwoS7Xt4ulmyYFpWoEEUkxxiSVuM/jEwHAd0/B8slwfzJENavaazvJlgMnuf61pQT5+9CnZTT929Shb6towgP9Kn3N03kFLN6WwdcbDvDjlvNJYUB8Xe6/tjlx4bWq8BMopaqTJoLLOXUQJiVC+zEw9LWqvbYT7c/MITrE3ylrFOTkFfLT9sN8veEg328+RGgtHz68oxut6oZU+XsppZyvrESgZX6AkLrQ6TZrVtKT7rNQfL3wWk5bqKaWnzeDEmL5z9iOfP7HHhgDo95eTsre4055P6WUfTQRnNXjATBF1noF6gKt64by2b09CA/05dZ3V7J422G7Q1JKVSFNBGdFNILE0ZA8FY7vtTsal9MgMpDZ9/SgSe0g7pqWzJdrdUCbUjWFJoLirv0fEC9Y+De7I3FJ0SH+fDyxO50aRfDQJ2uZtizV7pCUUlVAE0FxYXHWHESbv4DUn+2OxiWFBvjy4R1d6de6Dk/P3cS/Fm7XCfCUcnOaCC7W408Q1gAWPA5FhXZH45ICfL1569ZOjOxcn3//sIO/fbmJoiJNBkq5K00EF/MLhOueg0MbYM1Hdkfjsny8vfi/kYlM6N2Uj1bs5cFP1lKoyUApt6SJoCTxw6FhD/jh75CTaXc0LktEeHJIGx4d2Ip56/Yz9ec9doeklKoETQQlEYHBL8Lpo7Dk/+yOxuXd17cZ/dvU4eXvtrErI8vucJRSFaSJoDSx7a1BZivfgiM77I7GpYkILwxPIMDXm7/OXq9VREq5GU0EZbn2KfANhG+ftDsSlxcTGsAzQ9uSsvc47/+iVURKuRNNBGUJjoE+f4Ud38GOhXZH4/Ju6hBH/zYx/N+329itVURKuQ1NBJfTdSJENoNvnoDCfLujcWlWFVE7/H28eFSriJRyG5oILsfHDwb9E47ugF/fsTsal2dVEcVrFZFSbqRciUBEHhSRULG8JyKrRWSAs4NzGS0GQPP+sPhFyD5idzQub3jHOPq1tqqI9hzJtjscpdRllLdEcIcx5iQwAIgGbgdedFpUrkYEBr4AeVnw4z/sjsbliQgvjHBUEX26TquIlHJx5U0EZ1c1HwK8b4xZV2ybZ4huBV0nwOppcGC93dG4vDqhATx9YzzJe4/zgU5Op5RLK28iSBGR77ASwbciEgIUXeacmqfvY1ArEj65BTJ/szsalzei09kqoq1aRaSUCytvIrgTeBzoYow5DfhiVQ95lloRcOtsyD0B026EE2l2R+TSzlYR+XlrFZFSrqxcaxaLSE9grTEmW0RuBToB/zbGVPsKLk5Zs7ii0lPgw5sgMApunw+h9eyNx8XNTknjkU/XMTqpAU2igygsMhc+jPVsjKFDgwj6t43B38fb7rCVqlGuePF6EVkPtAcSgY+A94ARxpg+VRloebhEIgBIS7aSQXCMlQxC6todkcsyxvCnmWv4av2BS/Z5Cfh4eeHlBcbAmYIiIoP8uKlDHKO7NKBV3RAbIlaq5qmKRLDaGNNJRP4GpBtj3ju7raqDvRyXSQQAv62E6SMgJBbGfw0hdeyOyGUZY8g6U4C3l1gPsZ5Fzvc5KCwyLN2RwazkfSzcfIj8QkP7BuGMTmrAje1jCQnwtfETKOXeqiIR/AR8A9wB9AIysKqK2lVloOXhUokAYO9ymH4zhNWH8V9ZJQR1xY5mneHzNenMSt7H9kNZ1PL1Zki7WMZ0bUBSo4gLEohS6vKqIhHUBcYBq4wxS0WkIdDXGPPhZc4bBPwb8AbeNca8eNH+MGA60BDwAV42xrxf1jVdLhGAtazljN9BeCMrGQTVtjuiGsMYw9p9mcxK3se8dQfIOlNAz+ZRPDG4DQlxYXaHp5TbuOJE4LhIHaCL489fjTGHL3O8N7AduA5IA1YBY40xm4sd8yQQZox5TESigW1AXWNMXmnXdclEALBnCcwYBZFN4Q/zICjK7ohqnNN5BXz86z5e+3EHJ3LyGd4hjocHtiIuvJbdoSnl8spKBOWdYmIU8CvwO2AUsFJERl7mtK7ATmPMbscX+8fAsIuOMUCIWOX8YOAYUFCemFxOk94wdiYc2wUfDtOVzZwg0M+HO65uwk+PXsPE3s34asMBrnl5MS8u2MrJXJ0QUKnKKu84gv+HNYbgD8aY32N9yT91mXPigH3F/k5zbCtuMtAG2A9sAB40xlwyUE1EJohIsogkZ2RklDNkGzS7Bsb8FzK2wJd/tLrBqCoXVsuXxwe3ZtEjfbkhMZa3l+yiz0uLmPrzHvIKPG+co1JXqryJwOuiqqCj5Ti3pNa8i78ZBwJrgXpAB2CyiIRecpIxU4wxScaYpOjo6HKGbJPm/eC652DrV7B8st3R1Ghx4bV4dVQH5t1/NfH1wnjuq81c96+f+HbTQbtDU8qtlDcRfCMi34rIeBEZD3wNzL/MOWlAg2J/18f65V/c7cAcY9kJ7AFalzMm19X9PmhzIyx82upVpJwqIS6Mj+7syge3d6GWrzcTP0rh2XmbyC+sXOnAGMOujCzK236mlLsrVyIwxjwKTMEaUNYemGKMeewyp60CWohIExHxA8YAcy865jegH5xrjG4F7C5/+C5KBIa9DhGNYPbtkOXC1Vk1hIjQt1UM8/50Nbf3bMz7v6Ryy7sryTh1pkLXOXgil7umJdPvlZ94deF2J0WrlGspd6+hSl1cZAgwCav76FRjzPMicg+AMeYtEakHfADEYlUlvWiMmV7WNV2211BJDqyHd/tDo6vg1jngpdMmVJfP16TxxJwNhNfy481bO9GxYUSZxxtjmJW8j398tYX8oiLaxYWxKvU4b9/WmYHxOmpcub9Kdx8VkVNcWq8P1pe2McZcUp/vbG6VCABWfwhz/wR9HoNrnrQ7Go+yaf8J7pmewqETZ3h2WDxjuzYs8bi046d5Ys4Glu44Qrcmkbw0MpE6oQGMfns5uzKy+eKPPWkeE1zN0StVtSrdfdQYE2KMCS3hEWJHEnBLHW+D9uPgp5dg5w92R+NR4uuFMe/+q+nWNJIn5mzg8c/Wc6ag8Nz+oiLDRyv2MvBfS1i99zh/vymBmXd3p1FUEAG+3rx5a2f8fbyY+FEyp7R7qqrBdM1iZxOB61+BmDbw2V06dXU1Cw/044Pbu3Jf32Z8vGofo95ewYETOew9ms24d1fw1Bcb6dQogm//3JvbujfCy+t8Z7d64bWYPK4TqUdP8/CsdRTpNNqqhnJqG4EzuF3V0FlHdsCUvhDT1pqt1FsnUKtu32w8wMOz1uHv683pvAJ8vb146vq2/C6pfplzF7338x7+/tVmHhnQkvuvbVGNEStVda54ZLGqArVbwND/QNqvVrdSVe0GJcTy5f09qRMaQK8W0Sz8cx9GdWlw2Qns7ujZmGEd6vHKwu0s2lbmzCoVcuBEDmOmLGf5rqNVdk2lKkNLBNVt/l/h17dh1EfQdqjd0ahyyskrZMSby0g/fpq5919N49pBV3S9vIIiRk9ZzprfMmlSO4hvH+qNn4/+LlPOoyUCVzLgHxDXGT6fCNsW2B2NKqdaft5Mua0zXl7CPdNTOJ13ZVNivTB/C2t+y+S27o3YcySbactSqyZQpSpBE0F18/GDsR9DdGuYORZWvGV3RKqcGkQG8tqYjmw/dIq/zl5f6ZHHX65N54Nlqdx5dRP+flMC17SK5rUfdnAkq2KD35SqKpoI7BAcY61o1vp6+OYxq7qoqPDy5ynb9W4ZzSMDW/HV+gNMWVLxQfDbD53i8c82kNQogscHW7Op/M8NbcnJL+SV77ZVdbhKlYsmArv4BcKoD+Gq+602g4/HwZksu6NS5XBvn2YMaVeXfy7Yyj8XbKGgnHMaZZ0p4J7pKQT5e/P6LZ3w9bb++zWLDmZ8j8Z8vGofG9NPODN0pUqkicBOXt4w8HlrnMGO7+D9wXDy4nn5lKsREf41ugO3dGvI2z/tZtw7Kzl0MrfMc4wxPDZ7PalHsvnP2E7UCQ24YP+f+rUgItCP5+Zt1snuVLXTROAKutwF42bBsd3wTj84uMHuiNRl+Pt48/zwdkwa3YEN6Se4/rWlLNt5pNTjp/6SytcbDvDXQa25qtmlq9eF1fLlkQGt+DX1GPM36DTaqnppInAVLa6DO76xRiJPHQTbv7M7IlUON3WMY+79PQmr5cut761k8o87LhmBvCr1GP+cv4UBbeswsXfTUq81uksD2sSG8sL8LeTma5uRqj6aCFxJ3XZw1w/WusczR8OKN3WVMzfQok4Ic++/mhsS6/Hyd9u5Y9oqjmdby24fPpXLH2espn5ELV4e1b7MwWveXsLfbmhLemYO71SiIVqpytJE4GpCY+H2BdByMHzzOMy+A86csjsqdRlB/j78e0wH/n5TAst2HuWG//xMyt5j/Om/aziZm8+bt3YmNODy04pc1SyKwQl1eWPxLg6cyKmGyJXSROCa/INh9HTo9zRs/gLeuRYOb7E7KnUZIsJt3Rvx6T1XAXDzm8tZuecYLwxvR5vY8k/W++SQNhQaw/8u2OqsUJW6gCYCV+XlBb3+Ar//EnKOW8lg/ad2R6XKoX2DcL5+4GqGdajHn65tzohO9St0foPIQO7u1YQv1u4nZe/xK4ol83Qes1bt456PUli6Q1fKUyXTuYbcwckDVhXRb8usHkYDXwAff7ujUk6UfaaAa15eTGxYAJ/f1/OC6bEv50ROPgs3H+Kr9fv5eccRCooMvt5CoJ8P8x/sRVx4LSdGrlyVzjXk7kJj4Q9zocefYNW7Vq+izN/sjko5UZC/D48Pbs26tBN8vib9ssefys1nzuo07vxgFUn/WMgjn65j5+Es7uzVhHn3X83CP/ehsMjwwMw15JdzAJzyHFoicDdb5sEX91mD0Ua8Y3U7VTVSUZFh+JvL2HU4i0ZRgRhjrRtb/P+stc2QevQ0eQVF1AsL4PrEWK5PrEf7+mEX9FKau24/D8xcw719m/HYoNY2fCJlp7JKBD7VHYy6Qm1utBa3mfUHmDESYttDkz7QtA807GFNXaFqBC8v4ZXfJfLqwu2cyS/C+k63vthFrFfWs9CrRTRD2sXSsUF4qdVIQ9vXY/muo7y5eBfdmkTSt1VMlcabnpnD45+t54bEWEZ3KXl9aOWatETgrvJzYMUb1jrI+36Fonzw8oUGXc8nhrjOuhKaukBufiHDJv9CRtYZFjzY65KpLiorZe8xJn6UwpGsPEICfPj5r9cSFqj/9lyJthHURL61oNfD1rKXj++FWz+D7vdCXhYs/idMHQj/2xg+vR1ydSIzZQnw9eb1WzqSk1fIAzPXUFgF6zB/mryPsVNWEuzvw+RxHTmVW8CUpbuqIFpVXbRqqCbwC4Lm/a0HwOljkLoUdi+G1R/B8T1w6xwIjLQ1TOUamseE8I+bEnj403W89sMO/nxdy0pdp7DI8M/5W3j35z1c3bw2k8d1JDzQj282HuT9X1K5vWcTagdr7zZ3oCWCmigwEtoOgxv+BWNmwKHNMG0oZJc+KZryLDd3rs/Nnerz2o87ypwsrzQnc/O544NVvPvzHsb3aMwHt3chPNAPgD9f15Lc/ELeWKSlAnehiaCmazkQxs6Eozvhg+vh1CG7I1Iu4rlh8TStHcSDn6wl41T5V0fbcySb4a//wi87j/DC8HY8MzQeH+/zXyXNooO5uVN9pq/cq9NkuAlNBJ6geT+45VPI3AcfDNE1DxRgjVV4/ZZOnMzJ5y+z1l4ya2pJft5xhJte/4Vj2XlMv6sb47qV3Dvowf4tMMbw2g87qzps5QTaRuApmvSC2+bA9JHWAjh/mAfh2sXP07WuG8ozQ+N5Ys4G/vPjToZ1qMfx03lkns7nWHYex0+ffeRzNOsM3285TPPoYN79QxINIkvvqlw/IpBxXRsyfeVvTOzdlMa1g6rxU6mK0u6jniYtBaYPB/9Qa7RyZOnz4yvPYIzhgY/XMm9dySVFby8hItCX8EA/OjQI55mh8QT7X/435OFTufR+aRGD4usyaUzHqg5bVVBZ3Uc1EXii/Wvho+HgE2Alg9ot7I5I2ex0XgFfrT+Aj5cQEehHeKAvkUF+hAf6ERrgU+Y6CmX554ItTFmym28e7E2ruiGVukZBYRHZZwrJyisg+0wBWWes57qhATSPCa50bJ5GE4G61KFN8OEwQKwxCLGJdkekaqDj2Xn0fmkRPZpH8fZtJX4HXaCoyPDG4p3MTkkjy/Gln5tf+txItYP96NY0iquaRtG9aRTNooM0MZRCp5hQl6oTD+O/trqVvt0LWgyArhOh2bXWFNhKVYGIID/u7NWESd/vYN2+TNo3CC/12GPZeTz0yVqWbM/g6ua1aRgVSLC/D0F+PgT5exPs70NwgA9Bjm17jmSxYvcxlu86ytfrDwAQE+JP96ZRXNXMSgyNowI1MZSDlgg8XdZhWPUeJE+F7MMQ1Ry6ToD2YyGg/IupKFWaU7n59H5pEQlxYXx0Z7cSj1n923H+OGM1R7PyeGZoPGO7Nij3F7gx1qR7K3YfZfmuoyzfffRcd9i6oQF0bxpJd0eJoZEHJwatGlKXV3AGNn8JK9+C9BTwC4EO46ykULu53dEpNzdlyS5emL+VTyZ0p1vTqHPbjTFMW5bK8/O3UDcsgDfGdaZd/bArei9jDLuPZLN811FW7D7Kit3HOJKliUETgaqYtBT49W3YOMeazK55f+h2DzTrp9VGqlJy8wvp/dIiGkUFMmviVYgIWWcKeOyz9Xy9/gD928Twyu86OGWiOmMMuzKyHUnhwsTQMDLw3Cpy3hVY/McdaSJQlXPqEKR8AMnvQdYhR7XRROgwFvwr1wNEea6Plqfy1Jeb+OD2LtQLr8U901NIPZLNowNbM7F30wqtwnYliieGWcn7WJ92ghYxwTw6sBXXta1jSwnh7GA+Z94DTQTqyhTkOaqN3rSqjfxDoeNt0PVuiGxid3TKTeQVFHHtK4sBOJqVR5C/D/8Z25GrmkWVfaITGWNYsPEgL3+7jd1HsunUMJzHBrW+oPrK2fIKirjrw2S2HzzF325sy+CEuk5JRpoIVNXZt8pqR9j8BRQVQqvBVrVRk97gIXWtqvJmp6TxyKfr6NokksljOxJTReshXKmCwiI+TUlj0vfbOXTyDNe0iuavg1rTJta5HSaMMTw8ax1z1qTTOCqQ1KOnuaZVNM8NSyhz5HZlaCJQVe/kfqu3Ucr7cPooxMRDzwch4Wbw1l7JqmTGGNbsyyQxLuyCiepcRU5eIdOWp/LGop2cOlPAsPb1eHhAqyr/Uj7r5W+3MXnRTh6+riX39m3GtOV7efW7bRQawwP9WnDX1U3x86ma+6SJQDlPfi5snA3LJkPGFghvBD0fgA63gq9r/NpTqqJOnM7nrSW7eP+XPfh4efH88ASGdYir0veYsXIv/+/zjYzt2oAXhrc7Vx104EQOz87dzDebDtKyTjD/uKkdXZtc+VoitiUCERkE/BvwBt41xrxYwjF9gUmAL3DEGNOnrGtqInBRRUWw/RtY+gqkJ0NQDFz1R0i6Q8cjKLeVnpnDgzPXkLz3OKOS6vPM0HgC/a68xPvDlkPc/WEyfVpG887vk0osHf2w5RB/+3IT6Zk5jEqqzxOD2xAR5Ffp97QlEYiIN7AduA5IA1YBY40xm4sdEw4sAwYZY34TkRhjzOGyrquJwMUZY62OtvRV2L0IAsKgy93WMppBte2OTqkKKygsYtL3O3h98U6aRQczeVxHWtet/I+bdfsyGTNlBc1jgvl4QneCypjA73ReAf/+YQfvLd1DSIAPzw5LYGj7epV6X7vWLO4K7DTG7DbG5AEfA8MuOmYcMMcY8xvA5ZKAcgMiVsPx77+AuxdZr5e+Av9KgK8fgcNb7I5QqQrx8fbikYGtmH5nN07k5DNs8i/MWLmXyvyI3ns0mzs+WEXtED+mju9SZhIACPTz4YnBbfjqgatpGh3M6TMFlf0YZXJmiWAk1i/9uxx/3wZ0M8bcX+yYSVhVQvFACPBvY8yHJVxrAjABoGHDhp337t3rlJiVk2Rsg58nWW0JhXnQqKdVZdTmRvDRNW2V+8g4dYaHP13Hku0ZXN8ulhdGtCOsVvkGwR3LzuPmN5dx/HQen93bg2bRwRV67ysda2BXiaCkaC/OOj5AZ+B6YCDwlIhcspK2MWaKMSbJGJMUHR1d9ZEq54puBcPfhL9sgf7Pwsl0+OxOeLUtfP8MHE+1O0KlyiU6xJ8Pxnfh8cGt+XbTQa5/bSlrfjt+2fNy8wu5a9oq0jNzePf3SRVOAmAlAGcNOHNmP780oEGxv+sDF698kYbVQJwNZIvIEqA9VtuCqmmCasPVD0GPB2D3j7BqKvzyb6u00Lw/dLkTml+n3U+VS/PyEu7p04yuTSJ5YOYafvfWclrWCSEiyJeIQL9z6zhEBvoSEeRHRKAf01fsZc2+TN4Y14mkxlfeA6iqObNqyAfrC70fkI7VWDzOGLOp2DFtgMlYpQE/4FdgjDFmY2nX1cbiGuZEOqyeBinTIOug1bjc7FprWuzm/SE4xu4IlSrViZx8Jv+4gz1Hsjl+Op/j2Xkccyz1ebG/3dCWO662byS+nd1Hh2B1DfUGphpjnheRewCMMW85jnkUuB0owupiOqmsa2oiqKEK82HHd7BtPuxYaM1tBFCvo5UUWgywXnt52xunUuVQUFjEiZx8KzmczsPP26vMtRiqgw4oU+6lqAgObbASw46FkLYKTBEERllVR/E3WTOh+lS+T7VSnkYTgXJvp4/Brh8dieE7yDluVSG1GQrtRkLjXlpSUOoydKlK5d4CI60v/HYjrSqkXYusrqibPoc1H0FwHYgfbs1zVL+LTn6nVAVpIlDuxdsXWg6wHvk5sP1bKykkv2/NihreENreZLUpNOxuHa+UKpNWDamaIfcEbJ1vJYXdP1krq/mFQNM+0OI6qwdSWH27o1TKNlo1pGq+gDBr5bQOY+HMKSsZ7FwIO76HrV9Zx0S3gRb9rQbnRj20tKCUg5YIVM1mDGRstXof7VwIe5dbpYXwhtDrEegwThOC8gjaa0ips86cgp0/wC+TYP8aa/2E3o9C+zGaEFSNZtdcQ0q5Hv8QaxzC3Ytg3CyrR9Lc+2FyEqyZbvVKUsrDaCJQnkkEWg60EsLYT6w2hi//CJO7wJoZUOic6X6VckWaCJRnE4FWg2DCTzBmplVi+PI+q4Sw8GnYvdhajlOpGkzbCJQqzhjYtgCWvw77VkBRAfgEWGMSmva1HnUTdSSzcjvafVSp8hKB1kOsx5ks2LvMKhXsXmytnQBQK8Jaea1+F/ALBt9a1sOnVrHXAdZzWH1dfEe5PE0ESpXGP/j8KGaAU4dgzxJHYlgEm7+8/DUCwiBhJHS4BeI66fQXyiVp1ZBSlWEM5GZa01ycfRTkQv5pq00h/7T12L0YNs+FghyIbm2NW0gcDSF17f4EysPoOAKl7JR7AjZ9AWtnwL6VIF7WlBcdboFWg7XqSFULTQRKuYojO2Hdf2HtTDi132pvaHuTNXNqo57gpR35lHNoIlDK1RQVWtVGa/9rrcqWfxpCYiF+BLS7Geppe4KqWtprSClX4+UNzftZj7xs2P4NbPgMVr0DK16HiCZWKaHdSIhpY52Td9pawjM7w3rOOgRZh61HUG1oNwqiW9r7uZRb0hKBUq4kJ9OaLXXDbNjzk7VEZ0is1ZU171QJJ4i1hGfOcTCFVkmi/VgriQRFVXf0yoVp1ZBS7ijrsNVFNW0V1IqE4BhrNbbgOo7XMRBYG7x9rK6tG2fDuplwcAN4+ViL8ySOhpaDwDfA7k+jbKaJQClPcmgTrPsY1s+CrIPWWIb44dB2mNUgrb2UPJImAqU80dkG6XUfW9VN+aetkdBN+1oT7rUYoOMZPIg2FivliS5okD5tjYre/g3s+O78qm2xHRxJYSDU66jdVz2UlgiU8jTGWNVHO76F7d9abRCmCPxDwdvPem0KreNMkVWyMEXWI7iOtZ5Dwgjt4upmtGpIKVW608dg5/ew71fry168zj+8vK0v+7N/H95qHVuUDxGNrXEPCTdDnXhNCi5OE4FSqurkHIetX8PGz2D3T1bpoXYrKyEkjIDaLeyOUJVAE4FSyjmyMmDLl7Dxc9j7C2AgvKE1RXdcEtRPstZv0O6rttNEoJRyvpP7rZlWf1sGaSlwMs3a7uULdRPOJ4a4JIhsoov7VDNNBEqp6nfyAKQnQ1oypKdA+mrIz7b2eftbVUi1W0J0q/PPUc11nIOTaPdRpVT1C42F0BuhzY3W30WFkLHVSggZW+HIditBbPoccPwgFS+rETq6tZUYzj7XbgV+gXZ9khpPE4FSqnp4eVu9i+rEX7g97zQc3WklhoxtcGSb9bxjodU7CQCx2h6iW0NMa+u5diurVBEQWu0fpabRRKCUspdfIMQmWo/iCvPh2G6r9JCxDQ5vsZ53L4LCvPPHhdSzZl2t3bJYVVMray4m7dJaLpoIlFKuydvXUT3U6sLthQVwfE+x0sN2qzSx9r+Ql3X+OP9Q8Lmot9LFiUG8rbWp/YIdzyHWs3/I+W3RbaDFdTW67UITgVLKvXj7OBqaWwA3nN9ujNVz6WxyOLbLKlWcP+DSaxUWWMkjL8ua6js71Zru+4xj29mSR0C4NUYicQw06FrjShqaCJRSNYMIhMVZj2bXVs0183Mh9WdY/7G1vGjyVKsxO3G09YhqVjXvYzPtPqqUUuVx5hRsmWfN5rpnCWCsgXPtRkFgJJw5CbknS34uzLeSRnTr8w3eYQ2rdZI/HUeglFJV6UQ6bPgU1n8ChzdfuE+8rPaJgFDwD7OexcvqGXXqwPnjfAOtxu2YNo62kDZQpy2ENXBK1ZMmAqWUcgZj4OguKCpwfPGHgl9Q6V/kOcet9ouMLcV6Qm29MEH4h1rJIaYNxMRbySGmrVXquAK2JQIRGQT8G/AG3jXGvFjKcV2AFcBoY8zssq6piUApVePkZFoJ4dAmq4RxeIv1Ojfz/DEhsXDV/dDj/kq9hS0ji0XEG3gduA5IA1aJyFxjzOYSjvtf4FtnxaKUUi6tVjg07G49zjLGKikc2uxIDpudtqKcM3sNdQV2GmN2A4jIx8Aw4KIKNf4EfAZ0cWIsSinlXkQgtJ71aNHfqW/lzCbrOGBfsb/THNvOEZE4YDjwVlkXEpEJIpIsIskZGRlVHqhSSnkyZyaCklpLLm6QmAQ8ZowpLOtCxpgpxpgkY0xSdHR0VcWnlFIK51YNpQENiv1dH9h/0TFJwMditbDXBoaISIEx5gsnxqWUUqoYZyaCVUALEWkCpANjgHHFDzDGNDn7WkQ+AL7SJKCUUtXLaYnAGFMgIvdj9QbyBqYaYzaJyD2O/WW2CyillKoeTp1ryBgzH5h/0bYSE4AxZrwzY1FKKVWy6pvoQimllEvSRKCUUh7O7eYaEpEMYG8lT68NHKnCcJzNneJ1p1jBveJ1p1jBveJ1p1jhyuJtZIwpsf+92yWCKyEiyaXNteGK3Cled4oV3Cted4oV3Cted4oVnBevVg0ppZSH00SglFIeztMSwRS7A6ggd4rXnWIF94rXnWIF94rXnWIFJ8XrUW0ESimlLuVpJQKllFIX0USglFIezmMSgYgMEpFtIrJTRB63O57LEZFUEdkgImtFxKXW5hSRqSJyWEQ2FtsWKSILRWSH4znCzhiLKyXeZ0Qk3XF/14rIEDtjPEtEGojIIhHZIiKbRORBx3aXu79lxOqq9zZARH4VkXWOeJ91bHfFe1tarE65tx7RRuBYDnM7xZbNBMZevGymKxGRVCDJGONyg11EpDeQBXxojElwbHsJOGaMedGRaCOMMY/ZGedZpcT7DJBljHnZztguJiKxQKwxZrWIhAApwE3AeFzs/pYR6yhc894KEGSMyRIRX+Bn4EFgBK53b0uLdRBOuLeeUiI4t2ymMSYPOLtspqoEY8wS4NhFm4cB0xyvp2F9IbiEUuJ1ScaYA8aY1Y7Xp4AtWCv7udz9LSNWl2QsWY4/fR0Pg2ve29JidQpPSQSXXTbTBRngOxFJEZEJdgdTDnWMMQfA+oIAYmyOpzzuF5H1jqoj26sDLiYijYGOwEpc/P5eFCu46L0VEW8RWQscBhYaY1z23pYSKzjh3npKIijPspmupqcxphMwGPijo3pDVZ03gWZAB+AA8Iqt0VxERIKBz4CHjDEn7Y6nLCXE6rL31hhTaIzpgLViYlcRSbA5pFKVEqtT7q2nJILyLJvpUowx+x3Ph4HPsaq3XNkhR53x2brjwzbHUyZjzCHHf7Qi4B1c6P466oQ/A2YYY+Y4Nrvk/S0pVle+t2cZYzKBxVh17i55b88qHquz7q2nJIJzy2aKiB/WsplzbY6pVCIS5Gh8Q0SCgAHAxrLPst1c4A+O138AvrQxlss6+x/fYTgucn8djYTvAVuMMa8W2+Vy97e0WF343kaLSLjjdS2gP7AV17y3JcbqrHvrEb2GABzdrCZxftnM5+2NqHQi0hSrFADWKnL/daV4RWQm0BdrStxDwNPAF8AsoCHwG/A7Y4xLNNCWEm9frOK1AVKBiWfrie0kIlcDS4ENQJFj85NYde8udX/LiHUsrnlvE7Eag72xfgTPMsY8JyJRuN69LS3Wj3DCvfWYRKCUUqpknlI1pJRSqhSaCJRSysNpIlBKKQ+niUAppTycJgKllPJwmgiUqkYi0ldEvrI7DqWK00SglFIeThOBUiUQkVsd88GvFZG3HROAZYnIKyKyWkR+EJFox7EdRGSFYyKwz89OBCYizUXke8ec8qtFpJnj8sEiMltEtorIDMcIXaVso4lAqYuISBtgNNbEfx2AQuAWIAhY7ZgM8CesEcoAHwKPGWMSsUbZnt0+A3jdGNMe6IE1SRhYs3Q+BLQFmgI9nfyRlCqTj90BKOWC+gGdgVWOH+u1sCYiKwI+cRwzHZgjImFAuDHmJ8f2acCnjrmi4owxnwMYY3IBHNf71RiT5vh7LdAYa+ERpWyhiUCpSwkwzRjzxAUbRZ666Liy5mcpq7rnTLHXhej/Q2UzrRpS6lI/ACNFJAbOrWnbCOv/y0jHMeOAn40xJ4DjItLLsf024CfHvPxpInKT4xr+IhJYnR9CqfLSXyJKXcQYs1lE/gdrhTgvIB/4I5ANxItICnACqx0BrKmL33J80e8Gbndsvw14W0Sec1zjd9X4MZQqN519VKlyEpEsY0yw3XEoVdW0akgppTyclgiUUsrDaYlAKaU8nCYCpZTycJoIlFLKw2kiUEopD6eJQCmlPNz/B/jgNtvogSX2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Functional)    (None, 2, 2, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 23,903,010\n",
      "Trainable params: 2,100,226\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n",
      "[[414  86]\n",
      " [ 87 413]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.83      0.83       500\n",
      "         1.0       0.83      0.83      0.83       500\n",
      "\n",
      "    accuracy                           0.83      1000\n",
      "   macro avg       0.83      0.83      0.83      1000\n",
      "weighted avg       0.83      0.83      0.83      1000\n",
      "\n",
      "[ True  True False False False False  True False False False]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "414 86 87 413\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model=model_InceptionV3(X_train)\n",
    "model.load_weights('save/best_weights_ALL2.hdf5')\n",
    "pred = model.predict(X_test)[:,0] > 0.5\n",
    "y_test_pain=y_test[:,0]\n",
    "\n",
    "print(confusion_matrix(y_test[:,0],pred))\n",
    "print(classification_report(y_test[:,0],pred))\n",
    "\n",
    "\n",
    "print(pred[0:10])\n",
    "print(y_test[0:10,1])\n",
    "\n",
    "tT = 0\n",
    "tF = 0\n",
    "fT = 0\n",
    "fF = 0\n",
    "for i in range(len(y_test)):\n",
    "    if (y_test_pain[i] == 0)&(pred[i] == 0):\n",
    "            tT += 1\n",
    "    elif (y_test_pain[i] == 0)&(pred[i] == 1):\n",
    "            tF += 1\n",
    "    elif (y_test_pain[i] == 1)&(pred[i] == 0):\n",
    "            fT += 1\n",
    "    elif (y_test_pain[i] == 1)&(pred[i] == 1):\n",
    "            fF += 1\n",
    "print(tT,tF,fT,fF)\n",
    "        \n",
    "##save result\n",
    "file = 'result_NO.csv'\n",
    "with open(file, 'a+', newline = '') as csvFile:\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "    csvWriter.writerow([tT,tF,fT,fF,'N_CNN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import joblib\n",
    "\n",
    "def modelPredict2(df_sita,df,label,faceModel,ssModel,clf,file_path):    \n",
    "    #載入正臉model\n",
    "    face = joblib.load(faceModel)\n",
    "    ssFace = joblib.load(ssModel)\n",
    "    #輸入sita!!!!!!!\n",
    "\n",
    "    df=df\n",
    "    Sitadata = df_sita\n",
    "    data = ssFace.transform(Sitadata)\n",
    "\n",
    "    pred = face.predict(data)\n",
    "    \n",
    "\n",
    "    df=df[pred==1]\n",
    "    label=label[pred==1]\n",
    "    \n",
    "    image_df_health=df[label[:,0]==0]\n",
    "    image_df_pain=df[label[:,0]==1]\n",
    "    labelH=label[label[:,0]==0]\n",
    "    labelP=label[label[:,0]==1]\n",
    "\n",
    "\n",
    "    if len(image_df_pain) >= len(image_df_health):\n",
    "        image_df_pain = dataSample2(image_df_pain,image_df_health.shape[0])\n",
    "        labelP = dataSample2(labelP,labelH.shape[0])\n",
    "        print(image_df_pain.shape)\n",
    "        print(image_df_health.shape)\n",
    "\n",
    "    elif len(image_df_pain) < len(image_df_health):\n",
    "        image_df_health = dataSample2(image_df_health,image_df_pain.shape[0])\n",
    "        labelH = dataSample2(labelH,labelP.shape[0])\n",
    "        print(image_df_pain.shape)\n",
    "        print(image_df_health.shape)    \n",
    "    \n",
    "    \n",
    "    random_state=42\n",
    "    A_train, A_test, b_train, b_test = train_test_split(image_df_health, labelH, test_size=20/42, random_state=random_state)\n",
    "    A_validation, A_test, b_validation, b_test = train_test_split(A_test, b_test, test_size=0.5, random_state=random_state)\n",
    "\n",
    "    W_train, W_test, v_train, v_test = train_test_split(image_df_pain, labelP, test_size=20/42, random_state=random_state)\n",
    "    W_validation, W_test, v_validation, v_test = train_test_split(W_test, v_test, test_size=0.5, random_state=random_state)\n",
    "\n",
    "    X_train=np.append(A_train, W_train,axis=0)\n",
    "    X_validation=np.append(A_validation, W_validation,axis=0)\n",
    "    X_test=np.append(A_test, W_test,axis=0)\n",
    "\n",
    "    y_train=np.append(b_train, v_train,axis=0)\n",
    "    y_validation=np.append(b_validation, v_validation,axis=0)\n",
    "    y_test=np.append(b_test, v_test,axis=0)\n",
    "\n",
    "    print('train')\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print('validation')\n",
    "    print(X_validation.shape)\n",
    "    print(y_validation.shape)\n",
    "    print('test')\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "\n",
    "\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_validation = X_validation.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /=255\n",
    "    X_validation  /=255\n",
    "    X_test  /=255\n",
    "    \n",
    "    #model 初始化\n",
    "    model=model_InceptionV3(X_test)\n",
    "    \n",
    "    #confusion_matrix\n",
    "    model.load_weights(file_path)\n",
    "    pred = model.predict(X_test)[:,0] > 0.5\n",
    "    y_test_pain=y_test[:,0]\n",
    "    print(confusion_matrix(y_test_pain,pred))\n",
    "    print(classification_report(y_test_pain,pred))\n",
    "\n",
    "\n",
    "    tT = 0\n",
    "    tF = 0\n",
    "    fT = 0\n",
    "    fF = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if (y_test_pain[i] == 0)&(pred[i] == 0):\n",
    "                tT += 1\n",
    "        elif (y_test_pain[i] == 0)&(pred[i] == 1):\n",
    "                tF += 1\n",
    "        elif (y_test_pain[i] == 1)&(pred[i] == 0):\n",
    "                fT += 1\n",
    "        elif (y_test_pain[i] == 1)&(pred[i] == 1):\n",
    "                fF += 1\n",
    "    print(tT,tF,fT,fF)\n",
    "        \n",
    "    ##save result\n",
    "    file = 'result_NO.csv'\n",
    "    with open(file, 'a+', newline = '') as csvFile:\n",
    "        csvWriter = csv.writer(csvFile)\n",
    "        csvWriter.writerow([tT,tF,fT,fF,clf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_line\n",
      "(646, 128, 128, 3)\n",
      "(646, 128, 128, 3)\n",
      "train\n",
      "(676, 128, 128, 3)\n",
      "(676, 2)\n",
      "validation\n",
      "(308, 128, 128, 3)\n",
      "(308, 2)\n",
      "test\n",
      "(308, 128, 128, 3)\n",
      "(308, 2)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Functional)    (None, 2, 2, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 23,903,010\n",
      "Trainable params: 2,100,226\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n",
      "[[130  24]\n",
      " [ 16 138]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.84      0.87       154\n",
      "         1.0       0.85      0.90      0.87       154\n",
      "\n",
      "    accuracy                           0.87       308\n",
      "   macro avg       0.87      0.87      0.87       308\n",
      "weighted avg       0.87      0.87      0.87       308\n",
      "\n",
      "130 24 16 138\n"
     ]
    }
   ],
   "source": [
    "print('svm_line')\n",
    "modelPredict2(df_sita,df,label,'save/FaceModel_SVMLinear2.pkl','save/ssFace2.pkl','save/Linear','save/best_weights_ALL2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm\n",
      "(1058, 128, 128, 3)\n",
      "(1058, 128, 128, 3)\n",
      "train\n",
      "(1108, 128, 128, 3)\n",
      "(1108, 2)\n",
      "validation\n",
      "(504, 128, 128, 3)\n",
      "(504, 2)\n",
      "test\n",
      "(504, 128, 128, 3)\n",
      "(504, 2)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Functional)    (None, 2, 2, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 23,903,010\n",
      "Trainable params: 2,100,226\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n",
      "[[217  35]\n",
      " [ 41 211]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.86      0.85       252\n",
      "         1.0       0.86      0.84      0.85       252\n",
      "\n",
      "    accuracy                           0.85       504\n",
      "   macro avg       0.85      0.85      0.85       504\n",
      "weighted avg       0.85      0.85      0.85       504\n",
      "\n",
      "217 35 41 211\n"
     ]
    }
   ],
   "source": [
    "print('svm')\n",
    "modelPredict2(df_sita,df,label,'save/FaceModel_SVM2.pkl','save/ssFace2.pkl','save/SVM','save/best_weights_ALL2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc\n",
      "(1166, 128, 128, 3)\n",
      "(1166, 128, 128, 3)\n",
      "train\n",
      "(1220, 128, 128, 3)\n",
      "(1220, 2)\n",
      "validation\n",
      "(556, 128, 128, 3)\n",
      "(556, 2)\n",
      "test\n",
      "(556, 128, 128, 3)\n",
      "(556, 2)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Functional)    (None, 2, 2, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 23,903,010\n",
      "Trainable params: 2,100,226\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n",
      "[[249  29]\n",
      " [ 45 233]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.90      0.87       278\n",
      "         1.0       0.89      0.84      0.86       278\n",
      "\n",
      "    accuracy                           0.87       556\n",
      "   macro avg       0.87      0.87      0.87       556\n",
      "weighted avg       0.87      0.87      0.87       556\n",
      "\n",
      "249 29 45 233\n"
     ]
    }
   ],
   "source": [
    "print('rfc')\n",
    "modelPredict2(df_sita,df,label,'save/FaceModel_RFC2.pkl','save/ssFace2.pkl','save/RFC','save/best_weights_ALL2.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
